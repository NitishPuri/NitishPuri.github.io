{"pages":[{"url":"pages/peterpan/","text":"","tags":"pages","title":"PeterPan"},{"url":"pages/untitled1/","text":"","tags":"pages","title":"Untitled1"},{"url":"pages/graffiti1/","text":"","tags":"pages","title":"graffiti1"},{"url":"pages/magazines/","text":"","tags":"pages","title":"magazines"},{"url":"pages/nightclub/","text":"","tags":"pages","title":"nightClub"},{"url":"pages/portrait1_2/","text":"","tags":"pages","title":"portrait1_2"},{"url":"pages/portrait1_filter/","text":"","tags":"pages","title":"portrait1_filter"},{"url":"pages/graffiti201/","text":"","tags":"pages","title":"graffiti2~01"},{"url":"pages/graffiti3_filter01/","text":"","tags":"pages","title":"graffiti3_filter~01"},{"url":"pages/graffiti301/","text":"","tags":"pages","title":"graffiti3~01"},{"url":"pages/greeklovers01/","text":"","tags":"pages","title":"greekLovers~01"},{"url":"pages/landscape12_electromagnetic01/","text":"","tags":"pages","title":"landscape12_electromagnetic~01"},{"url":"pages/landscape12_ultraviolet01/","text":"","tags":"pages","title":"landscape12_ultraviolet~01"},{"url":"pages/landscape1201/","text":"","tags":"pages","title":"landscape12~01"},{"url":"pages/noface101/","text":"","tags":"pages","title":"noFace1~01"},{"url":"pages/portrait11_filter01/","text":"","tags":"pages","title":"portrait11_filter~01"},{"url":"pages/portrait7_negative01/","text":"","tags":"pages","title":"portrait7_negative~01"},{"url":"pages/portrait701/","text":"","tags":"pages","title":"portrait7~01"},{"url":"pages/silhouette3_electromagnetic01/","text":"","tags":"pages","title":"silhouette3_electromagnetic~01"},{"url":"pages/silhouette3_negative01/","text":"","tags":"pages","title":"silhouette3_negative~01"},{"url":"pages/splash_ufilter01/","text":"","tags":"pages","title":"splash_ufilter~01"},{"url":"pages/splash01/","text":"","tags":"pages","title":"splash~01"},{"url":"pages/woodpecker201/","text":"~01.jpg)","tags":"pages","title":"woodpecker(2)~01"},{"url":"pages/graffiti_mrdj_filter/","text":"","tags":"pages","title":"Graffiti_mrDJ_filter"},{"url":"pages/graffiti_mrdj/","text":"","tags":"pages","title":"graffiti_mrDJ"},{"url":"pages/wonderwoman_2/","text":"","tags":"pages","title":"wonderWoman_2"},{"url":"pages/69_filter01/","text":"","tags":"pages","title":"69_filter~01"},{"url":"pages/6901/","text":"","tags":"pages","title":"69~01"},{"url":"pages/batman_filter01/","text":"","tags":"pages","title":"Batman_filter~01"},{"url":"pages/batman01/","text":"","tags":"pages","title":"Batman~01"},{"url":"pages/boat1/","text":"","tags":"pages","title":"Boat1"},{"url":"pages/girl103_filtered201/","text":"","tags":"pages","title":"Girl103_filtered2~01"},{"url":"pages/girl103_filtered01/","text":"","tags":"pages","title":"Girl103_filtered~01"},{"url":"pages/ironman_filter_201/","text":"","tags":"pages","title":"IronMan_filter_2~01"},{"url":"pages/ironman_filter01/","text":"","tags":"pages","title":"IronMan_filter~01"},{"url":"pages/ironman01/","text":"","tags":"pages","title":"IronMan~01"},{"url":"pages/johnnybravo/","text":"","tags":"pages","title":"JohnnyBravo"},{"url":"pages/window_filtered01/","text":"","tags":"pages","title":"Window_filtered~01"},{"url":"pages/window01/","text":"","tags":"pages","title":"Window~01"},{"url":"pages/wonderwoman01/","text":"","tags":"pages","title":"WonderWoman~01"},{"url":"pages/animalcomposition102/","text":"","tags":"pages","title":"animalComposition1~02"},{"url":"pages/boy102/","text":"","tags":"pages","title":"boy102"},{"url":"pages/composition_10901/","text":"","tags":"pages","title":"composition_109~01"},{"url":"pages/dragonsonthewall/","text":"","tags":"pages","title":"dragonsOnTheWall"},{"url":"pages/face0101/","text":"","tags":"pages","title":"face01~01"},{"url":"pages/face0301/","text":"","tags":"pages","title":"face03~01"},{"url":"pages/feline_1/","text":"","tags":"pages","title":"feline_1"},{"url":"pages/feline_1_filtered/","text":"","tags":"pages","title":"feline_1_filtered"},{"url":"pages/fly/","text":"","tags":"pages","title":"fly"},{"url":"pages/forest_electromagnetic01/","text":"","tags":"pages","title":"forest_electromagnetic~01"},{"url":"pages/forest_negative01/","text":"","tags":"pages","title":"forest_negative~01"},{"url":"pages/forest01/","text":"","tags":"pages","title":"forest~01"},{"url":"pages/girl12_filter01/","text":"","tags":"pages","title":"girl12_filter~01"},{"url":"pages/girl1201/","text":"","tags":"pages","title":"girl12~01"},{"url":"pages/portrait1101/","text":"","tags":"pages","title":"portrait11~01"},{"url":"pages/thingfish/","text":"","tags":"pages","title":"thingFish"},{"url":"pages/wonderwoman0101/","text":"","tags":"pages","title":"WonderWoman~01~01"},{"url":"pages/portrait_angelina_edited/","text":"","tags":"pages","title":"portrait_angelina_edited"},{"url":"pages/portrait_ash/","text":"","tags":"pages","title":"Portrait_Ash"},{"url":"pages/scarlett/","text":"","tags":"pages","title":"Scarlett"},{"url":"pages/architecture_1201/","text":"","tags":"pages","title":"architecture_12~01"},{"url":"pages/mface_28/","text":"","tags":"pages","title":"mFace_28"},{"url":"pages/mface_03/","text":"","tags":"pages","title":"mFace_03"},{"url":"pages/mface_09/","text":"","tags":"pages","title":"mFace_09"},{"url":"pages/mface_16/","text":"","tags":"pages","title":"mFace_16"},{"url":"pages/mface_17/","text":"","tags":"pages","title":"mFace_17"},{"url":"pages/mface_25/","text":"","tags":"pages","title":"mFace_25"},{"url":"pages/mface_32/","text":"","tags":"pages","title":"mFace_32"},{"url":"pages/frac_01/","text":"","tags":"pages","title":"frac_01"},{"url":"pages/frac_05/","text":"","tags":"pages","title":"frac_05"},{"url":"pages/frac_08/","text":"","tags":"pages","title":"frac_08"},{"url":"pages/frac_13/","text":"","tags":"pages","title":"frac_13"},{"url":"pages/gallery/","text":"","tags":"pages","title":"Gallery"},{"url":"pages/bio/","text":"A self motivated and passionate engineer who is interested in computer graphics, simulations, machine intelligence, computer vision and everything in between. On the other side I am very much into video games(all kind), music(all kind), visual art(all kind) and (philosophy of)sciences(almost all kind). I had a very boring start when I joined Bachelors in Mechanical, IIT Roorkee. Although it is an awesome place, I found out that my passions don't lie in the gear box, (or the machining lab for that matter). Pretty soon I found myself consuming lots of games and music. Started playing with some game engines and created a very basic 3D Flight Simulator . And that was all I did in my time there(apart from the other things that engineering students do). Fortunately, I got hired at VizExperts India , an information visualization company with roots in desktop graphics. That was the time when I realized how cool programming can be!!! From there on, it has been quite a journey. We primarily worked on our in-house 3D GIS based planning and simulation engine built on an open source renderer, OpenSceneGraph which has been called with different names since then, we will just call it GeorbIS . I worked on everything from frontend UI framework to rendering and simulation engine to 3D computational filters. It really brought back all the lost love i had for classical physics in the form of Matrix transformations.Did a lot of app level features with direct involvement with the clients. I also had a small role in VizSim platform, a distributed simulation engine that provides real time sensor data fusion and visualization. There I got introduced to OpenCV and computer vision in general and implemented my first object detection and tracking pipeline. It was very cool. After that, we started working on VizGame , a gamified training platform built on top of Unreal Engine . It used our GeorbIS framework as a data backend for creating procedurally populated, highly realistic terrains with GIS data. Here, again, my role went from laying out the Game design to implementing multiplayer(Co-presence) in VR. And by this time I was also involved in mentoring other people who were like me a few years back. In the mean time I was getting more and more interested towards data science and machine intelligence. So, I decided to pursue my interests with self learning, with a vision of somehow managing to merge my experience with computer graphics and simulation to the field of computer vision and robotics. Lets see how far we can get.!!!! For a more professional looking resume, click here .","tags":"bio","title":"Bio"},{"url":"posts/books/the-algorithms-design-manual-set-and-string-problems/","text":"Set and String Problems Set Cover Input description: A collection of subsets \\(S = {S_1, \\ldots , S_m}\\) of the universal set \\(U = {1, \\ldots , n}\\) . Problem description: What is the smallest subset \\(T\\) of \\(S\\) whose union equals the universal set—i.e. , \\( \\cup_{i=1}&#94;{|T|} T_i = U\\) ? Several variations of set problem, Are you allowed to cover elements more than once? Distinction between set cover and set packing. Are your sets derived from the edges or vertices of a graph? Can be modeled as vertex cover instead. Do your subsets contain only two elements each? You are in luck. Becomes NP-complete with three variables. Do you want to cover elements with sets, or sets with elements Greedy is the most natural and effective heuristic for set cover. Simulated annealing is likely to produce somewhat better set covers. Backtracking can be used to guarantee an optimal solution, but is computationally very expensive. Alternative, integer programming formulation of set cover. Related : Matching , vertex cover , set packing Set Packing Input description: A set of subsets \\(S = {S_1, \\ldots , S_m}\\) of the universal set \\(U = {1, \\ldots , n}\\) . Problem description: Select (an ideally small) collection of mutually disjoint subsets from \\(S\\) whose union is the universal set. Must every element appear in exactly one selected subset? This will be NP-complete is yes. Does each element have its own singleton set? What is the penalty for covering elements twice? The same heuristics as in set cover work here. Related : Independent set , set cover String Matching Input description: A text string \\(t\\) of length \\(n\\) . A pattern string \\(p\\) of length \\(m\\) . Problem description: Find the first (or all) instances of pattern \\(p\\) in the text. Arises in almost all text-processing applications. Issues to look for, Are your search patterns and/or texts short? Simple \\(O(mn)\\) would suffice. What about longer texts and patterns? Preprocessing the search pattern can help improve the jumps on finding a mismatch. Do I expect to find the pattern or not? Check backwards and perform better jumps. Will you perform multiple queries on the same text? Use suffix trees or suffix arrays. Will you search many texts using the same patterns? Build finite automaton. Also useful when searching for regular expressions. What if our text or pattern contains a spelling error? Use Approximate string matching algorithms. Implementations : Strmat, grep and variants, Boost string algorithms. Related : Suffix trees , approximate string matching Approximate String Matching Input description: A text string \\(t\\) and a pattern string \\(p\\) . Problem description: What is the minimum-cost way to transform \\(t\\) to \\(p\\) using insertions, deletions, and substitutions? A fundamental problem because we live in an error-prone world. Dynamic programming provides the basic approach. \\(D[i,j]\\) = cost of editing \\(i\\) characters of string \\(p\\) into first \\(j\\) characters of text \\(t\\) . The recurrence selected the minimum of, if \\(p_i = t_j\\) then \\(D[i-1, j-1]\\) else $D[i-1, j-1] + $ substitution cost. \\(D[i-1, j] + $ deletion cost of $p_j\\) . \\(D[i, j+1] + $ deletion cost of $t_j\\) . Several issues remain however, Do I match the pattern against the full text, or against a substring? How should I select the substitution and insertion/deletion costs? How do I find the actual alignment of the strings? What if the two strings are very similar to each other? Is your pattern short or long? You can use bit-parallel algorithms, which can be many times faster than dynamic programming. How can I minimize the required storage? Quadratic space required by dp table is only required if you need to reconstruct the actual sequence alignment. Should I score long runs of indels differently? Does similarity mean strings that sound alike? Implementations : agrep, nrgrep, TRE Related : String matching , longest common substring Text Compression Input description: A text string \\(S\\) . Problem description: Create a shorter text string \\(S'\\) such that \\(S\\) can be correctly reconstructed from \\(S'\\) . Decreasing secondary storage prices seem to have increased interest in data compression, because there is more data to compress. Several questions arise while selecting the right compression algorithm, Must we recover the exact input text after compression? Lossy vs Lossless encoding. Documents can't use lossy compression. Images/videos can. Can I simplify my data before I compress it? Any information that can be removed would help in compression later. Does it matter whether the algorithm is patented? Just something to look out for. How do I compress image data? Use JPEG. Must compression run in real time? Depends on the application. Several dozen algorithms are available, Huffman codes , greedy variable length encoding based on frequency. Lempel-ziv algorithms (LZV compression), just use this. Implementations : gzip , bzip2 Related : Shortest common superstring , cryptography Cryptography Input description: A plaintext message \\(T\\) or encrypted text \\(E\\) , and a key \\(k\\) . Problem description: Encode \\(T\\) (decode \\(E\\) ) using \\(k\\) giving \\(E\\) ( \\(T\\) ). Foundation for the modern internet. Three classes of cryptosystems everyone should be aware of, Ceaser shifts , substitute on character for something else. Easy to break using statistical analysis. Block shuffle ciphers , DES(now crackable ), AES, Triple DES. Public key cryptography , RSA Never try to roll out your own novel cryptosystem. It is not going to work. Certain problems related to cryptography, How can I validate the integrity of data against random corruption? use checksums, cyclic redundancy check. How can I validate the integrity of data against deliberate corruption? MD5, SHA-256. How can I prove that a file has not been changed? Digital signatures. How can I restrict access to copyrighted material? Stream ciphers are used, but are needed to be protected by the law. Implementations : Nettle, Crypto++ Related : Factoring and primality testing , text compression Finite State Machine Minimization Input description: A deterministic finite automaton \\(M\\) . Problem description: Create the smallest deterministic finite automaton \\(M'\\) such that \\(M'\\) behaves identically to \\(M\\) . Useful in control systems, compilers, software and hardware design. Minimizing the state machine can reduce both storage and execution costs. Consider three different problems, Minimizing deterministic finite state machine , be removing redundancy. Constructing deterministic machines from nondeterministic machines , this can however be worse than NP-complete, as the number of states blow up exponentially. Constructing machines from regular expressions , can construct either NFA or DFA. Related : Satisfiability , string matching Longest Common Substring/Subsequence Input description: A set \\(S\\) of strings \\(S_1, \\ldots , Sn\\) . Problem description: What is the longest string \\(S'\\) such that all the characters of \\(S'\\) appear as a substring or subsequence of each \\(S_i, 1 \\le i \\le n\\) ? Arises when finding similarity among multiple sequences. Issues arising include, Are you looking for a common substring? Are you looking for a common scattered subsequence? What if there are relatively few sets of matching characters? What if the strings are permutations? What if we have more than two strings to align? Related : Approximate string matching , shortest common superstring Shortest Common Superstring Input description: A set of strings \\(S = {S_1, \\ldots , S_m}\\) . Problem description: Find the shortest string \\(S'\\) that contains each string \\(S_i\\) as a substring of \\(S'\\) . This can be useful in data compression, DNA sequence assembly. Finding a super-sequence is not a problem, but finding the shortest super-sequence is NP-complete. Easily reducible to asymmetric TSP problem. A greedy heuristic: find the substrings with maximum overlap and merge them, repeat. Related : Suffix trees , text compression if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"The Algorithms Design Manual, Set and String Problems"},{"url":"posts/books/the-algorithms-design-manual-computational-geometry/","text":"Computational Geometry Robust Geometric Primitives Input description: A point \\(p\\) and line segment \\(l\\) , or two line segments \\(l_1\\) , \\(l_2\\) . Problem description: Does \\(p\\) lie over, under, or on \\(l\\) ? Does \\(l_1\\) intersect \\(l_2\\) ? Even simple operations like line(segment) intersection can have many different cases including numerical stability and geometric degeneracy issues. Three primary approaches for dealing with degeneracy , Ignore it : Most common and recommended approach. Fake it : Random data perturbation so that it becomes non-degenerate. Deal with it : Write code to handle special degenerate cases Problems with overflows and numerical precision, Integer arithmetic : Force all the point coordinates to be fixed-size integers. Double precision reals : You may be able to avoid overflow and precision issues by using double precision for all the intermediate calculations and your data types. Arbitrary precision arithmetic : This is certain to be correct and slow. A set of low level geometric primitives : Area of a triangle $$\\begin{array}0 2.A(t) &=& \\begin{vmatrix}a_x & a_y & 1\\\\ b_x & b_y & 1 \\\\ c_x & c_y & 1\\end{vmatrix} \\\\&= &a_xb_y - a_yb_x + a_yc_x - a_xc_y + b_xc_y - c_xb_y\\end{array}$$ This formula extends to \\(d\\) -dimensions, replacing \\(2\\) with \\(d!\\) . Above-below-on test : On which side of a line does a point lie? Line segment intersection : A line segment intersects a line iff its end points lie on different sides of the line. In-circle test : Check whether 4 given points lie on a circle, $$\\begin{array}0 incircle(a,b,c,d) &=& \\begin{vmatrix}a_x & a_y & a_x&#94;2+a_y&#94;2&1\\\\ b_x & b_y & b_x&#94;2+b_y&#94;2 & 1 \\\\ c_x & c_y & c_x&#94;2+c_y&#94;2 & 1\\\\d_x & d_y & d_x&#94;2+d_y&#94;2 & 1\\end{vmatrix} \\\\\\end{array}$$ This will return 0 if all four points are cocircular, a positive value if \\(d\\) is inside the circle, and negative if \\(d\\) is outside. Implementations : CGAL, LEDA. Related : Intersection detection , maintaining arrangement . Convex Hull Input description: A set \\(S\\) of \\(n\\) points in \\(d\\) -dimensional space. Problem description: Find the smallest convex polygon (or polyhedron) containing all the points of \\(S\\) . The most important problem in elementary computational geometry, just as sorting is the most important elementary problem in combinatorial algorithms. Serves as a first preprocessing step to many geometric algorithms. As many convex hull algorithms as sorting algorithms. How to choose, How many dimensions are you working with? Certain assumptions break down in higher dimensions. For higher dimensions use a library method. Is your data given as vertices or half-spaces? These are dual of each other. How many points are likely to be on the hull? Topmost, leftmost, bottom-most and rightmost points would certainly be on the hull, and points lying in the region enclosed by these vertices can be discarded in one sweep. This can also be used in higher dimensions. How do I find the shape of my point set? Convex hulls would loose most of the shape information details. Graham scan is the primary algorithm. Start with a point \\(p\\) known to be on the hull. Sort all the points by their angular coordinates around \\(p\\) . Starting with the smallest, move counter-clockwise, adding points to the hull. Remove last point if they form a concavity , i.e. an angle greater than \\(180°\\) . Total time, \\(O(n \\lg n)\\) Implementations : CGAL, LEDA, Qhull Related : Sorting , Vornoi diagrams Triangulation Input description: A set of points or a polyhedron. Problem description: Partition the interior of the point set or polyhedron into triangles. Useful in finite element analysis to computer graphics. Some specific issues arising in triangulation, Are you triangulating a point set or a polygon? First find the convex hull of points. Does the shape of the triangles in your triangulation matter? How can I improve the shape of a given triangulation? By edge-flip ping internal triangles. What dimension are we working in? NP-complete if we dont cant add extra vertices. What constraints does the input have? Are you allowed to add extra points or move input vertces? Implementations : CGAL, LEDA, and more. Related : Vornoi diagrams , polygon partitioning Vornoi Diagrams Input description: A set \\(S\\) of points \\(p_1, \\ldots , p_n\\) . Problem description: Decompose space into regions around each point such that all points in the region around \\(p_i\\) are closer to \\(p_i\\) than any other point in \\(S\\) . Vornoi diagrams represent the region of influence around each of a given set of sites. They have a surprising variety of applications, Nearest Neighbour search : Select the cell. Facility location : Choose a vertex. Largest empty circle : Choose a vertex. Path planning : Stick to the edges. Quality triangulations : Delauny triangulations can be easily constructed as dual of the Voirnoi diagram. Each edge is a perpendicular bisector between two points in \\(S\\) . Fortune's sweepline algorithm runs in optimal \\(O(n\\log n)\\) . Interesting relationship between convex hulls(in \\(d+1\\) dimensions) and vornoi diagrams(in \\(d\\) dimensions) : Project each point \\(E&#94;d(x_1,x_2, \\ldots , x_d)\\) to point \\((x_1, x_2, \\ldots, x_d, \\sum_{i=1}&#94;{d}x_i&#94;2)\\) , take the convex hull in \\(d+1\\) dimensions and project back to \\(d\\) dimensions. This is the best way to construct Vornoi diagrams in higher dimensions. Variations of standard Vornoi diagrams that arise in practice, Non-Euclidean distance metric Power diagrams : Non uniform power of influence over space. K-th order and furthest-site diagrams : Implementations : CGAL, LEDA, Qhull, and more. Related : Nearest neighbor search , point location , triangulation Nearest Neighbor Search Input description: A set \\(S\\) of \\(n\\) points in \\(d\\) dimensions; a query point \\(q\\) . Problem description: Which point in \\(S\\) is closest to \\(q\\) ? Arises in numerous applications across the board. Is also important in classification and image compression(vector-quantization). Issues arising in nearest-neighbor search include: How many points are you searching? Only when the number of points is high, it pays to consider sophisticated approaches. How many dimensions are you working in? Gets progressively harder as the dimensionality increases. \\(kd-\\) tree data structure can be very useful here, but only upto a certain number of dimensions(20). Vornoi diagrams also prove to be an efficient data structure, but often become unusable at higher dimensions. Do you really need the exact nearest neighbor? Heuristics can give a reasonable answer fairly quickly. Dimensionality reduction also becomes very handy. Is your data set static or dynamic? Static structures can be more efficient. Implementations : ANN, KDTREE 2, CGAL, LEDA, and more,... Related : Kd-trees , Vornoi diagrams , range search Range Search Input description: A set \\(S\\) of \\(n\\) points in \\(E_d\\) and a query region \\(Q\\) . Problem description: What points in \\(S\\) lie within \\(Q\\) ? Arises often in database and GIS applications. The difficulty of range search depends on the following factors, How many range queries are you going to perform? - Brute force works just fine when the number ois small. What shape is your query polygon? - Axis-parallel rectangles are easiest to query against. Use decomposition for non-convex polygons. How many dimensions? Is your point set static? Can I just count the number of points in a region, or do I have to identify them? Implementations : CGAL, LEDA, ANN, Ranger Related : Kd-trees , point location Point Location Input description: A decomposition of the plane into polygonal regions and a query point \\(q\\) . Problem description: Which region contains the query point \\(q\\) ? Variations to the simple problem, Is a given point inside or outside of polygon P? Count how many times a ray originating from the query point intersects the polygon. How many queries must be performed? It could be more beneficial to construct a grid like structure. How complicated are the regions of your subdivision? Either perform a triangulation first, or compute a grid-like structure. How regularly sized and spaced are your regions? Use (irregular) grid like structures. How many dimensions will you be working in? For higher dimensions, \\(Kd\\) -trees might be a better choice. Am I close to the right cell? Implementations : CGAL, LEDA, ANN, Arrange Related : Kd-trees , Vornoi diagrams , nearest neighbor search Intersection Detection Input description: A set \\(S\\) of lines and line segments \\(l_1, \\ldots , l_n\\) or a pair of polygons or polyhedra \\(P_1\\) and \\(P_2\\) . Problem description: Which pairs of line segments intersect each other? What is the intersection of \\(P_1\\) and \\(P_2\\) ? Numerous applications from collision detection to error checking in VLSI design. Issues arising in intersection detection include, *Do you want to compute the intersection or just report it? Detection can be substantially easier. Are you intersecting lines or line segments? Lines(or rays) can be easier than line segments. How many intersection points do you expect? Can you see point x from point y ? Visibility/Occlusion queries. Are the intersecting objects convex? Are you searching for intersections repeatedly for the same basic objects? Using simpler bounding boxes can help improve the overall performance. Planar sweep algorithms can be used to efficiently compute the intersections for a set of line segments. Implementations LEDA, CGAL, and more. Related : Maintaining arrangements , motion planning Bin Packing Input description: A set of \\(n\\) items with sizes \\(d_1, \\ldots , d_n\\) . A set of \\(m\\) bins with capacity \\(c_1, \\ldots , c_m\\) . Problem description: Store all the items using the smallest number of bins. Arises in a variety of packaging and manufacturing problems. Eg. manufacturing widgets cut from sheet metal pr pants cut from cloth. To minimize cost and waste, is a bin-packing variant called cutting-stock problem. Even the most elementary sounding problems of bin-packing are NP-complete(Integer partition). Factors affecting the choice of heuristic, What are the shapes and sizes of the objects? One dimensional bin-packing(or two dimensional boxes with same width) becomes a special case of knapsack problem. Are there constraints on the orientation and placement of objects? Different boxes may have different constraints. Many people just ignore the constraints, but you may not be able to. Is the problem on-line or off-line? We can do a better job if we know all the constraints beforehand, and we can plan ahead. Biggest objects first, turns out to be the best heuristics. For non-rectangular shapes, bounding boxes can be used. More sophisticated algorithms are available. Related : Knapsack problem , set packing , Medial-Axis Transform Input description: A polygon or polyhedron \\(P\\) . Problem description: What are the set of points within \\(P\\) that have more than one closest point on the boundary of \\(P\\) ? Useful in thinning a polygon, or as is sometimes said, finding its skeleton . The skeleton is useful in many contexts, like shape reconstruction and motion planning. Always a tree for polygons(without holes). DP can be used to find the edit-distance between two skeletons. Two distinct images, Geometric data : Vornoi diagram of line segments can be used. The portion of the vornoi diagram that lies in the polygon is the skeleton. Image data : Geometric approach can be used by converting the image data into geometric regions. Pixel-based approaches can also be used, but they tend not to be very accurate, because of the differences in the continuos and discrete world. Implementations : CGAL, VRNOI, Related : Vornoi diagrams , minkowski sum Polygon Partitioning Input description: A polygon or polyhedron \\(P\\) . Problem description: Partition \\(P\\) into a small number of simple (typically convex) pieces. Important preprocessing step for many geometric algorithms. Several flavors of polygon partitioning, Should all the pieces be triangles? This would not produce the smallest number of partitions. Do I want to cover or partition my polygon? Partitioning only allows mutually non-overlapping pieces. Am I allowed to add extra vertices? Adding (steiner) vertices may result in smaller number of partitions(but with a more complicated algorithm). Hertel-Mehlhorn heuristic , start with an arbitrary triangulation, and delete chords until it leaves only convex pieces. DP finds the absolute minimum partitions in \\(O(n&#94;4)\\) . Related : Triangulation , set cover Simplifying Polygons Input description: A polygon or polyhedron \\(p\\) , with \\(n\\) vertices. Problem description: Find a polygon or polyhedron \\(p'\\) containing only \\(n'\\) vertices, such that the shape of \\(p'\\) is as close as possible to \\(p\\) . Two primary applications, Cleaning up a noisy representation of a shape, Data compression, reduce detail on large objects(LOD) Several issues arise, Do you want the convex hull? Can be useful in some applications(mmotion planning), and can be disastrous in some(OCR system). Am I allowed to insert or just delete points? Local modifications to reduce the vertex count are done. Most robust heuristics move the vertices around to cover up the gaps created by deletions. Must the resulting polygon be intersection-free? Simplicity(non-self intersection) can be difficult to achieve for some shapes. Are you given an image to clean up instead of a polygon to simplify? Conventionally, Fourier transform is used to clean up images. Related : Fourier transform , convex hull Shape Similarity Input description: Two polygonal shapes, \\(P_1\\) and \\(P_2\\) . Problem description: How similar are \\(P_1\\) and \\(P_2\\) ? We seek to identify the unknown shapes by matching them to the most similar shape models. What similar means can be application dependent. Possible approaches are, Hammming distance , measures the area of symmetric difference between the two polygons. Zero for identical and aligned polygons. Problem is simply finding the union and intersection of polygons, further simplified if rotation is constrained. However, this only captures a crude notion of shape, and might be ineffective in most applications. Hausdorff distance , identifies the maximum distance for two points on \\(P_1\\) and \\(P_2\\) . Comparing skeletons , this problem then reduces to subgraph isomorphism. Support Vector Machines , or other learning based approaches such as neural networks . Related : Graph isomorphism , thinning Motion Planning Input description: A polygonal-shaped robot starting in a given position \\(s\\) in a room containing polygonal obstacles, and a goal position \\(t\\) . Problem description: Find the shortest route taking \\(s\\) to \\(t\\) without intersecting any obstacles. Robots, computer animation, molecular docking, and more,.. Many factors govern the complexity of motion planning problems, Is your robot a point? Build the visibility graph using the polygons and the source and target vertices. Perform Dijkstra's shortest path from \\(s\\) to \\(t\\) . What motions can your robot perform? Size of the bot, degrees of freedom . Can you simplify the shape of your robot? Anything you can simplify will be a big win. Try replacing it with an enclosing disc. Are motions limited to translation only? Are the obstacles known in advance? Implementations : The Motion Planning Toolkit *, CGAL Related : Shortest path , Minkowski sum Maintaining Line Alignments Input description: A set of lines and line segments \\(l_1, \\ldots , l_n\\) . Problem description: What is the decomposition of the plane defined by \\(l_1, \\ldots , l_n\\) ? Examples, Degeneracy testing Satisfying the maximum number of linear constraints Issues arising in arrangements include, What is the right way to construct a line arrangement? Incremental? How big will your arrangements be? What do you want to do with your arrangement? Does your input consist of points instead of lines? Points represent the dual problem, $$L : y = 2ax - b \\leftrightarrow p : (a,b)$$ This is surprisingly the same problem in many cases. Related : Intersection detection , point location Minkowski Sum Input description: Point sets or polygons \\(A\\) and \\(B\\) , containing \\(n\\) and \\(m\\) vertices respectively. Problem description: What is the convolution of \\(A\\) and \\(B\\) — i.e. , the Minkowski sum \\(A + B = {x + y|x \\in A, y \\in B}\\) ? Very interesting geometric operations that can fatten objects in appropriate ways. Eg. For robot motion planning, transform the space by taking Minkowski sum of the obstacles and the shape of the robot, reducing the problem to point robots. Also helpful in shape simplification and smoothing. Issues arising in Minkowski sum, Are your objects rasterized images or explicit polygons? Polygonal representations can get more complicated. Do you want to fatten your object by a fixed amount? Just use a circular disk with offset as radius. Are your objects convex or non-convex? This can become ugly and majestic with surprising results for non-convex polygons. Related : Thinning , motion planning , simplifying polygons if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"The Algorithms Design Manual, Computational Geometry"},{"url":"posts/books/the-algorithms-design-manual-graph-problemshard-problems/","text":"Graph Problems : Hard Problems Dealing with NP-completeness. Clique Input description: A graph \\(G = (V,E)\\) . Problem description: What is the largest \\(S \\subset V\\) such that for all \\(x, y \\in S,\\, (x, y) \\in E\\) ? Finding the maximum clique is NP-complete, as hard as it gets. And, provably hard to approximate to withing the factor of \\(n&#94;{1/2-\\epsilon}\\) . What can we do about it? Will a maximal clique suffice? This is a clique that can not be enlarged by adding another vertex. Can be done in \\(O(n+m)\\) What if I will settle for a large dense subgraph? Can be done in \\(O(n+m)\\) . What if the graph is planar? Cannot have a clique of size larger than 4. For an exact solution, use an exhaustive search with backtracking and pruning. For an efficient solution, use randomized techniques such as simulated annealing. Implementations : Cliquer for C. Related : Independent set , vertex cover . Independent Set Input description: A graph \\(G = (V,E)\\) . Problem description: What is the largest subset \\(S\\) of vertices of \\(V\\) such that for each edge \\((x,y) \\in E\\) , either \\(x \\notin E\\) or \\(y \\notin E\\) ? Choose mutually separated vertices. Closely related to clique (on complement graph \\(G'\\) ) and vertex coloring (each color class defines an independent set) Randomized algorithms work well. Simple linear time algorithms are available for trees. Related : Clique , vertex coloring , vertex cover . Vertex Cover Input description: A graph \\(G = (V,E)\\) . Problem description: What is the smallest subset of \\(S \\subset V\\) such that each edge \\((x, y) \\in E\\) contains at least one vertex of \\(S\\) ? Special case of set cover and relatively lightweight. Closely related to independent set : if \\(S\\) is the vertex cover, \\(V-S\\) must be an independent set. Simple heuristics perform well. Related : Independent set , set cover Travelling Salesman Problem Input description: A weighted graph \\(G\\) . Problem description: Find the cycle of minimum cost, visiting each vertex of \\(G\\) exactly once. The most notorious NP-complete problem, mostly because of its general nature and explainability. Several issues arise in TSPs, Is the graph unweighted? The problem reduces to finding a Hamiltonian cycle . Does your input satisfy the triangle inequality? TSP heuristics work much better if they do. Are you given \\(n\\) points as input or a weighted graph? Geometric instances are easier to represent, eliminating the need for \\(n \\times n\\) matrix, satisfy triangle inequality and we can also take advantage of geometric data structures like kd-trees to speed up our searches. Can you visit a vertex more than once? Things become simpler. Is your distance function symmetric? Asymmetric problem is much harder to approximate. How important is it to find the optimal tour? Heuristics often suffice. Choice of heuristics, Minimum Spanning Trees, Incremental insertion methods K-optimal tours Implementations : Concorde Related : Hamiltonian cycle , minimum spanning tree , convex hull Hamiltonian Cycle Input description: A graph \\(G = (V,E)\\) . Problem description: Find a tour of the vertices using only edges from \\(G\\) , such that each vertex is visited exactly once. A special case of TSP. Several possible lines of attack, Is there a serious penalty for visiting vertices more than once? We can find better heuristics if not. Am I seeking the longest path in a directed graph (DAG)? Linear time solutions exist. Is my graph dense? Sufficiently dense graphs almost always contain a Hamiltonian cycle. Are you visiting all the vertices or all the edges? Backtracking with pruning is the only possible correct solution. Related : Eulerian cycle , travelling salesman Graph Partition Input description: A (weighted) graph \\(G = (V,E)\\) and integers \\(k\\) and \\(m\\) . Problem description: Partition the vertices into \\(m\\) roughly equal-sized subsets such that the total edge cost spanning the subsets is at most \\(k\\) . Graph partitioning arises in many divide-and-conquer algorithms. Graph partition also arises when we need to cluster the vertices into logical components. It has different flavors, Minimum cut set Graph partition, equal sized pieces. Maximum cut, (NP-complete) Heuristics with randomization, particularly simulated annealing are almost certain to produce good results. Apply recursively for more than two partitions. Related : Edge/vertex connectivity , network flow Vertex Coloring Input description: A graph \\(G = (V,E)\\) . Problem description: Color the vertices of \\(V\\) using the minimum number of colors such that \\(i\\) and \\(j\\) have different colors for all \\((i,j) \\in E\\) . Register allocation in compiler optimization is a canonical application of coloring. The smallest number of colors sufficient to vertex-color a graph is its chromatic number . Special cases of interest, Can I color the graph using only two colors? i.e. a bipartite graph. Checking this is easy. Is the graph planar, or are all vertices of low degree? Every planar graph can be vertex colored using at most four distinct colors. Four coloring is easy. three coloring is NP-complete. Is this an edge coloring problem? Edge coloring is relatively easy to approximate. Heuristics using incremental methods work very well. Simulated annealing is likely to be even more effective. Related : Independent set , edge coloring Edge Coloring Input description: A graph \\(G = (V,E)\\) . Problem description: What is the smallest set of colors needed to color the edges of \\(G\\) such that no two same-color edges share a common vertex? The National Football League solves such an edge-coloring problem each season to make up its schedule. The minimum number of colors needed to edge color a graph is called its edge-chromatic number or chromatic index . Related : Vertex coloring , scheduling Graph Isomorphism Input description: Two graphs, \\(G\\) and \\(H\\) . Problem description: Find a (or all) mapping \\(f\\) from the vertices of \\(G\\) to the vertices of \\(H\\) such that \\(G\\) and \\(H\\) are identical; i.e. , \\((x,y)\\) is an edge of \\(G\\) iff \\((f(x),f(y))\\) is an edge of \\(H\\) . Pattern recognition reduces to this sometimes, identifying molecules is an isomorphism testing problem. Automorphism provides a great deal of information about symmetries in the graph. Several variants arise in practice, Is graph \\(G\\) contained in graph \\(H\\) ? Subgraph isomorphism . These can be even harder than vanilla graph isomorphism. Are your graphs labeled or unlabeled? Use pruning extensively. Are you testing whether two trees are isomorphic? Faster algorithms exists for trees and planar graphs. How many graphs do you have? Indexing can help asymptotically. No polynomial time algorithm is known, but neither is it known to be NP-complete. Backtracking and pruning is the way to go. More efficient approach, partition the vertices into equivalence classes on the basis of, Vertex degree, Shortest path matrix Counting k-length paths Implementations : Nauty (C), VFLib, GraphGrep, LEDA. Related : Shortest path , string matching Steiner Tree Input description: A graph \\(G = (V,E)\\) . A subset of vertices \\(T \\in V\\) . Problem description: Find the smallest tree connecting all the vertices of \\(T\\) . The Steiner tree problem is distinguished from the minimum spanning tree (MST) problem in that we are permitted to construct or select intermediate connection points to reduce the cost of the tree. Steiner tree construction include, How many points do you have to connect? Is the input a set of geometric points or a distance graph? Are there constraints on the edges we can use? Do I really need an optimal tree? Its a hard problem! Use exhaustive search with extensive pruning. How can I reconstruct Steiner tree vertices I never knew about? Find an MST and improve it. Alternatively, start with shortest path for two terminals, for the remaining terminals, find the shortest path to intermediate vertices on the path and add this path to the tree. Related : Minimum spanning trees , shortest path Feedback Edge/Vertex Set Input description: A (directed) graph \\(G = (V,E)\\) . Problem description: What is the smallest set of edges \\(E'\\) or vertices \\(V'\\) whose deletion leaves an acyclic graph? Feedback set problems arise because many things are easier to do on directed acyclic graphs (DAGs) than general digraphs. For a scheduling problem, if there are cyclic constraints, In the feedback edge (or arc) set problem, we drop individual precedence constraints. In the \\(feedback vertex\\) set problem, we drop entire jobs and all constraints associated with them. Similar considerations are involved in eliminating race conditions from electronic circuits. Also called maximum acyclic subgraph problem . Issues in feedback set problem, Do any constraints have to be dropped? Nothing to delete if its already a DAG. But if there is, the problem is NP-complete. How can I find a good feedback edge set? How can I get a good feedback vertex set? What if I want to break all cycles in an undirected graph? Implementation : GRASP, GOBLIN , Stanford GraphBase. Related : Bandwidth Reduction , topological sorting , scheduling if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"The Algorithms Design Manual, Graph Problems(Hard Problems)"},{"url":"posts/books/the-algorithms-design-manual-graph-problemspolynomial-time/","text":"Graph Problems : Polynomial-Time Connected Components Input description: A directed or undirected graph \\(G\\) . Problem description: Identify the different pieces or components of \\(G\\) , where vertices \\(x\\) and \\(y\\) are members of different components if no path exists from \\(x\\) to \\(y\\) in \\(G\\) . Associated problems Identify natural clusters in a set of items. Also used as a preprocessing step to test whether a graph is connected. Other notions of connectivity , What if my graph is connected? Weekly or strongly connected? Weekly connected components can be identified by a single DFS or BFS traversal. For strongly connected components, check whether the graph is weekly connected, then check again on the reversed graph. What is the weakest point in my graph/network? Is the graph a tree? How can I find a cycle if cone exists? Implementations C++ : Boost Graph Library, LEDA Java : JUNG, JGraphT Related : Edge-vertex connectivity , shortest path Topological Sort Input description: A directed acyclic graph \\(G = (V,E)\\) , also known as a partial order or poset . Problem description: Find a linear ordering of the vertices of \\(V\\) such that for each edge \\((i,j) \\in E\\) , vertex \\(i\\) is to the left of vertex \\(j\\) . Arises as a subproblem in most algorithms on DAGs. Plays the same role for DAGs as depth-first search plays for general graphs. Can be used to schedule tasks under precedence constraints. Only DAGs can be topologically sorted, any directed cycle would provide an inherent contradiction to linear order of tasks. Every DAG can be topologically sorted. DAGs can be often topologically sorted in many different ways. Simple linear time algorithm : Find source vertices(zero in-degree) using DFS. Eliminate source vertices and edges, find new source vertices and place then next in the schedule. Repeat. Special considerations, What if I need all the linear extensions, instead of just one of them? NP-hard, use backtracking. What if your graph is not acyclic? Remove the smallest set of edges(feedback arc set) or vertices(feedback vertex set) so as to create a DAG. Also NP-hard. Implementations : C++ : Boost Graph Library, LEDA Java : JDSL, JGraphT Related : Sorting , feedback edge/vertex set Minimum Spanning Tree Input description: A graph \\(G = (V,E)\\) with weighted edges. Problem description: The minimum weight subset of edges \\(E' \\subset E\\) that form a tree on \\(V\\) . MST defines the cheapest subset of edges that keep the graph in one connected component. Can be compute quickly and easily, and create a sparse subgraph that reflects a lot about the original graph. They provide a way to identify clusters in sets of points. They can be used to give approximate solutions to hard problems such as Steiner tree and traveling salesman. As an educational tool, MST algorithms provide graphic evidence that greedy algorithms can give provably optimal solutions. Kruskal's algorithm . Each vertex starts as a separate tree and these trees merges together by repeatedly adding the lowest cost edge that spans two distinct subtrees (i.e. , does not create a cycle). Efficiently implemented using union-find data structure. Prim's algorithm . Starts with an arbitrary vertex and grows a tree from it, repeatedly finding the lowest-cost edge that links some new vertex into this tree. Implemented using priority queues. Boruvka's algorithm Rests on the observation that the lowest-weight edge incident on each vertex must be in the minimum spanning tree. The union of these edges will result in a spanning forest of at most \\(n/2\\) trees. Now for each of these trees \\(T\\) , select the edge \\((x,y)\\) of lowest weight such that \\(x \\in T\\) and $y \\notin T $. Repeat till a single tree is created. Questions to ask, Are the weights of all the edges of your graph identical? MST can be found using DFS or BFS. Should I use Prim's or Kruskal's algorithm? Prim's algorithm is faster on dense graphs, while Kruskal's is faster on sparse graphs What if my input is points in the plane, instead of a graph? First run Delaunay triangulation, then find MST on that graph. How do I find a spanning tree that avoids vertices of high degree? NP-Complete, identical to Hamiltonian path problem. However efficient approximation algorithms exist. Implementations : Boost, LEDA, and more. Related : Steiner tree , travelling salesman Shortest Path Input description: An edge-weighted graph \\(G\\) , with vertices \\(s\\) and \\(t\\) . Problem description: Find the shortest path from \\(s\\) to \\(t\\) in \\(G\\) . Applications , Most obvious applications arise in transportation or communications. Image segmentation . requires modelling the graph with proper transitions. Differentiate homophones , words that sound similar. For informative visualization of graphs. Keep the center at the center . Dijkstra's algorithm : single source shortest path on positively weighted graphs. Questions to ask, Is your graph weighted or unweighted? If unweighted, a simple BFS would do. If weighted use Dijkstra's algorithm. Does your graph have negative cost weights? Use Bellman-Ford algorithm . If negative cost cycles are present, then the problem is ill defined. Is your input a set of geometric obstacles instead of a graph? Dijkstra's algorithm would work, but there are faster algorithms for this setting. Is your graph acyclic? i.e. a DAG? Use topological sort. Do you need the shortest path between all pairs of points? Use Floyd-Warshall algorithm How do I find the shortest cycle in a graph? Floyd's algorithm can do that. Finding longest cycle is similar to Hamiltonian cycle, and is NP-complete. Other graph properties are related, Eccentricity of a vertex is the shortest-path distance to the farthest vertex. Radius of a graph is the smallest eccentricity . Center is the set of vertices whose eccentricity is the radius. Diameter of a graph is the maximum eccentricity of any vertex. Implementations : C++ : MLB, Boost, LEDA and more. Related : Network flow , motion planning Transitive Closure and Reduction Input description: A directed graph \\(G = (V,E)\\) . Problem description: For transitive closure , construct a graph \\(G' = (V, E')\\) with edge \\((i, j) \\in E'\\) iff there is a directed path from \\(i\\) to \\(j\\) in \\(G\\) . For transitive reduction , construct a small graph \\(G' = (V, E')\\) with a directed path from \\(i\\) to \\(j\\) in \\(G'\\) iff there is a directed path from \\(i\\) to \\(j\\) in \\(G\\) . Transitive closure can be thought of as establishing a data structure that makes it possible to solve reachability questions efficiently. The simplest algorithm just performs a breadth-first or depth-first search from each vertex and keeps track of all vertices encountered. But this degenerates to cubic time on dense graphs. Can also use Warshall's algorithm , or use matrix multiplication. The problem can be greatly reduced if we only consider the strongly connected components. Transitive reduction (also known as minimum equivalent digraph ) is the inverse operation of transitive closure, reducing the number of edges, while maintaining identical reachability properties. Primary application in space minimization, reducing redundancy, remove clutter while visualization. However, there are multiple identifying formulations of the problem A linear-time, quick-and-dirty transitive reduction algorithm identifies the strongly connected components of G, replaces each by a simple directed cycle, and adds these edges to those bridging the different components. Implementations : Boost Graph, LEDA, Graphlib(Transitivity) and more. Related : Connected components , shortest path Matching Input description: A (weighted) graph \\(G = (V,E)\\) . Problem description: Find the largest set of edges \\(E'\\) from \\(E\\) such that each vertex in \\(V\\) is incident to at most one edge of \\(E'\\) . The basic matching problem can be formulated in many different forms while remaining essentially the same assignment problem. Is your graph bipartite? Then things will be simpler. What if certain employees can be given multiple jobs? This can be modeled by replicating the employee(or job) as many times as needed. Is your graph weighted or unweighted? Most problems would be unweighted, but the same can be modeled on weighted graphs, where we require to construct maximum weight matching. Standard algorithms for bipartite matching are based on network flow. Implementations : CSA, BIM, GOBLIN, LEDA, Blossum IV, Stanford GraphBase and more. Related : Eulerian Cycle , network flow Eulerian Cycle/Chinese Postman Input description: A graph \\(G = (V,E)\\) . Problem description: Find the shortest tour visiting each edge of \\(G\\) at least once. This problem is has many applications and variants. These are a few conditions that can determine if a Eulerian cycle or path exists, An undirected graph contains an Eulerian cycle iff (1) it is connected, and (2) each vertex is of even degree. An undirected graph contains an Eulerian path iff (1) it is connected, and (2) all but two vertices are of even degree. These two vertices will be the start and end points of any path. A directed graph contains an Eulerian cycle iff (1) it is strongly-connected, and (2) each vertex has the same in-degree as out-degree. Finally, a directed graph contains an Eulerian path from x to y iff (1) it is connected, and (2) all other vertices have the same in-degree as out-degree, with x and y being vertices with in-degree one less and one more than their out-degrees, respectively. This characterization of Eulerian graphs makes it easy to test and explicitly create a cycle. The chinese postman problem minimizes the length of a cycle that traverses every edge at least once. Related : Matching , Hamiltonian Cycle Edge and Vertex Connectivity Input description: A graph \\(G\\) . Optionally, a pair of vertices \\(s\\) and \\(t\\) . Problem description: What is the smallest subset of vertices (or edges) whose deletion will disconnect \\(G\\) ? Or which will separate \\(s\\) from \\(t\\) ? The edge (vertex) connectivity of a graph \\(G\\) is the smallest number of edge (vertex) deletions sufficient to disconnect \\(G\\) . Is the graph already disconnected? Is there one weak link in my graph? What if I want to split the graph into equal sized pieces? Are arbitrary cuts OK, or must I separate a given pair of vertices? Edge and vertex connectivity can both be found using network-flow techniques. Related : Connected components , network flow Network Flow Input description: A directed graph \\(G\\) , where each edge \\(e = (i,j)\\) has a capacity \\(c_e\\) . A source node \\(s\\) and sink node \\(t\\) . Problem description: What is the maximum flow you can route from \\(s\\) to \\(t\\) while respecting the capacity constraint of each edge? Goes far beyond plumbing. A surprising variety of linear programming problems can be modeled as network-flow problems. And, network flow algorithms can solve these problems much faster than general purpose linear programming methods. Two primary classes of problems, Maximum Flow Minimum Cost flow Special considerations, What if I have multiple sources/sinks? Add a vertex to create super source/sink. What if all arc capacities are identical, either 0 or 1? Faster algorithms exist. What if all my edge costs are identical? What if I have multiple types of material moving through the network? multicommodity flow Primary classes of algorithms, Augmenting path methods Preflow-push methods Related : Linear programming , matching , connectivity Drawing Graphs Nicely Input description: A graph \\(G\\) . Problem description: Draw a graph \\(G\\) so as to accurately reflect its structure. What exactly does a nice drawing mean? Several criteria can be used, Crossings, Area, Edge length, Angular resolution, Aspect ratio Unfortunately, these goals are mutually contradictory and the problem is NP-complete. Also, drawing the complete graph, with more than 15 to 20 vertices, would not look particularly nice in the absence of any inherent symmetry. Some questions to ask, Must the edges be straight, or can I have curves/bends? Is there a natural, application specific drawing? use it if it exists. Is your graph either planer or a tree? Is your graph directed? How fast must your algorithm be? Use incremental updates for interactive applications. Does your graph contain symmetries? First quick and dirty method, place all the vertices in a circle, and start adding the edges. Simulated annealing can be used to minimize the crossings. A general purpose heuristic can model the graph as a system of springs and then use enerygy minimization to space the vertices. After the graph is drawn, you may also want to place the edge/vertex labels. This, can be shown to be NP-complete, but heuristics can be used effectively. Also related problem of graph visualization in 3 dimensions. Implementations : GraphViz. Related : Drawing trees , planarity testing Drawing Trees Input description: A tree \\(T\\) , which is a graph without any cycles. Problem description: Create a nice drawing of the tree \\(T\\) . Are you drawing a free or a rooted tree. Rooted trees define a hierarchical order. Free trees do not encode any structure beyond their connection topology(e.g. a Minimum Spanning Tree). Trees are always planar and hance can and should be drawn without any crossing edges. Two primary options for trees, Ranked embeddings , place the root at top, divide space into root-degree strips, remmove root, repeat recursively. Do some adjustments afterwards. Radial embeddings , useful for free trees, place root/center at the center of page, divide the space into angular sections based on the degree, repeat recursively. Adjust. Implementations : GraphViz. Related : Drawing graphs , planar drawings Planarity Detection and Embedding Input description: A graph \\(G\\) . Problem description: Can \\(G\\) be drawn in the plane such that no two edges cross? If so, produce such a drawing. Planar drawings(or embeddings ) make clear the structure of a given graph by eliminating crossing edges. However, not very much needed/encountered explicitly in applications. More important, planarity testing. Related : Graph partition , drawing trees if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"The Algorithms Design Manual, Graph Problems(Polynomial-Time)"},{"url":"posts/books/the-algorithms-design-manual-combinatorial-problems/","text":"Combinatorial Problems Check out Numerical Recipes Whats different? Issues of Precision and Error. Floating point issues. Use both single and double precision, and think hard when they diverge. Extensive Libraries of Code. There is no reason to not to use all thats already written. Sorting Input description: A set of \\(n\\) items. Problem description: Arrange the items in increasing (or decreasing) order. The most fundamental algorithmic problem in computer science. First rule of algorithm design : \"when in doubt, sort\" Questions to ask, How many keys will you be sorting? Use simple routines. Will there be duplicate keys in the data? Do you need sort to be stable? What do you know about your data? Has the data already been partially sorted? Insertion sort would perform much better. Do you know the distribution of the keys? A bucket or distribution sort would make sense. Are your keys very long or hard to compare? It might make sense to use prefixes, or maybe use radix sort. Is the range of possible keys very small? Use something like counting sort. Do I have to worry about disk accesses? Use external sorting , or use B-tree . How much time do you have to write and debug your routine? If you want to implement your own quicksort , Use randomization, Median of three Leave small subarrays for insertion sort Do the smaller partition first. compiler optimizations using tail recursion might help. Implementations : GNU sort, C++ STL sort and stable_sort , and many more. Related : Dictionaries , searching , topological sorting Searching Input description: A set of \\(n\\) keys \\(S\\) , and a query key \\(q\\) . Problem description: Where is \\(q\\) in \\(S\\) ? \"Searching\" is a word that means different things to different people. We consider the task of searching for a key in a list, array or a tree. Sequential search vs. Binary search. Questions to ask, How much time can you spend programming? Binary search can be tricky to be made bug free. Are certain items accessed more often than other ones? Exploit there relative frequencies. Might access frequencies change over time? Use self-organizing structures like splay trees . Is the key close by? Use sequential search. Is my data structure sitting on external memory? Use B-trees . Can I guess where the key should be? Interpolation search Implementations : C++ STL find and binary_search Related : Dictionaries , sorting Median and Selection Input description: A set of \\(n\\) numbers or keys, and an integer \\(k\\) . Problem description: Find the key smaller than exactly \\(k\\) of the \\(n\\) keys. Median finding is an essential problem in statistics, more robust than mean . Special case of selection problem which arises in several applications, Filtering outlying elements : Remove 10% largest and smallest values. Identifying the most promising candidates : Select top 25%. Deciles and related divisions. Order statistics Issues in median finding(arbitrary selection), How fast does it have to be? \\(O(n\\log n)\\) or \\(O(n)\\) expected -time. What if you only get to see each element once? Define approximate deciles, or do random sampling, or mix both strategies. How fast can you find the mode? Implementations : C++ STL nth_element Related : Priority queues , sorting Generating Permutations Input description: An integer \\(n\\) . Problem description: Generate (1) all, or (2) a random, or (3) the next permutation of length \\(n\\) . Many algorithmic problems require seek the best way to order a set of objects, like travelling salesman , bandwidth , graph isomorphism . A fundamental notion of order is required. Two different paradigms : ranking/unranking and incremental change methods. Define functions Rank/Unrank such that, \\(p = Unrank(Rank(p), n)\\) . Sequencing permutations Generating random permutations Keep track of a set of permutations. Incremental change algorithms can be tricky, but concise. We can also save time by avoiding identical permutations if there are duplicate elements. Implementations : C++ STL next_permutation and prev_permutation . Related : Random-number generation , generating subsets , generating partitions . Generating Subsets Input description: An integer \\(n\\) . Problem description: Generate (1) all, or (2) a random, or (3) the next subset of the integers \\(\\{1, \\cdots , n\\}\\) . Here, the order among the elements does not matter. Many algorithmic problems seek the best subset : vertex cover , knapsack , set packing . There are \\(2&#94;n\\) different subsets of an \\(n\\) -element set. This is much less than the \\(n!\\) permutations. It is a good idea to keep elements in subset sorted in a canonical order so as to speed up identity testing. Options, Lexicographic order : surprisingly difficult to generate. Gray Code : Adjacent subsets differ by insertion/deletion of only one element. Binary counting : Use a bit-vector. Useful in, K-subsets All subsets of length K. Strings Related : Generating permutations , generating partitions Generating Partitions Input description: An integer \\(n\\) . Problem description: Generate (1) all, or (2) a random, or (3) the next integer or set partitions of length \\(n\\) . Integer partitions are multisets of nonzero integers that add up exactly to \\(n\\) . Use in for eg. nuclear fision .. Set partitions divide the elements \\(1, \\ldots, n\\) into nonempty subsets. Use in for eg. vertex/edge coloring and connected components . Related : Generating permutations , generating subsets . Generating Graphs Input description: Parameters describing the desired graph, including the number of vertices \\(n\\) , and the number of edges \\(m\\) or edge probability \\(p\\) . Problem description: Generate (1) all, or (2) a random, or (3) the next graph satisfying the parameters. Useful for generating test data for programs. A different application arises in network design. Adding redundancy and tolerance to vertex failures. Questions to ask, Do I want labeled or unlabeled graphs? Do I want directed or undirected graphs? How do you want to model randomness? Random edge generation Random edge selection Preferential attachment Alternatively, we can generate organic graphs that can reflect relationships among real-world objects. Other interesting graphs, Trees Fixed degree sequence graphs Implementations : Stanford GraphBase, Combinatorica, and more resources. Related : Generating permutations , graph isomorphism Calendrical Calculations Input description: A particular calendar date \\(d\\) , specified by month, day, and year. Problem description: Which day of the week did \\(d\\) fall on according to the given calendar system? Important in business applications. More important for international applications dealing with different timezones and possibly different calender systems. Complications arise with irregularity in years duration(leap years). So it becomes pointless to implement them by hand. Implementations : C++ Boost datetime . Related : Arbitrary precision arithmetic , generating permutations Job Scheduling Input description: A directed acyclic graph \\(G = (V,E)\\) , where vertices represent jobs and edge \\((u,v)\\) implies that task \\(u\\) must be completed before task \\(v\\) . Problem description: What schedule of tasks completes the job using the minimum amount of time or processors? Devising a proper schedule to satisfy a set of constraints is fundamental to many applications. Mapping tasks to processors is a critical aspect of any parallel-processing system. Applications Topological sorting : precedence constraints. Bipartite matching : skill matching Vertex and edge coloring : avoid interference. Travelling salesman Eulerian Cycle Interesting problems, Critical path Minimum completion time What is the tradeoff between the number of workers and completion time? Can also be modeled using Integer-linear programming. More variations, Assign jobs to identical machines to minimize the the total elapsed time. Tasks are provided with allowable start and required finish times. Implementations : JOBSHOP (C), Tablix, LEKIN and more. Related : Topological sorting , matching , vertex coloring , edge coloring , bin packing Satisfiability Input description: A set of clauses in conjunctive normal form. Problem description: Is there a truth assignment to the Boolean variables such that every clause is simultaneously satisfied? A primary application of testing hardware/software design on all the inputs. The original NP-complete problem. Issues, Is your formula the AND of OR s (CNF) or the OR of AND s (DNF)? DNF can be solved easily, while CNF is NP-complete. We can use De Morgan's laws to convert CNF into DNF. However the translation itself could take exponential time. How big are your clauses? 3-SAT and above are NP-complete. Does it suffice to satisfy most of the clauses? This can make the problem easier . Related : Constrained optimization , travelling salesman problem if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"The Algorithms Design Manual, Combinatorial Problems"},{"url":"posts/books/the-algorithms-design-manual-numerical-problems/","text":"Numerical Problems Check out Numerical Recipes Whats different? Issues of Precision and Error. Floating point issues. Use both single and double precision, and think hard when they diverge. Extensive Libraries of Code. There is no reason to not to use all thats already written. Solving Linear Equations Input description: An \\(m \\times n\\) matrix \\(A\\) and an \\(m \\times 1\\) vector \\(b\\) , together representing \\(m\\) linear equations on \\(n\\) variables. Problem description: What is the vector \\(x\\) such that \\(A \\cdot x = b\\) ? Naive algorithm using Gaussian Elimination is \\(O(n&#94;3)\\) . Issues to worry about, Are roundoff errors and numerical stability affecting my solution? Use library routines. Which routine in the library should I use? Reduce to special form for faster implementations. Is my system sparse? Use specialized algorithms for faster implementations. Will I be solving many systems using the same coefficient matrix? Use LU Decomposition. $$A \\cdot x = (L \\cdot U) \\cdot x = L \\cdot (U \\cdot x) = b$$ This gives a solution in two \\(O(n&#94;2)\\) since backsubstitution gives solves triangular system of equations in quadratic time instead of \\(O(n&#94;3)\\) , after \\(LU\\) decomposition has been done in \\(O(n&#94;3)\\) . Implementations LAPACK (C/C++) JScience, JAMA (Java) Related : Matrix multipplication , determinant/permanent Bandwidth Reduction Input description: A graph \\(G = (V,E)\\) , representing an \\(n \\times n\\) matrix \\(M\\) of zero and non-zero elements. Problem description: Which permutation \\(p\\) of the vertices minimizes the length of the longest edge when the vertices are ordered on a line—i.e. , minimizes \\(max(i,j) \\in E |p(i) − p(j)|\\) ? Applied to matrices bandwidth reduction permutes the rows and columns of a sparse matrix to minimize the distance \\(b\\) of any non-zero entry from the center diagonal. Gaussian elimination can be performed in \\(O(nb&#94;2)\\) on matrices of bandwidth \\(b\\) . This is a big win over \\(O(n&#94;3)\\) if \\(b << n\\) . An example on graphs Arranging \\(n\\) circuit components in a line to minimize the length of the longest wire(and hence time delay) is a bandwidth problem. A hypertext application with links on a magnetic tape, we need to store linked objects near each other to minimize search time. More general formulations of rectangular circuit layouts and disks inherit the same hardness and heuristics. Variations In linear arrangement , we seek to minimize the sum of the lengths of the edges. In profile minimization , we seek to minimize the sum of one way distances for each vertex \\(v\\) the length of the longest edge whose other vertex is the left of \\(v\\) . Unfortunately, this is NP-complete, even for a tree, thus or only options are a brute-force search or heuristics. Heuristic in worst case \\(O(n&#94;3)\\) , close to linear in practice. Brute-force in \\(n!\\) possible permutations. Implementations Del Corso and Manzini's code for exact solutions to bandwidth problems. More references in the book. Related : Solving linear equations , topological sort Matrix Multiplication Input description: An \\(x \\times y\\) matrix \\(A\\) and a \\(y \\times z\\) matrix \\(B\\) . Problem description: Compute the \\(x \\times z\\) matrix \\(A \\times B\\) . A fundamental problem in linear algebra. Multiplication can done in arbitrary order, with varying costs in \\(O(xyz)\\) , but minimum can not be predicted. With bandwidth- \\(b\\) matrices, a speedup of \\(O(xbz)\\) can be achieved. Strassen's algorithm using divide-and-conquer runs in \\(O(n&#94;{2.81})\\) , but is only practically useful for \\(n > 100\\) . For long chains on matrix multiplications, dynamic programming can be used to optimize the parenthesization to minimize the dimensions of intermediate results. Related : Solving linear equations , shortest path . Determinants and Permanents Input description: An \\(n \\times n\\) matrix \\(M\\) . Problem description: What is the determinant \\(|M|\\) or permanent \\(perm(M)\\) of the matrix \\(M\\) ? Used to solve a variety of problems. Testing if a matrix is singular , i.e. the matrix has no inverse, iff \\(|M|=0\\) . Test whether a set of points lie in a plane, iff \\(|M|=0\\) . Test whether a point lies in the left or right side of a line or a plane. Compute area or volume of a triangle, tetrahedron or other simplicial complex. $$|M| = \\sum_{i=1}&#94;{n!}(-1)&#94;{sign(\\pi_i)} \\prod_{j=1}&#94;n M[j,\\pi_j]$$ This is \\(O(n!)\\) . However can be done faster using LU decomposition in \\(O(n&#94;3)\\) . Closely related, permanent , counts the number of perfect matchings in \\(G\\) , represented by its adjacency matrix \\(M\\) . $$perm(M) = \\sum_{i=1}&#94;{n!} \\prod_{j=1}&#94;n M[j, \\pi_j] $$ However, calculating this is NP-hard. Related : Solving linear equations , matching , geometric primitives . Constrained and Unconstrained Optimization Input description: A function \\(f(x_1, \\ldots , x_n)\\) . Problem description: What point \\(p = (p_1, \\ldots , p_n)\\) maximizes (or minimizes) the function \\(f\\) ? Optimization arises whenever there is an objective function that must be tuned for optimal performance. Pattern recognition to energy/potential minimization Questions to ask, Am I doing constrained ot unconstrained optimization? Is the function I am trying to optimize described by a formula? Is it expensive to compute the function at a given point? How many dimensions do we have? How many do we need? How smooth is my function? Variations of gradient descent and simulated annealing Related : Linear programming , satisfiability Linear Programming Input description: A set \\(S\\) of $$ linear inequalities on $m$ variables $$ S_i := \\sum_{j=1}&#94;m c_{ij} \\cdot x_j \\ge b_i, 1 \\le i \\le n \\($ and a linear optimization function $f(X) = \\sum_{j=1}&#94;m c_j \\cdot x_j\\) . Problem description: Which variable assignment \\(X'\\) maximizes the objective function \\(f\\) while satisfying all inequalities \\(S\\) ? Most important problem in mathematical optimization and operations research. Resource allocation Approximating the solution of inconsistent equations. Graph algorithms : Many can be solved using linear programming, most of the rest can be solved using Integer linear programming . The simplex method. While a simple algorithm, needs considerable art and the right data structures for large sparse systems. Also used, interior-point methods. Commercial solutions are of much higher quality than free/open source solutions. Questions to ask, Do any variables have integrality constraints? Although it is NP-complete, reasonable programs are available. Do I have more variables or constraints? If there are more constraints than variables, consider solving the dual LP, which would be much easier. What if my optimization function or constraints are not linear? Although fast implementations exist(for quadratic programming), but this is NP-complete. What if my model does not match the input format of my LP solver? Map your problem to standard forms . Implementations COIN OR GNU Linear Programming Kit: GLPK Related : Constrained and Unconstrained optimization , network flow Random Number Generation Input description: Nothing, or perhaps a seed. Problem description: Generate a sequence of random integers. Discrete event simulations, passwords and cryptographic keys, randomized algorithms for graph and geometric problems. Anyone who considers arithmetical methods of producing random digits is , of course, in a state of sin. -- Von Neumann. However, we can create pseudorandom numbers. Questions to ask, Should my program use the same random numbers each time it runs? How good is my compiler's built-in random number generator? What if I must implement my own random-number generator? $$R_n = (aR_{n-1} + c) \\mod m$$ What if I don't want such large numbers? What if I need non-uniformly distributed random numbers? How long should I run my Monte-Carlo simulation to get the best results? Related : Constrained and unconstrained optimization , generating permutations , generating subsets , generating partitions . Factoring and Primality Testing Input description: An integer \\(n\\) . Problem description: Is \\(n\\) a prime number, and if not what are its factors? Long suspected of being only of mathematical interest, these problems have surprisingly many applications. The RSA, has tables, games. Several algorithms and implementations exist for generating and testing prime numbers and factoring(exponential). Related : Cryptography , high precision arithmetic Arbitrary Precision Arithmetic Input description: Two very large integers, \\(x\\) and \\(y\\) . Problem description: What is \\(x + y\\) , \\(x − y\\) , \\(x \\times y\\) , and \\(x/y\\) ? Many applications require much larger integers than that can fit into a 32-bit integer. Questions to ask, Am I solving a problem instance requiring large integers, or do I have an embedded application? Do I need high- or arbitrary-precision arithmetic? What base should I do arithmetic in? How low-level are you willing to get for fast computation? The basic operations, Addition Subtraction Multiplication Division Exponentiation Related : Factoring Integers , cryptography Knapsack Problem Input description: A set of items \\(S = \\{1, \\cdots , n\\}\\) , where item \\(i\\) has size \\(s_i\\) and value \\(v_i\\) . A knapsack capacity is \\(C\\) . Problem description: Find the subset \\(S' \\subset S\\) that maximizes the value of \\(\\sum_{i \\in S'}v_i\\) , given that \\(\\sum_{i \\in S'}s_i \\le C\\) ; i.e. , all the items fit in a knapsack of size \\(C\\) . Resource allocation and financial constraints. Variations \\(0/1\\) problem, where objects can not be broken arbitarily. This makes it hard. Questions to consider, Does every item have the same cost/value or the same size? This becomes easy Does each item have the same \"price per pound\"? NP-complete, but still is considered \"easy\". Also called subset problem . Integer partition becomes a special case. Are all the sizes relatively small integers? Can be solved in \\(O(nC)\\) , $C = $ capacity. What if I have multiple knapsacks? Bin-packing problem. Greedy heuristics often give \"good\" approximations. Based on 'price per pound' . Convert weights to integers using scaling . Related : Bin packing , integer programming Discrete Fourier Transform Input description: A sequence of \\(n\\) real or complex values \\(h_i, 0 \\le i \\le n − 1\\) , sampled at uniform intervals from a function \\(h\\) . Problem description: The discrete Fourier transform \\(H_m = \\sum_{k=0}&#94;{n-1} h_k e&#94;{2\\pi ikm/n\\) } for \\(0 \\le m \\le n − 1\\) . Electric engineers eat these for breakfast. They provide a way to transform samples of a time series into the frequency domain . Appplications include, Filtering Image compression Convolution and deconvolution Computing the correlation of functions $$z(t) = \\int_{-\\inf}&#94;{\\inf}f(\\tau)g(t + \\tau)d\\tau$$ Naive implementation works in \\(O(n&#94;2)\\) . The fast Fourier transform(FFT) computes discrete fourier transform in \\(O(n \\log n)\\) . Often implemented in hardware for real time performance. Related : Data compression , high-precision arithmetic if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"The Algorithms Design Manual, Numerical Problems"},{"url":"posts/books/the-algorithms-design-manual-data-structures/","text":"Data Structures Dictionaries Input Description : A set of \\(n\\) records, each identified by one or more fields. Problem description : Build and maintain a data structure to efficiently locate, insert, and delete the record associated with any query key \\(q\\) . It is more important to avoid using a bad data structure than to identify the single best option available. Questions to ask: How many items will you have in your data structure? Do you know the relative frequencies of insert, delete, and search operations? Can we assume that the access pattern for keys will be uniform and random? Is it critical that individual operations be fast, or only that the total amount of work done over the entire program be minimized? Under the hood: Unsorted linked lists or arrays: For small data sets. Sorted linked lists or arrays Hash tables How do I deal with collisions? Open addressing or bucketing? How big should the table be? At least as big as \\(m\\) , the number of items you expect to put in the table, it better be prime . What hash functions should I choose? For strings, $$H(S,j) = \\sum_{i=0}&#94;{m-1}\\alpha&#94;{m-(i+1)}\\times char(s_{i+j})\\mod{m}$$ \\(\\alpha\\) is the size of the alphabet, \\(char(x)\\) maps a character to its ASCII code. This can be computer efficiently as, $$H(S,j+1) = (H(S,j) - \\alpha&#94;{m-1}char(s_j))\\alpha + s_{j+m}$$ . In the end, make sure that the distribution is as uniform as possible. Binary search trees Elegant data structures that support fast insertions, deletions and queries. Do I need self balancing trees? Red-black trees , splay trees . Use the best implementations!! B-trees For data sets so large that they will not fit in the memory. Uses caches and secondary storage. Look for Cache-oblivious algorithms Skip lists Somewhat of a cult data structure. Implementations C++ : std::map Implemented as Binary Search Tree . LEDA hashing, perfect hashing, B-trees, red-black trees, random search trees, skip lists. Java Collections and Data Structures Library in Java Related : Sorting , searching Priority Queues Input description: A set of records with numerically or otherwise totally-ordered keys. Problem description: Build and maintain a data structure for providing quick access to the smallest or largest key in the set. Very useful in simulations(as future events ordered by time). Not required if insertions, deletions and queries are not intermixed. Questions to ask: What other operations do you need? Do you know the maximum data structure size in advance? Might you change the priority of the elements already in the queue? Choices: Sorted array or list Binary heaps Bounded height priority queue Useful for small, discrete range of keys. Binary Search trees Very useful when you need more dictionary operations or the size is unbounded. Fibonacci and pairing heaps Speed up decrease-key operation. Implementations C++ STL std::priority_queue Uses a std::vector or std::dequeue . LEDA Binary heaps, Fibonacci heaps, pairing heaps, Emde-Boas trees and bounded height priority queues Java Collections : java.util.PriorityQueue Related : Dictionaries , sorting , shortest path . Suffix Trees and Arrays Input description: A reference string \\(S\\) . Problem description: Build a data structure to quickly find all places where an arbitrary query string \\(q\\) occurs in \\(S\\) . Phenomenally useful for solving string problems. A suffix tree is simply a trie of all the proper suffixes of \\(S\\) . Can be constructed in \\(O(n)\\) by making clever use of pointers!! What can you do with it? Find all occurrences of \\(q\\) as a substring of \\(S\\) in \\(O(|q|+k)\\) , where \\(k\\) is the number of occurrences. Longest substring common to a set of strings. Find the longest palindrome in \\(S\\) . They get even better when used as suffix arrays . Implementations C implementation by Schurmann and Stoye . Many C/C++ implementations in Pizza&Chili corpus Java BioJava::SuffixTree Related : String Matching , Text Compression , Longest Common Substring Graph Data Structures Input description: A graph \\(G\\) . Problem description: Represent the graph \\(G\\) using a flexible, efficient data structure. Adjacency matrices and adjacency lists . For most things, adjacency lists are the way to go, unless the graphs are very small or very dense. Questions to ask: How big will your graph be? How dense will your graph be? Which algorithms will you be implementing? Will you be modifying the graph over the course of your application? Prefer existing implementations. Graphs have different flavors, like Planar graphs , Hypergraphs , hierarchical graphs (representation). Implementation C++ : LEDA, Boost Java : JUNG, Data Structures Library(JDSL), JGraphT Stanford Graphbase Related : Set data structures , graph partition Set data structures Input description: A universe of items \\(U = \\{u_1, \\ldots , u_n}\\\\) on which is defined a collection of subsets \\(S = \\{S_1, \\ldots , S_m\\}\\) . Problem description: Represent each subset so as to efficiently \\((1)\\) test whether \\(u_i \\in S_j\\) , \\((2)\\) compute the union or intersection of \\(S_i\\) and \\(S_j\\) , and \\((3)\\) insert or delete members of \\(S\\) . In mathematical terms, unordered collection of objects drawn from a fixed universal set. Uses a single canonical order for implementations, typically sorted. Distinguished from dictionaries(no fixed universal set) and strings(order is important). Multisets : An element can occur more than once. A system of subsets can also be represented as a hypergraph . Representations: Bit vectors : For a fixed universal set. Space efficient, fast intersection and union. Not very good for sparse subsets. Containers and dictionaries Bloom filters : Bit vectors with hashing. Set partition : When an item can be in only one set. Representations for set partition structures: Collection of containers : Membership testing is costly. Generalized bit vector : Union, intersection takes \\(O(n),\\; n = |U|\\) . Dictionary with a subset attribute : : Union, intersection are slow. Union-find data structures : Awesome asymptotic performance!!! Even better with path compression . Does not allow breaking subsets created by unions. Implementations C++ STL set and multiset . LEDA. Java Collections HashSet and TreeSet Related : Generating subsets , generating partitions , set cover , minimum spanning tree . Kd-Trees Input description: A set \\(S\\) of \\(n\\) points or more complicated geometric objects in \\(k\\) dimensions. Problem description: Construct a tree that partitions space by half-planes such that each object is contained in its own box-shaped region. Spatial data structures that hierarchically decompose space into a small number of cells, each containing a few representatives from an input set of points. Flavors differ in how the splitting plane is selected: Cycling through the dimensions Cutting along the largest dimension Quadtrees or Octtrees : Cutting (axes-parallel planes) simultaneously along all the dimensions. BSP-trees : General(arbitrary) cutting planes to carve up cells. More complicated to work with. R-trees : Objects are partitioned into (possibly overlapping) boxes. Advantages : Point location. Nearest neighbor search. Range search Partial key search Effective upto say 20 dimensions. Implementations KDTREE2 : C++ and Fortran Terralib : C++ Related : Nearest-neighbor search , point location , range search . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"The Algorithms Design Manual, Data structures"},{"url":"posts/books/the-algorithms-design-manual/","text":"How to design algorithms? Using 'The right stuff'.,.. Do I really understand the problem? What exactly does the input consist of? What exactly are the desired results or outputs? Can I construct an input example small enough to solve by hand? What happens when I try to solve it? How important is it to my application that i always find the optimal answer? Can I settle for something close to the optimal answer? How large is a typical instance of my problem? Will I be working on 10 items? 1,000 items? 1,000,000 items? How important is speed in my application? Must the problem be solved within one second? One minute? One hour? One day? How much time and effort can I invest in implementation? Will I be limited to simple algorithms that can be coded up in a day, or do I have the freedom to experiment with a couple of approaches and see which is best? Am I trying to solve a numerical problem? A graph algorithm problem? A geometric problem? A string problem? A set problem? Which formulation seems easiest? Can I find a simple algorithm or heuristic for my problem? Will brute force solve my problem correctly by searching through all subsets or arrangements and picking the best one? If so, why am I sure this algorithm always gives the correct answer? How do I measure the quality of a solution once I construct it? Does this simple, slow solution run in polynomial or exponential time? Is my problem small enough that this brute-force solution will suffice? Am I certain that my problem is sufficiently well defined to actually have a correct solution? Can I solve my problem by repeatedly trying some simple rule,, like picking the biggest item first? the smallest item first? A random item first? If so, on what types of inputs does this heuristic work well? Do these correspond to the data that might arise in my application? On what types of inputs does this heuristic work badly? If no such examples can be found, can I show that it always works well? How fast does my heuristic come up with an answer? Does it have a simple implementation? Is my problem in the catalog of algorithmic problems in the back of this book? What is known about the problem? Is there an implementation available that I can use? Did I look into the right place for my problem? Did I browse through all pictures? Did I look in the index under all possible keywords? Are there relevant resources available on the World Wide Web? Did I do a Google web and Google Scholar search? Did I go to the page associated with this book? Are there special cases of the problem that I know how to solve? Can I solve the problem efficiently if I ignore some of the input parameters? Does the problem become easier to solve when I set some of the input parameters to trivial values, such as 0 or 1? Can I simplify the problem to the point where I can solve it efficiently? Why can't this special case algorithm be generalized to a wider class of inputs? Is my problem a special case of a more general problem in the catalog? Which of the standard algorithm design paradigms are most relevant to my problem? Is there a set of items that can be sorted by size or some key? Does this sorted order make it easier to find the answer? Is there a way to split the problem in two smaller problems, perhaps by doing a binary search? How about partitioning the elements into big and small, or left and right? Does this suggest a divide-a-conquer algorithm? Do the input objects or desired solution have a natural left-to-right order, such as characters in a string, elements of a permutation, or leaves of a tree? Can I use dynamic programming to exploit this order? Are there certain operations being done repeatedly, such as searching, or finding the largest/smallest element? Can I use a data structure to speed up these queries? What about a dictionary/hash table or a heap/priority queue? Can I use random sampling to select which object to pick next? What about constructing many random configurations and picking the best one? Can I use some kind of directed randomness like simulated annealing to zoom in on the best solution? Can I formulate my problem as a linear program? How about an integer program? Does my problem seem something like satisfiability, the travelling salesman problem, or some other NP-complete problem? Might the problem be NP-complete problem? Might the problem be NP-complete and thus not have an efficient algorithm? Is it in the problem list in the back of Garey and Johnson ? Am I sill stumped? Am I willing to spend money to hire an expert to tell me what to do? Why don't I go back to the beginning and work through these questions again? Did any of my answers change during my latest trip through the list? Backtrack!! A Catalog of Algorithmic Problems Data Structures Numerical Problems Combinatorial Problems Graph Problems : Polynomial-Time Graph Problems : Hard Problems Computational Geometry Set and String Problems","tags":"books","title":"The Algorithms Design Manual"},{"url":"posts/articles/a-review-of-c-stl/","text":"http://www.studytonight.com/cpp/stl/stl-overview-of-algorithms https://gradestack.com/Programming-in-C-/Overview-of-Standard/Summary/21211-4330-53285-study-wtw https://embeddedartistry.com/blog/2017/8/2/an-overview-of-c-stl-containers","tags":"articles","title":"A review of C++ STL"},{"url":"posts/robotics/inverse-kinematics-on-kuka-arm-using-ros-and-python/","text":"Picking and placing objects is something that we as humans take for granted. That's not the case for our mechanical(and electronic) friends. They have to Calculate an optimal collision-free path from the source to target location. Perform inverse kinematics to control the joints on your arm. Pick the object cleanly,without knocking over other objects in your path(well, this one doesn't always go very well for us either). One of the most challenging projects that I did in my Udacity Robotics Nanodegree program was to control a 6-jointed robot arm to pick and place an object. I was given a trajectory that the arm should follow to reach the object, pick up and drop it at a given location. My job was to perform inverse kinematic analysis to calculate the joint positions that will move the gripper along the requested path. Enter math. Fig. 1 : Shows the link frames(coordinate systems) choosen according to Modified DH convention discussed next. \\(O_i\\) is the origin for link \\(i\\) frame, and \\(X_i\\) , \\(Z_i\\) are the \\(X\\) and \\(Z\\) axis correspondingly, and \\(Z\\) represents the axis of rotation(translation in case of prismatic joints). Since we are using a right handed coordinate system, \\(Y_i\\) can be calculated accordingly. Here is a diagram of the gripper showing the degrees of freedom that the arm has, along with their reference frames. Computing through these transformations can become complex and tedious really fast. So, we use a convention. Denavit–Hartenberg Analysis The Denavit–Hartenberg(DH) convention is a commonly used system for selecting the frames of reference in robotics applications. They are particularly designed to cut out the number of free parameters required to specify the whole system. Here is an illustration, Fig. 2 : Modified DH convention axes assignment and parameters. Here, \\(d_i\\) : Link offset, distance between \\(X_{i-1}\\) and \\(X_i\\) , measured along \\(Z_{i-1}\\) , variable in prismatic joints. \\(\\alpha_{i-1}\\) : Angle between \\(Z_{i-1}\\) and \\(Z_i\\) , measured along \\(X_i\\) . \\(a_{i-1}\\) : Link length, distance between \\(Z_{i-1}\\) and \\(Z_i\\) , measured along \\(Z_{i-1}\\) . \\(\\theta_i\\) : Joint angle, Angle between \\(X_{i-1}\\) and \\(X_i\\) , measured along \\(Z_i\\) , variable in revolute joints. So, according to this convention, the total transform between links \\(L_{i-1}\\) and \\(L_i\\) can be thought of as a roation by \\(\\alpha_{i-1}\\) along \\(X_{i-1}\\) , translation by \\(\\alpha_{i-1}\\) along \\(X_{i-1}\\) , rotation by \\(\\theta_i\\) along \\(Z_i\\) , and finally translation by \\(d_i\\) along \\(Z_i\\) . That is, $$ T_{i-1}&#94;{i} = R(x{i-1},, \\alpha_{i-1}) \\cdot T(x_{i-1}, a_{i-1}) \\cdot R(z_i, \\theta_i) \\cdot T(z_i, d_i)$$ Which, when expanded analytically, turns out to be, $$\\begin{eqnarray} T_{i-1}&#94;{i} = \\begin{bmatrix} cos(\\theta_i) & -sin(\\theta_i) & 0 & a_{i-1} \\\\ sin(\\theta_i)cos(\\alpha{i-1}) & cos(\\theta_i)cos(\\alpha{i-1}) & -sin(\\alpha{i-1}) & -sin(\\alpha{i-1})d_i \\\\ sin(\\theta_i)sin(\\alpha{i-1}) & cos(\\theta_i)sin(\\alpha{i-1}) & cos(\\alpha{i-1}) & cos(\\alpha{i-1})d_i \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} \\end{eqnarray}$$ Now, we can apply this convention to our robotic arm and find out all the required parameters for further analysis. Here are the model specifications and final DH-parameters, \\(Link_i\\) \\(\\alpha_{i-1}\\) \\(a_{i-1}\\) \\(d_i\\) $\\theta_i 1 0 0 0.75 q1 2 -pi/2 0.35 0 q2 - pi/2 3 0 1.25 0 q3 4 -p1/2 -0.054 1.50 q4 5 pi/2 0 0 q5 6 -pi/2 0 0 q6 7(G) 0 0 0.303 0 Referring back to the transformation equation (1), transformation between two links can be defined separately, we use sympy for symbolic computation, simplification and substitution. # Create transformation matrix between two links # according to Modified DH convention with given parameters def createMatrix ( alpha , a , q , d ): mat = Matrix ([[ cos ( q ), - sin ( q ), 0 , a ], [ sin ( q ) * cos ( alpha ), cos ( q ) * cos ( alpha ), - sin ( alpha ), - sin ( alpha ) * d ], [ sin ( q ) * sin ( alpha ), cos ( q ) * sin ( alpha ), cos ( alpha ), cos ( alpha ) * d ], [ 0 , 0 , 0 , 1 ]]) return mat Also, total homogenous transform between base_link and gripper_link can be computed as, $$T_0&#94;G = T_0&#94;1*T_1&#94;2*T_2&#94;3*T_3&#94;4*T_4&#94;5*T_5&#94;6*T_6&#94;G$$ And, finally, the same total transform can also be computed given the gripper_link position and orientation w.r.t. base_link .Given, pg_0 = [ px , py , pz ] # End effector position. p_quat = [ qx , qy , qz , qw ] # End effector orientation as a quaternion. # R0_g = end-effector(gripper) rotation transformation(4X4) R0_g = tf . transformations . quaternion_matrix ( p_quat ) D0_g = tf . transformations . translation_matrix ( pg_0 ) T_total = R0_g * D0_g Now, the total transform computed previously, \\(T_0&#94;G\\) is gripper_link transform specified in DH convention( yellow ). However, the transform calculated from gripper_link position and orientation is in URDF frame( green ). These are shown in the following image, So, we need to correct T0_G transform by rotating by pi along Z , and then by -pi/2 along Y . Thus, T_total = T0_G*rot_z(pi)*rot_y(-pi/2) Now the IK part. The last three joints q4, q5, q6 don't affect the position of Wrist Center( O5 ), hereby referred to as WC position.(this can be confirmed by running the Forward kinematics demo.) This is very convenient for us in decoupling the IK problem into a position and orientation problem where we can first compute the position of the WC (which gives us the first three joint angles q1, q2, q3 ) and orientation of the wrist , which gives us the last three joints q4, q5, q6 . Detailed explanation follows, Given End effector position and orientation, we calculate the the wrist center as follows, # rwc_0 = wrist-center position w.r.t. base_link(O_0) rwc_0 = pg_0 - ( d_g * ( R0_g * z_g )) Where, pg_0 = End effector position received. p_quat = End effector orientation received as quaternion. d_g = s[d7] = Displacement of end-effector from wrist center(along z). R0_g = tf.transformations.quaternion_matrix(p_quat) = End effector rotation matrix. z_g = rot_z(pi)*rot_y(-pi/2)*([0, 0, 1]) = gripper frame z axis in DH convention. So, the above equation displaces pg_0 by -d_g in the z direction. Calculate q1 given WC . Fig. 7 : Oblique view of the arm, when q1 != 0 , all other angles are assumed zero. From the above image, q1 can be calculated by projecting WC on X0-Y0 plane and calculating angular displacement from X0 . i.e. theta1 = atan2(rwc_0[1], rwc_0[0]) Calculate O2 position according to calculated q1 . # position of O2 w.r.t. base_link in zero configuration, i.e. when q1 = 0 pO2_0 = Matrix ([[ s [ a1 ]], [ 0 ], [ s [ d1 ]]]) # Rotate pO2_0 w.r.t. Z by theta1 pO2_0 = rot_z ( theta1 ) * pO2_0 Consider triangle(O2, O3, WC) . Note : Points O0 , O1 , O2 , O3 and O5/WC now lie in the same plane, defined by rotatingplane X0Z0 about Z0 . Fig. 8 : Schematic of arm in the plane containing triangle O2 , O3 , WC . Various angles required dimensions are also shown. In the figure, position O2 , WC are known and length A , B and C are known. # O2 , WC are known # O3 = unknown # Distance between O2 and O3 = a2(in figure 1) A = s [ a2 ] # Distance between O2 and O5/WC pO2towc_0 = rwc_0 - pO2_0 B = pO2towc_0 . norm () # Distance between O3 and O5/WC = (d4&#94;2 + a3&#94;2) in figure 1 C = np . sqrt ( s [ d4 ] * s [ d4 ] + s [ a3 ] * s [ a3 ]) # Offset angle between the Y3 axis line(O3, O5), -q31 in figure beta_prime = atan2 ( s [ a3 ], s [ d4 ]) # From Fig. 1 Now, we can apply Law of cosines in \\(\\Delta(O_2, O_3, O_5)\\) . In any triangle(A, B, C) c.c = a.a + b.b - 2.a.b.cos(alpha), where alpha = angle(BAC) and `.` represents multiplication So, # applying cosine rule `C&#94;2 = A&#94;2 + B&#94;2 -2ABcos(gamma)` # angle(O3, O2, O5), q21 in figure. gamma = np . arccos ( float (( A * A + B * B - C * C ) / ( 2 * A * B ))) # angle(O2, O3, O5), q32 in figure beta = np . arccos ( float (( A * A + C * C - B * B ) / ( 2 * A * C ))) Find theta2 Next, we need to compute theta2 , which can be thought of as the angle between link 2 direction i.e. dir(O2, O3) and X2 . Also, dir(O2, O3) can be calculated by rotating dir(O2, WC) by -gamma along Z2 . We can get X2 and Z2 by substituting q1=theta1 (calculated above) in T0_2 and multiplying the result by X(1, 0, 0) and Z(0, 0, 1) respectively. Note : T0_2 = T0_1*T1_2 . So, # z_2prime is the Z2 axis when q1 = theta1, this does not depend upon q2 z_2prime = T0_2 . subs ({ q1 : theta1 }) . dot ([[ 0 ], [ 0 ], [ 1 ], [ 0 ]]) # Rotate pO2towc_0 by gamma along z_2prime z2_rotation = tf . transformations . rotation_matrix ( - gamma , z_2prime ) # quaternion_about_axis(gamma, z_2prime[0:3]) # tf.transformations.quaternion_from_matrix(z2_rotation) a_dir = z2_rotation * pO2towc_0 a_dir = a_dir . normalized () # Compute theta2 X2_prime = self . T0_2 . subs ({ q1 : theta1 , q2 : 0 }) . dot ([[ 1 ], [ 0 ], [ 0 ], [ 0 ]]) theta2 = np . arccos ( float ( np . dot ( X2_prime , a_dir [ 0 : 4 ]) )) Find theta3 theta3 is simply the deviation of angle(O2, O3, WC) from pi/2 - q31 .i.e. theta3 = (pi/2 - q31) - q32 , But q31 = -beta_prime and q32 = beta , So, theta3 = ( pi / 2 + beta_prime ) - beta Now, we need to calculate q4, q5, q6 . For this we calculate the rotation matrix R3_6 from our total transform and calculated angles numerically (from end effector position/rotation) and symbolically (from DH parameters). We then compare the two representations to calculate plausible values of the last three joint angles. So, Symbolically : Just combine the symbollic transformations for individual links from link 3 to 6. # Extract the rotation component of the matrix,cos that's what we want >>> R3_6_sym = ( T3_4 * T4_5 * T5_6 )[: 3 ,: 3 ] [[ - s4s6 + c4c5c6 , - s4c6 - s6c4c5 , - s5c4 ], [ s5c6 , - s5s6 , c5 ], [ - s4c5c6 - s6c4 , s4s6c5 - c4c6 , s4s5 ]] # Where, s = sin, c =cos, 4,5,6 = q4,q5,q6 # So that, -s5c6 = -sin(q5)cos(q6) Numerically : # Calculate R3_6 R0_g ( corrected ) = R0_6 * R_corr # Where R_corr = rot_z ( pi ) * rot_y ( - pi / 2 ) # So R0_g = R0_3 * R3_6 * R_corr R0_3 . T * R0_g * R_corr . T = R3_6 # And, R0_3 = T0_3 [ 0 : 3 , 0 : 3 ] # Extract the rotation matrix R3_6 = R0_3 . transpose () * Matrix ( R0_g ) * self . R_corr . transpose () Finally we can evaluate this Matrix numerically by substituting q1, q2 and q3 calculated above R3_6 = R3_6.subs({q1: theta1, q2:theta2, q3: theta3}) Now, we need to select suitable terms from the matrix to compute q4, q5, q6 . We just follow the strategy of selecting the simplest terms to give to atan2 function for a given angle. i.e. theta4 = atan2(R3_6[2,2], -R3_6[0, 2]) , Since, R3_6[2,2]/-R3_6[0, 2] = sin(q4)sin(q5)/sin(q5)cos(q4) = tan(q4) theta5 = atan2(sqrt(R3_6[0, 2]*R3_6[0, 2] + R3_6[2, 2]*R3_6[2, 2]), R3_6[1, 2]) , Since, sqrt(R3_6[0, 2]*R3_6[0, 2] + R3_6[2, 2]*R3_6[2, 2]) = sin(q5) , sqrt(R3_6[0, 2]*R3_6[0, 2] + R3_6[2, 2]*R3_6[2, 2])/R3_6[1,2] = sin(q5)/cos(q5) = tan(q5) And finally, theta6 = atan2(-R3_6[1,1], R3_6[1, 0]) , Since, -R3_6[1,1]/-R3_6[1, 0] = sin(q5)sin(q6)/sin(q5)cos(q6) = tan(q6) This completes the Inverse Kinematic Analysis of the Kuka arm. Computing Errors : Since all these computations are done numerically, they are bound to accumulate error, here is a plot showing the error in positions generated by the results of IK during a sample trajectory. Such low error values show the stability of the computed trajectory using the analysis discussed above. All of the code and more explanations can be found at my github repository . Here is badly edited video of the awesome robot in action. Next Steps This was a really good learning experience as well as a refresher for me. I got very familiar to the ROS and RViz interface, played with Gazebo and reinforced my knowledge of kinematics . And I got to introduced sympy , which now I absolutely love for its simplicity and power. That said and done, its time to apply this experience on an actual robotic arm. So stay tuned for that...!!! if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"robotics","title":"Inverse Kinematics on Kuka Arm using ROS and Python"},{"url":"posts/machine-intelligence/object-detection-and-image-segmentation-part-2/","text":"Image Segmentation SSD: Single Shot MultiBox Detector Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg : Dec 2016 Source Code Accurate approaches for image segmentation and object detection are available, like Faster R-CNN, but they are too slow for real time applications. Eliminates bounding box proposals and the subsequent pixel or feature resampling stage. Improvements include using a small convolutional filter to predict object categories and offsets in bounding box locations, using separate predictors (filters) for different aspect ratio detections, and applying these filters to multiple feature maps from the later stages of a network in order to perform detection at multiple scales. Faster than YOLO and as accurate as Faster R-CNN. Fig. : SSD framework . (a) SSD only needs an input image and ground truth boxes for each object during training. In a convolutional fashion, we evaluate a small set (e.g. 4) of default boxes of different aspect ratios at each location in several feature maps with different scales (e.g. 8 × 8 and 4 × 4 in (b) and (c)). For each default box, we predict both the shape offsets and the confidences for all object categories \\(((c_1, c_2, \\cdots , c_p))\\) .At training time, we first match these default boxes to the ground truth boxes. For example, we have matched two default boxes with the cat and one with the dog, which are treated as positives and the rest as negatives. The model loss is a weighted sum between localization loss (e.g. Smooth L1) and confidence loss (e.g. Softmax). Model Early layers based on a standard base network. Multi scale feature maps for detection. Convolutional predictors for detection. Default boxes and aspect ratios, similar to anchor boxes used in Faster R-CNN. Fig. 2: A comparison between two single shot detection models: SSD and YOLO. SSD model adds several feature layers to the end of a base network, which predict the offsets to default boxes of different scales and aspect ratios and their associated confidences. SSD with a 300 × 300 input size significantly outperforms its 448 × 448 YOLO counterpart in accuracy on VOC2007 test while also improving the speed. Training Objective Let \\(x_{ij}&#94;p=\\{1,0\\}\\) be an indicator for matching \\(i\\) -th default box to the \\(j\\) -th ground truth box of category \\(p\\) . In the matching strategy used here, we can have \\(\\sum_ix{ij}&#94;p \\ge 1\\) . Overall loss function: $$L(x, c, l, g) = \\frac 1 N (L_{conf}(x,c) + \\alpha L_{loc}(x, l, g))$$ \\(N = $ number of matched default boxes, $L_{loc} = $ localization loss, a smooth L1 loss between predicted box(\\) l \\() and ground truth(\\) g$), and $L_{conf} = $ confidence loss, softmax loss over multiple classes confidences. Data augmentation is crucial. More default box shapes is better. Multiple output layers at different resolutions is better. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Object Detection and Image Segmentation, Part 2"},{"url":"posts/books/improving-the-way-neural-networks-learn/","text":"Notes for the book . Source code for the book. Chapter 3: Improving the way neural networks learn Backpropagation was the basic swing , the fooundation for learning in most work on neural networks. Now we will learn the tricks . These include, A better cost function, known as cross entropy Four regularization methods. A better method for weight initialization . A set of heuristics to help choose good hyper-parameters . And several other techniques, The cross-entropy cost function Yet while unpleasant, we learn quickly when we're decisively wrong. By contrast, we learn slowly when our errors are less well defined. However, turns out this is not always the case with the neural networks we train. If the results are very wrong, it might very well be the case that the activations are close to 0 or 1. And thus the gradients of our sigmoid activation would be very small. This would cause the learning to progress very slowly. Introducing the cross-entropy cost function $$\\begin{eqnarray} C = -\\frac{1}{n} \\sum_x \\left[y \\ln a + (1-y ) \\ln (1-a) \\right], \\tag{57}\\end{eqnarray}$$ Barring the explanation of what it does, Here is the derivative, $$\\begin{eqnarray} \\frac{\\partial C}{\\partial w_j} = \\frac{1}{n} \\sum_x x_j(\\sigma(z)-y). \\tag{61}\\end{eqnarray}$$ Now, this expression says that the change is directly proportional to the error, which is what we would intuitively expect our network to do. The cross-entropy function was specially chosen to have just this property. Ans, in a similar way, we can calculate the partial derivative for the bias. $$\\begin{eqnarray} \\frac{\\partial C}{\\partial b} = \\frac{1}{n} \\sum_x (\\sigma(z)-y). \\tag{62}\\end{eqnarray}$$ When should we use this? Probably always,.. What does the cross-entropy mean? Where does it come from? It comes naturally from our expected gradients, If we start with, $$\\begin{eqnarray} \\frac{\\partial C}{\\partial w_j} & = & x_j(a-y) \\tag{71}\\ \\frac{\\partial C}{\\partial b } & = & (a-y). \\tag{72}\\end{eqnarray}$$ We can come up with this equation, $$\\begin{eqnarray} C = -\\frac{1}{n} \\sum_x [y \\ln a +(1-y) \\ln(1-a)] + {\\rm constant}, \\tag{77}\\end{eqnarray}$$ Cross-entropy also has significance in information theory , where it tells about information gain . Softmax The softmax activation, $$\\begin{eqnarray} a&#94;L_j = \\frac{e&#94;{z&#94;L_j}}{\\sum_k e&#94;{z&#94;L_k}}, \\tag{78}\\end{eqnarray}$$ What's so good about it,.?? $$\\begin{eqnarray} \\sum_j a&#94;L_j & = & \\frac{\\sum_j e&#94;{z&#94;L_j}}{\\sum_k e&#94;{z&#94;L_k}} = 1. \\tag{79}\\end{eqnarray}$$ That is, we can interpret it in terms of probabilities. Which can help us in providing a more intuitive explanation of the results. To the mathematicians at least. But, how does that help with the learning slowdown problem?? Let us consider this cost function, (called log-likelihood ) $$\\begin{eqnarray} C \\equiv -\\ln a&#94;L_y. \\tag{80}\\end{eqnarray}$$ Using this cost with softmax activation, we can derive the gradients w.r.t. weights and bias as, $$\\begin{eqnarray} \\frac{\\partial C}{\\partial b&#94;L_j} & = & a&#94;L_j-y_j \\tag{81}\\\\ \\frac{\\partial C}{\\partial w&#94;L_{jk}} & = & a&#94;{L-1}_k (a&#94;L_j-y_j) \\tag{82}\\end{eqnarray}$$ Which is strikingly similar in form to the gradients we calculated using sigmoid activation with cross-entropy loss. And hence, the same intuitions apply. So, what should we use then,.? sigmoid output layer with cross-entropy loss , or softmax output layer with log0likelihood loss . Actually, both work well. However, softmax log-likelihood is worth using when we want to interpret output activations as probabilities. Overfitting and regularization Models with large number of free parameters can describe amazingly wide range of phenomena. That doesn't make it a good model. It just means that the model has enough freedom to describe any data set of a given size, without really capturing any genuine insights about the phenomena. This model may work for the existing data, however it won't be able to generalize to new situations. Our simple model for MNIST dataset described earlier has 24,000 parameters. That's a lot of parameters. Current state-of-the-art models have millions or even billions of parameters. How can we trust those results? Define overfitting here... Talking about cross-validation,... Get more training data to reduce overfitting!!!! Regularization Techniques used to reduce overfitting. Weight decay or L2 regularization . $$\\begin{eqnarray} C = -\\frac{1}{n} \\sum_{xj} \\left[ y_j \\ln a&#94;L_j+(1-y_j) \\ln (1-a&#94;L_j)\\right] + \\frac{\\lambda}{2n} \\sum_w w&#94;2. \\tag{85}\\end{eqnarray}$$ The first term is the same old cross-entropy loss function. The second term, namely the squared sum of all weights, is the regularization that we've added. and \\(\\lambda > 0\\) , is called the regularization parameter . Worth noting: The regularization terms doesn't include biases. Of course we can add regularization to other cost functions as well. $$\\begin{eqnarray} C = \\frac{1}{2n} \\sum_x \\|y-a&#94;L\\|&#94;2 + \\frac{\\lambda}{2n} \\sum_w w&#94;2. \\tag{86}\\end{eqnarray}$$ Intuitively, the effect of regularization is to make it so the network prefers to learn small weights, all other things being equal. But first, let's see how this effects our equations for gradients and weight/bias updates. $$\\begin{eqnarray} \\frac{\\partial C}{\\partial w} & = & \\frac{\\partial C_0}{\\partial w} + \\frac{\\lambda}{n} w \\tag{88}\\\\ \\frac{\\partial C}{\\partial b} & = & \\frac{\\partial C_0}{\\partial b}. \\tag{89}\\end{eqnarray}$$ And, $$\\begin{eqnarray} b & \\rightarrow & b -\\eta \\frac{\\partial C_0}{\\partial b}. \\tag{90}\\end{eqnarray}$$ $$\\begin{eqnarray} w & \\rightarrow & w-\\eta \\frac{\\partial C_0}{\\partial w}-\\frac{\\eta \\lambda}{n} w \\tag{91}\\\\ & = & \\left(1-\\frac{\\eta \\lambda}{n}\\right) w -\\eta \\frac{\\partial C_0}{\\partial w}. \\tag{92}\\end{eqnarray}$$ A analysis of results with/without regularization on the MNIST data. Conclusion: Regularization helps reduce overfitting. But how?? Why does regularization help reduce overfitting? A standard story people tell to explain what's going on is along the following lines: smaller weights are, in some sense, lower complexity, and so provide a simpler and more powerful explanation for the data, and should thus be preferred. An example with linear/polynomial regression. The idea is that, larger weights in or neural net would allow the model to gather more information, and hence would allow it to learn the noise in the input. Simpler explanations can be more attractive, but that doesn't mean they are right, this intuition should be used with great caution! Further, deciding which of the explanations is simpler can be quite subtle and subjective . Finally, the true test of a model is not its simplicity, but how well it explains the unseen/new(for the model) phenomena. With that said, it is an empirical fact that regularization helps to generalize better. Still, we don't have an entirely satisfactory understanding of what's going on. We don't even have a good understanding of how generalization works. This is particularly galling because in everyday life we humans generalize phenomenally well. We have a system - the human brain - with huge number of free parameters. And we can generalize with very few training examples. Our brains in some sense are regularizing amazingly well. How? Back to our problem, it has been conjectures that the dynamics of gradient descent learning in multilayer nets has a self-regularizing effect . This is fortunate, but disquieting as we don't understand why. In the meantime, we would just use regularization whenever we can. Other techniques for regularization L1 regularization: $$\\begin{eqnarray} C = C_0 + \\frac{\\lambda}{n} \\sum_w |w|. \\tag{95}\\end{eqnarray}$$ Dropout: Here we randomly (and temporarily ) delete half* the hidden neurons in the network, while leaving all the weights and other neurons untouched. We do this only during the training,. When we run the full network during testing, we need to halve the weights outgoing from the hidden units. How does it do regularization? It is a lot like using a committee of smaller networks. The different networks will overfit in different ways, and hopefully, the net effect would reduce overfitting. In another explanation, using dropout forces the neurons to learn more robust features, reducing co-adaptations. Artificially expanding the training data: All about data augmentation Very powerful. Very useful. Weight initialization About using Gaussian distribution for input weights, and its pitfalls. Handwriting recognition revisited: the code The updated Network class, class Network ( object ): def __init__ ( self , sizes , cost = CrossEntropyCost ): self . num_layers = len ( sizes ) self . sizes = sizes self . default_weight_initializer () self . cost = cost Weight initialization, using Gaussian random variables with zero mean and standard deviation 1 divided by the square root of number of connections def default_weight_initializer ( self ): self . biases = [ np . random . randn ( y , 1 ) for y in self . sizes [ 1 :]] self . weights = [ np . random . randn ( y , x ) / np . sqrt ( x ) for x , y in zip ( self . sizes [: - 1 ], self . sizes [ 1 :])] Here is the old weight initializer, using only Gaussian random variables, def large_weight_initializer ( self ): self . biases = [ np . random . randn ( y , 1 ) for y in self . sizes [ 1 :]] self . weights = [ np . random . randn ( y , x ) for x , y in zip ( self . sizes [: - 1 ], self . sizes [ 1 :])] For our newly added cost attribute, class CrossEntropyCost ( object ): @staticmethod def fn ( a , y ): return np . sum ( np . nan_to_num ( - y * np . log ( a ) - ( 1 - y ) * np . log ( 1 - a ))) @staticmethod def delta ( z , a , y ): return ( a - y ) It is implemented as a class since along with the actual cost, we also need a way to calculate the gradient. This class encapsulates both things. And, here is the QuadraticCost that we were using earlier, abstracted into a class, class QuadraticCost ( object ): @staticmethod def fn ( a , y ): return 0.5 * np . linalg . norm ( a - y ) ** 2 @staticmethod def delta ( z , a , y ): return ( a - y ) * sigmoid_prime ( z ) How to choose a neural network's hyper-parameters? That's a huge space to get lost in. Broad strategy: Start with the problem of doing better than chance. The simplest (also fastest or easiest) method that can get you started. Just make sure to get quick feedback of how the model is doing. Then we start with parameter tuning. Learning rate: A sample result while training in MNIST. More rules of thumb about how to choose and change the learning rate. Use early stopping to determine the number of training epochs: Again, rules of thumb on when to use this, and what to do with it. Learning rate schedule: Its good to reduce the learning rate when accuracy starts to plateau. The regularization parameter: \\(\\lambda\\) Start with none. Find a good \\(\\eta\\) . Play with \\(\\lambda\\) . Fine tune \\(\\lambda\\) . Fine tune \\(\\eta\\) again. Mini-batch size: This one depends upon the resources available too. Using a larger mini-batch may make things go faster if sufficient memory is available. Automated techniques: Cross validation: Grid search and its smarter cousins. The space of hyper-parameters is so large, that one never really finishes optimizing, one only abandons the network to posterity. Other techniques Variations on stochastic gradient descent Hessian technique: Uses higher order derivatives . Can converge faster than gradient descent Difficult to apply in practice because of the huge size of the matrix. Momentum-based gradient descent: Based on similar intuition of using higher order derivatives. Introduces a notion of velocity . Gradient affects the velocity and not the position directly. Introduces a kind of friction term, which tends to gradually reduce the velocity. $$\\begin{eqnarray} v & \\rightarrow & v' = \\mu v - \\eta \\nabla C \\tag{107}\\\\ w & \\rightarrow & w' = w+v'. \\tag{108}\\end{eqnarray}$$ Other approaches of minimizing the cost function: BFGS and L-BFGS , and more... Other models of artificial neuron tanh instead of sigmoid relu : This is the new shit if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Improving the way neural networks learn"},{"url":"posts/books/how-the-backpropogation-algorithm-works/","text":"Notes for the book . Source code for the book. Chapter 2: How the backpropogation algorithm works Was introduced in the 70's, but came into light with this paper . Today, it is the workhorse of learning in neural networks. Warm up: a fast matrix-based approach to computing the output from a neural network First, the notations, For weights, For biases and activations, These are related, $$\\begin{eqnarray} a&#94;{l}_j = \\sigma\\left( \\sum_k w&#94;{l}_{jk} a&#94;{l-1}_k + b&#94;l_j \\right), \\tag{23}\\end{eqnarray}$$ which can be rewritten in vectorized form as, $$\\begin{eqnarray} a&#94;{l} = \\sigma(w&#94;l a&#94;{l-1}+b&#94;l). \\tag{25}\\end{eqnarray}$$ This form is more compact and practical as we will be using libraries that provide fast matrix multiplication and vectorization capabilities. The two assumptions we need about the cost function The goal of backpropogation is to calculate the partial derivatives \\(\\partial C / \\partial w\\) and \\(\\partial C / \\partial b\\) . Here is an example of cost function we will be using(there can and will be others). $$\\begin{eqnarray} C = \\frac{1}{2n} \\sum_x \\|y(x)-a&#94;L(x)\\|&#94;2, \\tag{26}\\end{eqnarray}$$ Now, the assumptions, The cost function can be written as an average \\(C = \\frac{1}{n} \\sum_x C_x\\) over cost \\(C_x\\) for individual training examples. The cost function can be written as a function of the outputs from the neural network: $$\\begin{eqnarray} C = \\frac{1}{2} \\|y-a&#94;L\\|&#94;2 = \\frac{1}{2} \\sum_j (y_j-a&#94;L_j)&#94;2, \\tag{27}\\end{eqnarray}$$ The Hadamard product, \\(s \\odot t\\) \\(s \\odot t\\) represents the elementwise product of two vectors. $$\\begin{eqnarray} \\left[\\begin{array}{c} 1 \\\\ 2 \\end{array}\\right] \\odot \\left[\\begin{array}{c} 3 \\\\ 4\\end{array} \\right] = \\left[ \\begin{array}{c} 1 * 3 \\\\ 2 * 4 \\end{array} \\right] = \\left[ \\begin{array}{c} 3 \\\\ 8 \\end{array} \\right]. \\tag{28}\\end{eqnarray}$$ The four fundamental equations behind backpropagation First, we define the error in the \\(j&#94;{th}\\) neuron in the \\(l&#94;{th}\\) layer, \\(\\delta&#94;l_j\\) $$\\begin{eqnarray} \\delta&#94;l_j \\equiv \\frac{\\partial C}{\\partial z&#94;l_j}. \\tag{29}\\end{eqnarray}$$ An equation for the error in the output layer, \\(\\delta&#94;L\\) : $$\\begin{eqnarray} \\delta&#94;L_j = \\frac{\\partial C}{\\partial a&#94;L_j} \\sigma'(z&#94;L_j). \\tag{BP1}\\end{eqnarray}$$ Which can again be rewritten in vectorized form, $$\\begin{eqnarray} \\delta&#94;L = \\nabla_a C \\odot \\sigma'(z&#94;L). \\tag{BP1a}\\end{eqnarray}$$ where, in case of a quadratic cost function, we have \\(\\nabla_a C = (a&#94;L-y)\\) .So, $$\\begin{eqnarray} \\delta&#94;L = (a&#94;L-y) \\odot \\sigma'(z&#94;L). \\tag{30}\\end{eqnarray}$$ An equation for the error \\(\\delta&#94;l\\) in terms of the error in the next layer, \\(\\delta&#94;{l+1}\\) : $$\\begin{eqnarray} \\delta&#94;l = ((w&#94;{l+1})&#94;T \\delta&#94;{l+1}) \\odot \\sigma'(z&#94;l), \\tag{BP2}\\end{eqnarray}$$ Suppose we know the error \\(\\delta&#94;{l+1}\\) at the \\(l+q&#94;{\\rm th}\\) layer. When we apply the transpose weight matrix, \\((w&#94;{l+1})&#94;T\\) , we can think intuitively of this as moving the error backward through the network, giving us some sort of measure of the error at the output of the \\(l&#94;{\\rm th}\\) layer. By combining \\((BP1)\\) and \\((BP2)\\) , we can compute the error \\(\\delta&#94;l\\) for any layer in the network. An equation for the rate of change of the cost with respect to any bias in the network $$\\begin{eqnarray} \\frac{\\partial C}{\\partial b&#94;l_j} = \\delta&#94;l_j. \\tag{BP3}\\end{eqnarray}$$ which can also be written as, $$\\begin{eqnarray} \\frac{\\partial C}{\\partial b} = \\delta, \\tag{31}\\end{eqnarray}$$ An equation for the rate of change of the cost with respect to any weight in the network: $$\\begin{eqnarray} \\frac{\\partial C}{\\partial w&#94;l_{jk}} = a&#94;{l-1}_k \\delta&#94;l_j. \\tag{BP4}\\end{eqnarray}$$ which can also be written as, $$\\begin{eqnarray} \\frac{\\partial C}{\\partial w} = a_{\\rm in} \\delta_{\\rm out}, \\tag{32}\\end{eqnarray}$$ This can also be depicted as, Looking at this image, we can also say that a weight will learn slowly if either the input neuron is low-activation, or if the output neuron has saturated , i.e. it's gradient has become too small(when its either high- or low-activation in case of sigmoid ). Summary of the four equations of backpropagation Proof of the four fundamental equations We start with the expression for \\(\\delta&#94;L\\) $$\\begin{eqnarray} \\delta&#94;L_j = \\frac{\\partial C}{\\partial z&#94;L_j}. \\tag{36}\\end{eqnarray}$$ Applying chain rule, $$\\begin{eqnarray} \\delta&#94;L_j = \\sum_k \\frac{\\partial C}{\\partial a&#94;L_k} \\frac{\\partial a&#94;L_k}{\\partial z&#94;L_j}, \\tag{37}\\end{eqnarray}$$ But, the output activation \\(a_k&#94;L\\) of the \\(k_{\\rm th}\\) neuron only depends on the weighted input \\(x_j&#94;L\\) for the \\(j&#94;{\\rm th}\\) neuron when \\(k=j\\) . And so, \\(\\partial a&#94;L_k / \\partial z&#94;L_j\\) vanishes when \\(k \\neq j\\) . So, $$\\begin{eqnarray} \\delta&#94;L_j = \\frac{\\partial C}{\\partial a&#94;L_j} \\frac{\\partial a&#94;L_j}{\\partial z&#94;L_j}. \\tag{38}\\end{eqnarray}$$ Recalling that, \\(a&#94;L_j = \\sigma(z&#94;L_j)\\) $$\\begin{eqnarray} \\delta&#94;L_j = \\frac{\\partial C}{\\partial a&#94;L_j} \\sigma'(z&#94;L_j), \\tag{39}\\end{eqnarray}$$ which is \\((BP1)\\) in component form. Next, we prove \\((BP2)\\) , which gives an equation for the error \\(\\delta&#94;L\\) in terms of the error in the next layer, \\(\\delta&#94;{l+1}\\) . $$\\begin{eqnarray} \\delta&#94;l_j & = & \\frac{\\partial C}{\\partial z&#94;l_j} \\tag{40}\\\\ & = & \\sum_k \\frac{\\partial C}{\\partial z&#94;{l+1}_k} \\frac{\\partial z&#94;{l+1}_k}{\\partial z&#94;l_j} \\tag{41}\\\\ & = & \\sum_k \\frac{\\partial z&#94;{l+1}_k}{\\partial z&#94;l_j} \\delta&#94;{l+1}_k, \\tag{42}\\end{eqnarray}$$ Now, $$\\begin{eqnarray} z&#94;{l+1}_k = \\sum_j w&#94;{l+1}_{kj} a&#94;l_j +b&#94;{l+1}_k = \\sum_j w&#94;{l+1}_{kj} \\sigma(z&#94;l_j) +b&#94;{l+1}_k. \\tag{43}\\end{eqnarray}$$ Differentiating, $$\\begin{eqnarray} \\frac{\\partial z&#94;{l+1}_k}{\\partial z&#94;l_j} = w&#94;{l+1}_{kj} \\sigma'(z&#94;l_j). \\tag{44}\\end{eqnarray}$$ Substituting back in \\((42)\\) , $$\\begin{eqnarray} \\delta&#94;l_j = \\sum_k w&#94;{l+1}_{kj} \\delta&#94;{l+1}_k \\sigma'(z&#94;l_j). \\tag{45}\\end{eqnarray}$$ which is \\((BP2)\\) in component form. The backpropagation algorithm Input \\(x\\) : Set the corresponding activation \\(a&#94;1\\) for the input layer. Feedforward: For each \\(l = 2, 3, \\ldots, L\\) compute \\(z&#94;l = w&#94;la&#94;{l−1} + b&#94;l\\) and \\(a&#94;l = \\sigma(z&#94;l)\\) . Output error \\(\\delta&#94;L\\) : Compute the vector \\(\\delta&#94;{L} = \\nabla_a C \\odot \\sigma'(z&#94;L)\\) . Backpropagate the error: For each \\(l = L−1, L−2,\\ldots, 2\\) compute \\(\\delta&#94;{l} = ((w&#94;{l+1})&#94;T \\delta&#94;{l+1}) \\odot \\sigma'(z&#94;{l})\\) . Output: The gradient of the cost function is given by \\(\\frac{\\partial C}{\\partial w&#94;l_{jk}} = a&#94;{l-1}_k \\delta&#94;l_j\\) and \\(\\frac{\\partial C}{\\partial b&#94;l_j} = \\delta&#94;l_j\\) . The above steps show back propagation applied w.r.t. a single training example. In practice, it is common to use some a learning algorithm like stochastic gradient descent , computing the gradients of many training examples. In particular, the following algorithm applies gradient descent learning step, based on mini-batches. Input a set of training examples For each training example \\(x\\) : Set the corresponding input activation \\(a&#94;{x,1}\\) and perform the following steps: Feedforward: For each \\(l = 2, 3, \\ldots, L\\) compute \\(z&#94;{x,l} = w&#94;l a&#94;{x,l-1}+b&#94;l\\) and \\(a&#94;{x,l} = \\sigma(z&#94;{x,l})\\) Output error \\(\\delta&#94;{x,L}\\) : Compute the vector \\(\\delta&#94;{x,L} = \\nabla_a C_x \\odot \\sigma'(z&#94;{x,L})\\) . Backpropagate the error: For each \\(l = L-1, L-2, \\ldots, 2\\) compute \\(\\delta&#94;{x,l} = ((w&#94;{l+1})&#94;T \\delta&#94;{x,l+1}) \\odot \\sigma'(z&#94;{x,l})\\) Gradient descent: For each \\(l = L, L-1, \\ldots, 2\\) update the weights according to the rule \\(w&#94;l \\rightarrow w&#94;l-\\frac{\\eta}{m} \\sum_x \\delta&#94;{x,l} (a&#94;{x,l-1})&#94;T\\) , and biases according to the rule \\(b&#94;l \\rightarrow b&#94;l-\\frac{\\eta}{m} \\sum_x \\delta&#94;{x,l}\\) . Of course, in practice, we would also need an outer loop, generating the mini-batches, and another outer loop, stepping through the multiple epochs, but they are just ommitted for simplicity. The code for backpropagation The code for backpropagation was is contained in two methods, update_mini_batch , described in the last post, and backprop method, discussed here, def backprop ( self , x , y ): \"\"\"Return a tuple \"(nabla_b, nabla_w)\" representing the gradient for the cost function C_x. \"nabla_b\" and \"nabla_w\" are layer-by-layer lists of numpy arrays, similar to \"self.biases\" and \"self.weights\".\"\"\" nabla_b = [ np . zeros ( b . shape ) for b in self . biases ] nabla_w = [ np . zeros ( w . shape ) for w in self . weights ] # feedforward activation = x activations = [ x ] # list to store all the activations, layer by layer zs = [] # list to store all the z vectors, layer by layer for b , w in zip ( self . biases , self . weights ): z = np . dot ( w , activation ) + b zs . append ( z ) activation = sigmoid ( z ) activations . append ( activation ) # backward pass delta = self . cost_derivative ( activations [ - 1 ], y ) * \\ sigmoid_prime ( zs [ - 1 ]) nabla_b [ - 1 ] = delta nabla_w [ - 1 ] = np . dot ( delta , activations [ - 2 ] . transpose ()) # Note that the variable l in the loop below is used a little # differently to the notation in Chapter 2 of the book. Here, # l = 1 means the last layer of neurons, l = 2 is the # second-last layer, and so on. It's a renumbering of the # scheme in the book, used here to take advantage of the fact # that Python can use negative indices in lists. for l in xrange ( 2 , self . num_layers ): z = zs [ - l ] sp = sigmoid_prime ( z ) delta = np . dot ( self . weights [ - l + 1 ] . transpose (), delta ) * sp nabla_b [ - l ] = delta nabla_w [ - l ] = np . dot ( delta , activations [ - l - 1 ] . transpose ()) return ( nabla_b , nabla_w ) In what sense is backpropagation a fast algorithm? Let's consider another approach, using numerical gradients, $$\\begin{eqnarray} \\frac{\\partial C}{\\partial w_{j}} \\approx \\frac{C(w+\\epsilon e_j)-C(w)}{\\epsilon}, \\tag{46}\\end{eqnarray}$$ Gradients for the biases can be computed similarly. This looks promising. It's conceptually simple and easy to implement. Certainly much more promising than the chain rule to compute the gradient! However, turns out it is extremely slow. That's because for each distinct weight \\(w_j\\) we need to compute \\(C(w+\\epsilon e_j)\\) in order to compute \\(\\delta C/\\delta w_j\\) . That means, if we have a million weights, to compute the gradient, we need to calculate the cost a million different times, requiring a million forward passes through the network. Backpropagation enables us to simultaneously calculate all the partial derivatives using just one single forward pass through the network, followed by one backward pass. Which is roughly the same as just two forward passes through the network. And so even though backpropagation appears superficially complex, it is much, much faster. But even that speedup was not enough in the early days, and we need some more clever ideas to make deeper networks work. Backpropagation: the big picture So, we have seen what backprop does, and the steps that it takes. But does that give an intuitive idea of how it does what it does? To improve our intuition, let's imagine that we've made a small change \\(\\Delta{w_{jk}&#94;l}\\) to some weight in the network. That will cause a change in its output activation, which will cause a change in all the activations in the next layer. and it would propagate to the final cost function. This change can also be written mathematically as, $$\\begin{eqnarray} \\Delta C \\approx \\frac{\\partial C}{\\partial w&#94;l_{jk}} \\Delta w&#94;l_{jk}. \\tag{47}\\end{eqnarray}$$ This suggests if we propagate the change \\(\\Delta w&#94;l_{jk}\\) forward, we should be able to compute \\(\\delta{C}/\\delta w&#94;l_{jk}\\) . Let's try that out, The change \\(\\Delta w&#94;l_{jk}\\) causes a small change \\(\\Delta a_l_j\\) in the activation of the \\(j&#94;{th}\\) neuron in the \\(l&#94;{th}\\) layer. $$\\begin{eqnarray} \\Delta a&#94;l_j \\approx \\frac{\\partial a&#94;l_j}{\\partial w&#94;l_{jk}} \\Delta w&#94;l_{jk}. \\tag{48}\\end{eqnarray}$$ This will cause change in all the activations in the next layer. We'll concentrate on just a single such activation. Which can be written as, $$\\begin{eqnarray} \\Delta a&#94;{l+1}_q \\approx \\frac{\\partial a&#94;{l+1}_q}{\\partial a&#94;l_j} \\Delta a&#94;l_j. \\tag{49}\\end{eqnarray}$$ Substituting in \\((48)\\) , $$\\begin{eqnarray} \\Delta a&#94;{l+1}_q \\approx \\frac{\\partial a&#94;{l+1}_q}{\\partial a&#94;l_j} \\frac{\\partial a&#94;l_j}{\\partial w&#94;l_{jk}} \\Delta w&#94;l_{jk}. \\tag{50}\\end{eqnarray}$$ And, following similar patterns, it propagates to the change in final cost \\(\\Delta C\\) . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"How the backpropogation algorithm works"},{"url":"posts/machine-intelligence/object-detection-and-image-segmentation/","text":"Image Segmentation Image segmentation review Source A review of segmentation at qure.ai Rich feature hierarchies for accurate object detection and semantic segmentation Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik : Oct 2014 Source Introduces R-CNN, Regions with CNN. Bridging the gap between image classification and object detection. Object detection with R-CNN Region proposals. Uses selective search . Propose a bunch of boxes in the image and see if any of them actually correspond to an object. Feature extraction. Extracts a 4096 dimensional feature vector from each region proposal by propagating a mean subtracted 227 X 227 RGB image through five conv layers and two fully connected layers. These test time detections are highly parallel and the costs can amortized costs are hence low. Training is done by supervised pre-training followed by domain-specific fine-tuning Finally, R-CNN runs a simpler linear regression on the region proposal to generate tighter bounding box coordinates to get our final results. Fast R-CNN Ross Girshick : Sep 2015 Source Implementation 9 X faster at training time. 213 X faster at test time. Streamline the previous process by jointly learning to classify object proposals and refine their spatial locations. Advantages: Higher detection quality than R-CNN and SPPnet. Training is single stage, using a multi-task loss. Training can update all network layers. No disk storage is required for feature caching. Architecture The RoI pooling layer : Run the CNN just once per image and then find a way to share that computation across the ~2000 proposals. Initializing from pre-trained networks. with some modifications. Fine tuning for detection. Hierarchical sampling. Multi-task loss. Classification loss + boounding box regression offsets. Mini-batch Sampling. Back-propagation through RoI pooling layers. SGD hyperparameters. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun : Jan 2016 Microsoft Research Source Implementation Eliminating the bottleneck, region proposals as inputs. Introduces Region Proposal Networks (RPNs) that share convolutional layers with object detection networks. While training we alternate between the region proposal task and object detection task while keeping the proposals fixed. Mask R-CNN Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick : Apr 2017 Facebook AI Research Source Implementation Extends Faster R-CNN by adding another branch that predicts the object mask along with the bounding boxes. Faster R-CNN does not provide pixel-to-pixel alignment between network inputs and outputs. To fix this a layer RoIAlign is proposed which replaces RoIPool layer used previously. The first stage is identical to Faster R-CNN. In the second stage, along with predicting the class and the box offset, Mask R-CNN also outputs a binary mask for each RoI. Multi-task loss is used : \\(L = L_{cls} + L_{bbox} + L_{mask}\\) . Masks are generated for every class without competition among classes. This decouples mask and class prediction. Different architectures are used as convolutional backbone , ResNet and ResNeXt A Review of Deep Learning Techniques Applied to Semantic Segmentation Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, Jose Garcia-Rodriguez : Apr 2017 Source Semantic Segmentation, Deep Learning, Scene Labeling, Object Segmentation This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. This also describes the terminology used as well as some background concepts, then some existing models are reviewed(2017). At last a set of promising future works are discussed. These techniques are not very mature as of yet, mainly because of a lack of unifying picture. CNN Architectures : AlexNet, VGG, GoogleNet, ResNet, etc.. 2D and 3D Datasets : PascalVOC , Microsoft COCO , and more,... Decoder Variants, Integrating Context Knowledge Instance Segmentation RGB-D Data and 3D Data Video Sequences DeepLab : Semantic Image Segmentation with Deep Convolution Nets, Atrous Convolution, and Fully Connected CRFs Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille : May 2017 Source Semantic Segmentation, Atrous Convolution, Conditional Random Fields Introduces upsampled filters(Altrous Convolution) as a tool in dense prediction tasks. Allows us to control the resolution at which feature responses are computed and also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. ???? // Read this again.. U-Net: Convolution Networks for Biomedical Image Segmentation Olaf Ronneberger, Philipp Fischer, Thomas Brox : May 2015 Source Focuses on end-to-end training for segmentation tasks, relying heavily on data augmentation. Fully Convolutional Networks for Semantic Segmentation Jonathan Long, Evan Shelhamer, Trevor Darrell : Mar 2015 Source One of the first works to use Fully Connected layers to create pixel heatmap as output. Introducing Upsampling or Convolution Transpose. From Image-level to Pixel-level Labeling with Convolutional Networks Pedro O. Pinheiro, Ronan Collobert : Apr 2015 Source Weakly supervised segmentation. Put more weights to pixels with known class labels. Uses part of model trained on ImageNet and trains for segmentation on PascalVOC. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Object Detection and Image Segmentation"},{"url":"posts/books/using-neural-nets-to-recognize-handwritten-digits/","text":"Notes for the book . Source code for the book. Chapter 1: Using neural nets to recognize handwritten digits Perceptrons $$\\begin{eqnarray} \\mbox{output} & = & \\left\\{ \\begin{array}{ll} 0 & \\mbox{if } \\sum_j w_j x_j \\leq \\mbox{ threshold} \\\\ 1 & \\mbox{if } \\sum_j w_j x_j > \\mbox{ threshold} \\end{array} \\right. \\tag{1}\\end{eqnarray}$$ Network of perceptrons First, simplify notation, \\(w \\cdot x \\equiv \\sum_j w_j x_j\\) Move, threshold into the network as bias , \\(b \\equiv -\\mbox{threshold}\\) $$\\begin{eqnarray} \\mbox{output} = \\left\\{ \\begin{array}{ll} 0 & \\mbox{if } w\\cdot x + b \\leq 0 \\\\ 1 & \\mbox{if } w\\cdot x + b > 0 \\end{array} \\right. \\tag{2}\\end{eqnarray}$$ Neural Nets as Logic Gates This network represent a NAND Gate NAND gates can do arbitrary computations, And so can the perceptrons, This is reassuring, as this shows that perceptron can be as powerful as any computing device. Bit is disappointing as it makes the perceptrons just another type of NAND . However, these perceptrons can learn . Sigmoid Neurons We want our network to do this, we would be able to learn if we repeat this process gradually improving our weights. However, perceptrons don't behave that way, changing the weights or bias may only completely flip the output, say 0 to 1. This makes it difficult to do gradual improvements to our network. Enter sigmoid , $$\\begin{eqnarray} \\sigma(z) \\equiv \\frac{1}{1+e&#94;{-z}}. \\tag{3}\\end{eqnarray}$$ and, \\(\\sigma(z) \\in [0,1]\\) Output of sigmoid neuron \\( = \\sigma(w \\cdot x+b)\\) Which is a smoothed out version of the step function represented by perceptrons . Using come calculus, $$\\begin{eqnarray} \\Delta \\mbox{output} \\approx \\sum_j \\frac{\\partial \\, \\mbox{output}}{\\partial w_j} \\Delta w_j + \\frac{\\partial \\, \\mbox{output}}{\\partial b} \\Delta b, \\tag{5}\\end{eqnarray}$$ \\(\\Delta \\mbox{output}\\) is a linear function with respect to \\(\\Delta w_j\\) and \\(\\Delta b\\) . This makes it easier to figure out how to change the weights to achieve some output. The architecture of neural networks Feedforward neural network A simple network to classify handwritten digits Learning with gradient descent The dataset . We use the following quadratic cost function , also called the mean squared error or just MSE , $$\\begin{eqnarray} C(w,b) \\equiv \\frac{1}{2n} \\sum_x \\| y(x) - a\\|&#94;2. \\tag{6}\\end{eqnarray}$$ To minimize this function, we use gradient descent , Gradient descent with two variables, We could use calculus to find the minima analytically, but it would become a nightmare as soon as the number of variables go up. So, let's start rolling a ball down the valley,.. $$\\begin{eqnarray} \\Delta C \\approx \\frac{\\partial C}{\\partial v_1} \\Delta v_1 + \\frac{\\partial C}{\\partial v_2} \\Delta v_2. \\tag{7}\\end{eqnarray}$$ We also define a gradient vector \\(\\nabla C\\) , $$\\begin{eqnarray} \\nabla C \\equiv \\left( \\frac{\\partial C}{\\partial v_1}, \\frac{\\partial C}{\\partial v_2} \\right)&#94;T. \\tag{8}\\end{eqnarray}$$ With this defined, we can rewrite, $$\\begin{eqnarray} \\Delta C \\approx \\nabla C \\cdot \\Delta v. \\tag{9}\\end{eqnarray}$$ This equation lets us choose \\(\\Delta v\\) so as to make \\(\\Delta C\\) negative. $$\\begin{eqnarray} \\Delta v = -\\eta \\nabla C, \\tag{10}\\end{eqnarray}$$ where \\(\\eta\\) is a small, positive parameter (known as the learning rate ). Then, we can combine \\((9)\\) and \\((10)\\) to give, \\(\\Delta C \\approx -\\eta \\nabla C \\cdot \\nabla C = -\\eta \\|\\nabla C\\|&#94;2\\) . So, we will use \\((10)\\) to compute \\(\\Delta v\\) , $$\\begin{eqnarray} v \\rightarrow v' = v -\\eta \\nabla C. \\tag{11}\\end{eqnarray}$$ doing this until - we hope - we reach a global minimum. This can also be written as, $$\\begin{eqnarray} w_k & \\rightarrow & w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k} \\tag{16}\\\\ b_l & \\rightarrow & b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l}. \\tag{17}\\end{eqnarray}$$ Calculating all the gradients can become slow, So we do that in batches, using stochastic gradient descent , We randomly choose a mini-batch of samples from the training inputs, \\(X_1, X_2, \\ldots,X_m\\) $$\\begin{eqnarray} \\frac{\\sum_{j=1}&#94;m \\nabla C_{X_{j}}}{m} \\approx \\frac{\\sum_x \\nabla C_x}{n} = \\nabla C, \\tag{18}\\end{eqnarray}$$ So now our update rule becomes, $$\\begin{eqnarray} w_k & \\rightarrow & w_k' = w_k-\\frac{\\eta}{m} \\sum_j \\frac{\\partial C_{X_j}}{\\partial w_k} \\tag{20}\\ b_l & \\rightarrow & b_l' = b_l-\\frac{\\eta}{m} \\sum_j \\frac{\\partial C_{X_j}}{\\partial b_l}, \\tag{21}\\end{eqnarray}$$ We do this update for all the training data, dividing it into batches. This completes a single epoch . Implementing our network to classify digits Clone the repo, git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git We will be using 10,000 images from the test set as our validation set . This will be used for hyper-parameter tuning . The Network class class Network ( object ): def __init__ ( self , sizes ): self . num_layers = len ( sizes ) # Number of layers self . sizes = sizes # Number of neurons in the respective layer self . biases = [ np . random . randn ( y , 1 ) for y in sizes [ 1 :]] self . weights = [ np . random . randn ( y , x ) for x , y in zip ( sizes [: - 1 ], sizes [ 1 :])] To create a Nueral Net with 2 neurons in the first layer, 3 neurons in the second layer, and 1 neuron in the final layer, net = Network ([ 2 , 3 , 1 ]) It then generates random initial bias and weights for the layers. We can calculate the activations of a given layer by, $$\\begin{eqnarray} a' = \\sigma(w a + b). \\tag{22}\\end{eqnarray}$$ Here we are vectorizing out operations to denote(and compute) them compactly. So, we can define the sigmoid activation in our code, def sigmoid ( z ): return 1.0 / ( 1.0 + np . exp ( - z )) and the feedforward function in the Network class, def feedforward ( self , a ): \"\"\"Return the output of the network, if `a` is the input\"\"\" for b , w in zip ( self . biases , self . weights ): a = sigmoid ( np . dot ( w , a ) + b ) return a Now, the main thing that we want our network to do is to learn, so we'll define an SGD method def SGD ( self , trainig_data , epochs , mini_batch_size , eta , test_data = None ): \"\"\"Train the neural network using mini-batch stochastic gradient descent. The \"training_data\" is a list of tuples \"(x,y)\" representing the training inputs and the desired outputs. If \"test_data\" is provided then the network will be evaluated against then test data after each epoch. This is good for tracking the progress, but slows things down\"\"\" if test_data : n_test = len ( test_data ) n = len ( trainig_data ) for j in xrange ( epochs ): random . shuffle ( trainig_data ) mini_batches = [ trainig_data [ k : k + mini_batch_size ] for k in xrange ( 0 , n , mini_batch_size )] for mini_batch in mini_batches : self . update_mini_batch ( mini_batch , eta ) if test_data : print ( \"Epoch {0}:{1}/{2}\" . format ( j , self . evaluate ( test_data ), n_test )) else : print ( \"Epocj {0} complete.\" . format ( j )) In the above code the training data is randomly divided into mini batches and for each batch the gradient step is applied using self.update_mini_batch(mini_batch, eta) . def update_mini_batch ( self , mini_batch , eta ): \"\"\"Update the network's weights and biases by applying gradient descent using backpropogation to a single mini batch. The \"mini_batch\" is a list of tuples \"(x,y)\", and \"eta\" is the learning_rate.\"\"\" nabla_b = [ np . zeros ( b . shape ) for b in self . biases ] nabla_w = [ np . zeros ( w . shape ) for w in self . weights ] for x , y in mini_batch : delta_nabla_b , delta_nabla_w = self . backprop ( x , y ) nabla_b = [ nb + dnb for nb , dnb in zip ( nabla_b , delta_nabla_b )] nabla_w = [ nw + dnw for nw , dnw in zip ( nabla_w , delta_nabla_w )] self . weights = [ w - ( eta / len ( mini_batch )) * nw for w , nw in zip ( self . weights , nabla_w )] self . biases = [ b - ( eta / len ( mini_batch )) * nb for b , nb in zip ( self . biases , nabla_b )] Here, most of the work is done by the line,(which is explained in the next article in the series) delta_nabla_b , delta_nabla_w = self . backprop ( x , y ) We can now load some data using the helper scripts in the repo, >>> import mnist_loader >>> training_data , validation_data , test_data = \\ ... mnist_loader . load_data_wrapper () And then create a network, >>> import network >>> net = network . Network ([ 784 , 30 , 10 ]) Finally, we can use SGD to learn from the MNIST data, >>> net . SGD ( trainig_data , epochs = 30 , mini_batch_size = 10 , eta = 3.0 , test_data = validation_data ) Here is the output you should expect, Epoch 0 : 9129 / 10000 Epoch 1 : 9295 / 10000 Epoch 2 : 9348 / 10000 ... Epoch 27 : 9528 / 10000 Epoch 28 : 9542 / 10000 Epoch 29 : 9534 / 10000 That is 95.42 percent accuracy in 28 epochs . Tuning the hyperparameters This can be challenging. The art of debugging is required here. The current state-of-the-art for this dataset is 99.79 percent. Towards Deep Learning How does the network does what it does? Possibly by, breaking down the problem into subproblems and finding those answers . But, this breaking down is done by the network automatically while learning, and we don't really have a say in it. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Using neural nets to recognize handwritten digits"},{"url":"posts/machine-intelligence/neural-network-architectures/","text":"Deep Learning Architectures Self-Normalizing Neural Networks Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter : Sep 2017 Source Deep learning is setting new benchmarks everyday with the help of RNNs and CNNs. However, looking at problems that are not related to vision or sequential tasks, gradient boosting, random forests, or support vector machines are winning most of the competitions(Eg. Kaggle, HIGGS Challenge ). With CNNs success, batch normalization and other stochastic regularization techniques has evolved into a standard. Both RNNs and CNNs can stabilize learning with weight sharing. However, this is not very useful with FNNs, and often leads to high variance. Self-Normalizing Neural Networks Definition 1 : A neural network is self-normalizing if it possesses a mapping \\(g : \\Omega \\mapsto\\Omega\\) for each activation \\(y\\) that maps mean and variance from one layer to the next and has a stable and attracting fixed point depending on \\((\\omega,\\tau)\\) in \\(\\Omega\\) . Furthermore, the mean and the variance remain in the domain \\(\\Omega\\) , that is \\(g(\\Omega)\\subseteq\\Omega\\) , where \\(\\Omega = \\{(\\mu,\\nu)|\\mu\\in[\\mu_{min}, \\mu{max}], \\nu\\in[\\nu_{min}, \\nu{max}]\\}\\) . When iteratively applying the mapping \\(g\\) , each point within \\(\\Omega\\) converges to this fixed point. So, SNNs keep normalization of activations when propagating them through layers of the network. Constructing SNNs : The activation function, SELU $$\\text{selu}(x) = \\lambda\\begin{cases}x, & \\text{if } x \\ge 0 \\\\ \\alpha e&#94;x - \\alpha, & \\text{if } x \\leq 0 \\end{cases}$$ This activation allows to construct a mapping \\(g\\) with properties that lead to SNNs. They cannot be derived with (scaled) ReLUs, sigmoid units, \\(tanh\\) units and leaky ReLUs. For weight initialization \\(\\omega=0\\) and \\(\\tau=1\\) for all units in higher layer is proposed. New Dropout techniques are introduced. Benchmarks compared for UCI repository datasets, outperforming FNNs with and without normalization techniques, such as batch, layer and weight normalization or specialized architectures such as ResNets. Also proved that SNNs do not face vanishing and exploding gradients problem and therefore work well for architectures with many layers. The best performaing SNNs are typically very deep in contrast to other FNNs. Understanding deep learning requires rethinking generalization Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals : Feb 2017 Source Neural networks have far more often trainable parameters than the number of samples they are trained on. Even then they exhibit small generalization errorr i.e. difference between \"training error\" and \"test error\". Effective Capacity Of Neural Networks Randomization tests. Standard architectures were trained on a copy of data where the true labels were replaced by random labels. Deep neural networks easily fit random labels i.e. the they achieve 2 test error. The test error was of course no better than random chance as there was no correlation between the training and test labels. Also replacing the true images with random pixels(Gaussian noise), we observe that CNNs continue to fit the data with zero training error. This has the following implications: The effective capacity of neural networks is sufficient for memorizing the entire dataset. Even optimization on random labels remains easy. In fact, training time increases only by a small constant factor compared with training on the true labels. Randomizing the labels is solely a data transformation, leaving all other properties of the learning problem unchanged. The role of regularization Explicit regularization may improve generalization performance, but is neither necessary not by itself sufficient for controlling generalization error. \\(l_2\\) regularization sometimes even helps optimization, illustrating its poorly understoof nature in deep learning. Finite sample expressivity Theorem 1. There exists a two-layer neural network with ReLU activations and \\(2n+d\\) weights that can represent any function on a sample of size \\(n\\) in \\(d\\) dimensions. Implicit Regularization : An Appeal To Linear Models Arguments showing that it is not necessarily easy to understand the source of generalization for linear models either. Do all global minima generalize equally well? Is there a way to determine when one global minimum will generalize whereas another will not? In case of a linear model, even the curvature of the loss function would be the same. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Neural Network Architectures"},{"url":"posts/machine-intelligence/style-transfer-part-2/","text":"Style Transfer Artistic style transfer for videos Manuel Ruder, Alexey Dosovitskiy, Thomas Brox : Apr 2016 Source The previously discussed techniques have been applied to videos on per frame basis. However, processing each frame of the video independently leads to flickering and false discontinuities, since the solution of the style transfer task is not stable. To regularize the transfer temporal constraints using optical flow are introduced. Notation \\(\\mathbf p&#94;{(i)}\\) is the \\(i&#94;{th}\\) frame of the original video. \\(\\mathbf a\\) is the style image. \\(\\mathbf x&#94;{(i)}\\) are the stylized frames to be generated. \\(\\mathbf {x'}&#94;{(i)}\\) is the initialization of the style optimization algorithmat frame \\(i\\) . Short-term consistency by initialization Most basic way to yield temporal consistency is to initialize the optimization for the frame \\(i+1\\) with the stylized frame \\(i\\) . Does not perform very well if there are moving objects in the scene, so we use optical flow. \\(\\mathbf {x'}&#94;{(i+1)}=\\omega_i&#94;{i+1}\\mathbf x&#94;{(i)}\\) . Here \\(\\omega_i&#94;{i+1}\\) denotes the function tha warps a given image using the optical flow field that was estimated between \\(\\mathbf p&#94;{(i)}\\) and \\(\\mathbf p&#94;{(i+1)}\\) . DeepFlow and EpicFlow , both based on Deep Matching are used for optical flow estimation. Temporal consistency loss Let \\(\\mathbf w = (u,v)\\) be the optical flow in forward direction and \\(\\mathbf {\\hat w}=(\\hat u, \\hat v)\\) the flow in backward direction. Then, \\(\\mathbf {\\tilde w}(x,y) = \\mathbf{w}((x,y) + \\mathbf{\\hat{w}}(x,y))\\) is the forward flow warped to the second image. In areas without disoclusion, this warped flow should be approximately the opposite of the backward flow. So, we can find the areas of disoclusions where \\(|\\mathbf{\\widetilde{w} + \\hat{w}}|&#94;2 > 0.01(|\\mathbf{\\widetilde{w}}|&#94;2+|\\mathbf{\\hat{w}}|&#94;2)+0.5\\) . and motion boundaries can be detected where \\(|\\Delta\\mathbf{\\hat{u}}|&#94;2+|\\Delta\\mathbf{\\hat{v}}|&#94;2>0.01|\\mathbf{\\hat{w}}|&#94;2+0.002\\) . So, temporal consistency loss function penalizes deviations from the warped image in regions where the optical flow is consistent and estimated with high confidence. $$\\mathcal{L}_{temporal}(\\mathbf{x,\\omega,c}) = \\frac1D\\sum_{k=1}&#94;Dc_k\\cdot(x_k-\\omega_k)&#94;2$$ Here, \\(\\mathbf{c}\\in [0,1]&#94;D\\) is per-pixel weighing of the loss and \\(D=W\\times{H}\\times{C}\\) is the dimensionality of the image. We define \\(\\mathbf{c}&#94;{(i-1,i)}\\) between frames \\(i-1\\) and \\(i\\) as \\(0\\) in disoccluded regions and the motion boundaries, and 1 everywhere else. So, overall loss takes the form, $$\\mathcal L_{shortterm}(\\mathbf{p}&#94;{(i)},\\mathbf{a},\\mathbf{x}&#94;{(i)}) = \\alpha\\mathcal{L}_{content}(\\mathbf{p}&#94;{(i)},\\mathbf{x}&#94;{(i)}) + \\beta\\mathcal{L}_{style}(\\mathbf{a},\\mathbf{x}&#94;{(i)}) + \\gamma\\mathcal{L}_{temporal}(\\mathbf{x}&#94;{(i)}, \\omega_{i-1}&#94;i(\\mathbf{x}&#94;{(i-1)}), \\mathbf{c}&#94;{(i-1,i)})$$ Long-term consistency The short-term model has the following limitation: when some areas are occluded in some frame and disoccluded later, these areas will likely change their appearance in the stylized video. So, we need to use a penalization for deviations from more distant frames too. \\(J\\) is the set of relative indices that each frame takes into account. So, the loss function is, $$\\mathcal L_{longterm}(\\mathbf{p}&#94;{(i)},\\mathbf{a},\\mathbf{x}&#94;{(i)}) = \\alpha\\mathcal{L}_{content}(\\mathbf{p}&#94;{(i)},\\mathbf{x}&#94;{(i)}) + \\beta\\mathcal{L}_{style}(\\mathbf{a},\\mathbf{x}&#94;{(i)}) + \\gamma\\sum_{j\\in J:i-j\\geq1}\\mathcal{L}_{temporal}(\\mathbf{x}&#94;{(i)}, \\omega_{i-j}&#94;i(\\mathbf{x}&#94;{(i-j)}), \\mathbf{c}_{long}&#94;{(i-j,i)})$$ where, \\(\\mathbf{c}_{long}&#94;{(i-j,i)}=\\text{max}(\\mathbf{c}&#94;{(i-j,i)} - \\sum_{k\\in J:i-k>i-j}\\mathbf{c}&#94;{(i-k,i)}, \\mathbf{0})\\) Multi-pass algorithm The image boundaries tend to have less contrast and less diversity than other areas. This is not a problem for mostly static videos, but with large camera motion, these effects can creep in towards the center, which leads to lower quality images over time. So, we use a multi-pass algorithm which processes the whole sequence in multiple passes and alternating directions. Each pass consists of a lower number of iterations without full convergence. The sequence is run in alternating directions with each flow and blended for some number of iterations till some convergence. The multi-pass algorithm can be combined with temporal consistency loss described above. Achieve good results if temporal loss is disabled in several initial passes and enabled in later passes after the images had stabilized. Long term motion estimate... Artifacts at image boundaries,... Implementation : https://github.com/manuelruder/artistic-videos Watch in action : https://youtu.be/vQk_Sfl7kSc Instance Normalization: The Missing Ingredient for Fast Stylization Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky : Sep 2016 Source Learn a generator network \\(g(x,z)\\) that can apply to a given input image \\(x\\) the style of another \\(x_0\\) . \\(g\\) is a convolutional neural network learned from examples \\(x_t\\) by solving $$\\text{min}_g\\frac1n\\sum_{t=1}n\\mathcal{L}(x_0, x_t, g(x_t, z_t)), \\text{where }z_t \\sim\\mathcal{N}(0,1)$$ Perceptual Losses for Real-Time Style Transfer and Super Resolution Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li : 2016 Source The system consists of two components : image transformation network \\(f_W\\) (deep resnet with encoder-decoder scheme parameterized by weights \\(W\\) ) and a loss network \\(\\phi\\) that is used to define several loss functions \\(l_i,...l_k\\) . The optimization problem becomes, $$W&#94;*=\\text{arg min}_W\\mathbf{E}_{x,\\{y_i\\}}[\\sum_{i=1}\\lambda_i l_i(f_W(x), y_i)]$$ Uses the loss network \\(\\phi\\) to define a feature reconstruction loss \\(l_{feat}&#94;{\\phi}\\) and style reconstruction loss \\(l_{style}&#94;{\\phi}\\) that measures differences in content and style between images. Simple loss functions : In addition to the perceptual losses discussed above(and described earlier), two simple loss functions that depend only on low level pixel information are used. Pixel Loss : Can only be used when ground truth is available. Total Variation Regularization : to encourage spatial smoothness. Implementation* : https://github.com/jcjohnson/fast-neural-style Stylizing Face Images via Multiple Exemplars Yibing Song, Linchao Bao, Shengfeng He, Qingxiong Yang, Ming-Hsuan Yang : Aug 2017 Source Existing methods using a single exemplar lead to inaccurate results when the exemplar does not contain sufficient stylized facial components for a given photo. Proposes a style transfer algorithm in which a Markov random field is used to incorporate patches from multiple exemplars. The proposed method enables the use of all stylization information from different exemplars. And, proposes an artifact removal methods based on an edge-preserving filter. It removes the artifacts introduced by inconsistent boundaries of local patches stylized from different exemplars. In addition to visual comparison conducted by existing methods, performs quantitative evaluations using both objective and subjective metrics to demonstrate effectiveness of the proposed method. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Style Transfer, Part 2"},{"url":"posts/books/fundamentals-of-computer-graphics-part-3/","text":"","tags":"books","title":"Fundamentals of Computer Graphics, Part 3"},{"url":"posts/books/neural-networks-and-deep-learning/","text":"Notes for the book . Source code for the book. Chapter 1 : Using neural nets to recognize handwritten digits Chapter 2 : How the backpropogation algorithm works Chapter 3 : Improving the way neural networks learn","tags":"books","title":"Neural Networks and Deep Learning"},{"url":"posts/machine-intelligence/style-transfer-part-1/","text":"Style Transfer A Neural Style Algorithm of Artistic Style Leon A. Gatys, Alexander S. Ecker, Matthias Bethge : Sep 2015 Source In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. Then we came across Deep Neural Networks. Higher layers in the network capture the high-level content in terms of objects and their arrangement in the input image. We represent these feature responses as content representation . $$\\mathcal L_{content}(\\vec p,\\vec x,l) = \\frac12\\sum_{i,j}{(F&#94;l_{ij} - P&#94;l_{ij})&#94;2}$$ For style we need to capture correlations(given by Gram matrix \\(G&#94;l \\in \\mathcal R&#94;{N_l \\times N_l}\\) where \\(G&#94;l_{ij} = \\sum_kF&#94;l_{ik}F&#94;l_{jk}\\) ) between different filter responses. This representation captures the texture information of the input, but not the global arrangement. This multi-scale representation is called style representation . $$E_l = \\frac1{4N&#94;2_lM&#94;2_l}\\sum_{ij}(G&#94;l_{ij}-A&#94;l_{ij})&#94;2$$ $$\\mathcal L_{style}(\\vec a,\\vec x) = \\sum_{l=0}&#94;Lw_lE_l$$ So, we can manipulate both content and style separately. The images are synthesised by finding an image that simultaneously matches the content representation of the photograph and the style representation of the respective piece of art. $$\\mathcal L_{total}(\\vec p,\\vec a,\\vec x) = \\alpha\\mathcal L_{content}(\\vec p,\\vec x) + \\beta\\mathcal L_{style}(\\vec a,\\vec x)$$ Gallleries Style Transfer Studies Implementations Neural Style, JC Johnson, Lua Improving the Neural Algorithm of Artistic Style Roman Novak, Yalroslav Nikulin : May 2016 Source Objectives addressed in this paper: Similar areas of the content image should be repainted in a similar way. Different areas should be painted differently. Useful Modifications, A better per-layer content/style weighting scheme. \\(w_l&#94;s = 2&#94;{D-d(l)},\\quad w_l&#94;c=2&#94;{d(l)}\\) This indicates that most important style properties come from bottom layers, while content is mostly represented by activations in the upper layers. Using more layers to capture more style properties. Used all 16 conv layers of VGG-19 for calculating Gram matrices. Using shifted activations when computing Gram matrices to eliminate sparsity and make individual entries more informative and also speed-up style transfer convergence. \\(G&#94;l=(F&#94;l+s)(F&#94;l+s)&#94;T\\) , (where \\(s=-1\\) for best results). Targeting correlations of features belonging to different layers to capture more feature interactions. \\(G&#94;{lk}=F&#94;l[up(F&#94;k)]&#94;T\\) , if \\(X_k \\leq X_l\\) This blows up the number of definitions of style( \\(G\\) ) to \\(2&#94;{16&#94;2}\\) for 16 layers of VGG-19. However, experiments also show that tieing in distant layers gives poor results. Correlation Chain Instead of considering all layer combinations, use only a \"chained\" representation, \\(\\{G&#94;{l,l-1}|l=2...16\\}.\\) So, only correlations with immediate neighbors are considered. Blurred Correlations While calculating correlations, the smaller feature layer is upsampled, but even after having the same dimensions, the feature maps may still correspond to features of different scales. To overcome this we use blurring. \\(G&#94;{lk}=F&#94;l[blur&#94;{l-k}\\circ up(F&#94;k)]&#94;T\\) This gives positive results, but it does complicate the objective function and results in slow and unreliable convergence. Some Modifications that did not work out in the end, Gradient Masking Amplifying Activations Adjacent Activations Correlations Content-aware Gram Matrices Gram Cubes Experiments Preserving Color in Neural Artistic Style Transfer Leon A. Gatys, Matthias Bethge, Aaron Hertzmann, Eli Shechtman : Jun 2016 Source The original style transfer method also copies the colors of the style image, which might be undesirable in many cases. Approach #1: Color histogram matching Transform style image \\((S)\\) to match the colors of content image \\((C)\\) . This produces a new style \\((S')\\) . The algorithm remains unchanged otherwise. We have several different options for the initial color transfer. Linear method, \\(\\mathbf x_{S'}\\leftarrow \\mathbf Ax_S+\\mathbf b\\) \\(\\mathbf b=\\mu_C- \\mathbf A\\mu_S\\) , where \\(\\mu_C\\) and \\(\\mu_S\\) are mean colors. \\(\\mathbf A\\Sigma_S \\mathbf A&#94;T=\\Sigma_C\\) , where \\(\\Sigma_C\\) and \\(\\Sigma_C\\) are pixel covariances. \\(\\mathbf A\\) can be computed using Cholesky decomposition, or by using Image Analogies. Color transfer before style transfer generally gives better results. Approach #2: Luminance-only transfer This approach is motivated by the observation that visual perception is far more sensitive to change in luminance than in color. \\(L_S\\) and \\(L_C\\) are luminance channels extracted from the style and content images. Use a YIQ color space, the color information represented by I and Q channels is combined with \\(L_T\\) to produce the final output image. \\(L_{S'}=\\frac {\\sigma_C}{\\sigma_S}(L_S - \\mu_S) + \\mu_C\\) Comparison Linear color transfer onto the style image, before style transfer. Limited by how well the color transfer from content to style works. Style transfer only in the luminance channel. Preserves the colors of content image perfectly. However, dependencies between the luminance and the color channels are lost in the output image. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Style Transfer, Part 1"},{"url":"posts/books/elements-of-statistical-learning-part-3/","text":"Chapter 14: Unsupervised Learning Introduction Learning without labels.. Association Rules Market Basket Analysis The Apriori Algorithm Unsupervised as Supervised Learning Data Pooling Generalized Association Rules Cluster Analysis Priority Matrices Dissimilarities Based on Attributes Object Dissimilarity Clustering Algorithms Combinatorial Algorithms K-means Gaussian Mixtures as Soft K-Means Clustering Vector Quantization K-medoids Hierarchical Clustering Self-Organizing Maps Principal Components, Curves and Surfaces Principal Components Principal Curves and Surfaces Spectral Clustering Kernel Principal Components Sparse Principal Components Non-Negative Matrix Factorization Independent Component Analysis and Exploratory Projection Pursuit Nonlinear Dimension Reduction and Multidimensional Scaling The Google PageRank Algorithm Chapter 15: Random Forests Definition of Random Forests Details of Random Forests Chapter 16: Ensemble Learning Boosting and Regularization Paths Learning Ensembles Chapter 17: Undirected Graphical Models Markov Graphs and Their Properties Undirected Graphical Models for Continous Variables Undirected Graphical Models for Discrete Variables Chapter 18: High Dimensional Problems: p >> N Diagonal Linear Discriminant Analysis and Nearest Shrunken Centroids Linear Classifiers and Quadratic Regularization Regularized Discriminant Analysis Logistic Regression with Quadratic Regularization The Support Vector Classifier Feature Selection Computational Shortcuts When p >> N Linear Classifiers with {L_1} Regularization Classification when Features are Unavailable High-Dimensional Regression: Supervised Principal Components Feature Assessment and the Multiple Testing Problem","tags":"books","title":"Elements Of Statistical Learning, Part 3"},{"url":"posts/robotics/soft-robotics/","text":"Very minimal notes on some papers or articles that I recently read. Mainly for logging purposes. Robotics Soft Robotics Soft Robotics: A Perspective—Current Trends and Prospects for the Future Carmel Majidi : 2013 Source Soft robots are primarily composed of easily deformable matter such as fluids, gels, and elastomers that match the elastic and rheological properties of biological tissue and organs. Like an octopus squeezing through a narrow opening or a caterpillar rolling through uneven terrain, a soft robot must adapt its shape and locomotion strategy for a broad range of tasks, obstacles, and environmental conditions. This emerging class of elastically soft, versatile, and biologically inspired machines represents an exciting and highly interdisciplinary paradigm in engineering that could revolutionize the role of robotics in healthcare, field exploration, and cooperative human assistance. Most suitable for environments and applications that require interaction with soft materials and organisms and/or artificial replication of biological functions. Compliance Matching To prevent injury or robot immobility, the surface e of soft robots must be adequately soft and deformable in order to distribute forces over a large contact area and eliminate interfacial stress concentrations. Compliance matching is particularly important in the subdomain of wearable technologies for human motor assistance. Potential Applications Soft wearables for human motor assistance. Biologically inspired field robots for autonomous exploration. At the scales of invertebrates, insects and microorganisms, may also eventually be used for drug delivery, minimally invasive surgery, and medical implants. It is unlikely that they would be useful for heavy-duty industrial applications. Beyond Robotics As the field of soft robotics grows, the supporting softmatter technologies used in sensing, electronics, and actuation will continue to mature and will eventually appear in application domains. Strechable microelectronics.","tags":"robotics","title":"Soft Robotics"},{"url":"posts/books/elements-of-statistical-learning-part-2/","text":"Chapter 7: Model Assessment and Selection Introduction Bias, Variance and Model Complexity The Bias-Variance Decomposition Example : Bias-Variance Tradeoff Optimism of the Training Error Rate Estimates of In-Sample Prediction Error The Effective Number of Parameters Also known as effective degree of freedom \\(= trace(S)\\) , where \\(\\hat y=Sy\\) . The Bayesian Approach and BIC Minimum Description Length Vapnik-Chervonenkis Dimension ☠ Cross-Validation 👍 K-Fold Cross Validation The Wrong and Right Way to Do Cross-validation Does Cross-Validation Really Work? Bootstrap Methods Conditional or Expected Test Error? ☠ Chapter 8: Model Inference and Averaging Introduction: Provides a general exposition of maximum likelihood approach and the Bayesian method of inference. The Bootstrap and Maximum Likelihood A model-free, non-parametric method for prediction. Bayesian Methods Relationship Between the Bootstrap and Bayesian Inference ☠ The EM Algorithm The EM algorithm in General ☠ MCMC(Markov Chain Monte-Carlo) for sampling from the Posterior Bagging Stochastic Search : Bumping Chapter 9: Additive Models, Trees, and Related Methods Generalized Additive Models Provides an extension to linear models, making them more flexible while retaining much of their interpretability. Tree Based Methods Regression and Classification trees. Gini index and Cross Entropy loss Overfitting Lack of smoothness PRIM(Patient Rule Induction Method) : Bump Hunting MARS: Multivariate Adaptive Regression Splines Hierarchical Mixture of Experts Chapter 10: Boosting and Additive Trees Boosting Methods Combines the output of many \"weak\" classifiers to produce a powerful \"committee\" . AdaBoost Boosting Fits an Additive Model \"Off the Shelf\" Procedures for Data Mining Boosting Trees Numerical Optimization via Gradient Boosting Regularization Shrinkage Subsampling Chapter 11: Neural Networks Projection Pursuit Regression Neural Networks Fitting Neural Networks Issues in Training Neural Nets Initizlization Overfitting Scaling of the Inputs Number of hidden units and layers Multiple Minima Performance comparion Computational Considerations Chapter 12: Support Vector Machines and Flexible Discriminants The Support Vector Classifier maximizing margin. Computing the Support Vector Classifier ☠ Support Vector Machines and Kernals Computing the SVM for Classification The SVM as a Penalization Method Function Estimation and Reproducing Kernals ☠ SVMs and the Curse of Dimensionality A Path Algorithm for the SVM Classifier ☠ Support Vector Machines for Regression Regression and Kernals Generalizing Linear Discriminant Analysis Flexible Discriminant Analysis Penalized Discriminant Analysis Chapter 13: Prototype Methods and Nearest-Neighbors Prototype Methods K-means Clustering Learning Vector Quantization Gaussian Mixtures k-Nearest-Neighbors Classifiers Adaptive Nearest-Neighbors Methods if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Elements Of Statistical Learning, Part 2"},{"url":"posts/robotics/mobile-robots/","text":"Very minimal notes on some papers or articles that I recently read. Mainly for logging purposes. Robotics Kinematics tf : The Transform Library Tully Foote Open Source Robotics Foundation The need for tf : to provide a standard way to keep track of coordinate frames and transform data within the entire system to a component user without requiring knowledge of all the coordinate frames. Broadcaster and Listner modules. Closely related to scene graphs . There are several different sources of information regarding various coordinate frames in a system, coming from sensors connected to hardware. This data can come at different frequencies. tf must accept asynchronous inputs and be robust to delayed or lost information. Must be robust to a distributed computing environment with unreliable networking and non negligible latency. Ability to dynamically change the relationship between frames to account for dynamic/varying structure. Design Transforms and frames are represented as a graph with transforms as edges and frames as nodes. The graphs can be disconnected, and must be directed ,acyclic and quickly searchable. Limiting the graphs to trees enables this. Difference from scene graphs: they are made to be iterated across periodically, while tf is designed to be queried for values asynchronously. History is also required. This data collectively is called a Stamp . Broadcaster broadcasts messages every time an update is heard about a specific transform. Listner collects the values and interpolates using SLERP, without assuming the presence of a future frame. The interpolation is a critical ability, as it allows the system to be asynchronous and robust to lost packets. Transform Computation using chaining. \\(T_c&#94;a=T_a&#94;b\\timesT_b&#94;c\\) . Strengths : Efficiency, Flexibility Extensions : Support for velocity. Transforming data in time. Solving Kinematics Problems of a 6-DOF Robot Manipulator Computer Science Department, The University of Georgia : 2015 Source An analytical approach for solving forward kinematics problem of a serial robot manipulator with six degrees of freedom and a specific combination of joints and links to formulate the position of gripper by a given set of joint angles. The functional state of each joint related to its successive joint in the design of this robot is as follows: $$ R_1 \\bot R_2 \\parallel R_3 \\bot R_4 \\bot R_5 \\bot R_6 $$ in which \\(R\\) indicates a revolute joint and the indices describe the position of the joint relative to the base of the robot. Uses D-H parameter convention for assigning coordinate frames. D-H parameter analysis for Kuka KR60 can be found here Robot Grasping Robotic Grasping and Contact: A Review Source Survey of work done in last two decades. Functions of Human hand Explore : haptics Restrain : fixturing Manipulation : dexterous manipulation Closure properties of grasps Contact modelling the grap Force Analysis Contact model Kinematics of contact Contact compliance Measures of grasp performance Grasping and the kinematics of the hand Dynamics Mobile Robots Modular and Reconfigurable Mobile Robots Source Classification Modular robots with mobile configuration change(MCC) S-bots Uni-Rovers JL-I and JL-II Millibots AMOEBA Modular robots with whole body locomotion(WBL) Whole body locomotion in chain architecture CONRO/PolyBot GZ-I CKBot Whole body locomotion in a lattice architecture Macro robots in a lattice architecture Crystalline Odin I-Cubes Catoms Mini robots in a lattice archtecture Reconfigurable mechanisms in a lattice architecture Whole body locomotion in a hybrid architecture M-TRAN/iMobot Molecubes ATRON YaMOR SuperBot if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"robotics","title":"Mobile Robots"},{"url":"posts/books/algorithms-part-7/","text":"Chapter 10: Quntized Algorithms There is a catch ofcourse: this algorithm needs a quantum computer to execute. Qubits, superposition and measurment Such a superposition is the basic unit of encoded information in quantum computers. It is called a qubit . This linear superposition is however private to the electron. For us to get a glimpse of the electron's state, we must make a measurment , and when we do get a single bit of information, 0 or 1. How do we encode \\(n\\) bits of information? We could choose \\(k=2&#94;n\\) levels of the hydrogen atom. But a more promising option is to use \\(n\\) qubits. In this phenomenon lies the basic motivation for quantum computation. After all, if Nature is so extravagant at the quantum level, why should we base our computers on classical physics? Why not tap into this massive amount of effort being expended at the quantum level? But there is a fundamental problem: this exponentially large linear superposition is the private world of the electrons. Measuring the system only reveals \\(n\\) bits of information. As before, the probability that the outcome is a particular 500-bit string \\(x\\) is \\(|\\alpha_x|&#94;2\\) . And the new state after measurement is just \\(|x>\\) . The plan The input to a quantum algorithm consists of \\(n\\) classical bits, and the output also consists of \\(n\\) classical bits. It is while the quantum system is not being watched that the quantum effects take over and we have the benefit of Nature working exponentially hard on our behalf. If the input is an \\(n\\) -bit string \\(x\\) , then the quantum computer takes as input \\(n\\) qubits in state \\(|x>\\) . Then a series of quantum operations are performed, by the end of which the state of the \\(n\\) qubits has been transformed to some superposition \\(\\su_y\\alpha_y|y>\\) . Finally, a measurement is made, and the output is the n-bit string y with probability \\(|\\alpha_y|&#94;2\\) . Observe that this output is random . But this is not a problem, as we have seen before with randomized algorithms such as the one for primality testing. As long as \\(y\\) corresponds to the right answer with high enough probability, we can repeat the whole process a few times to make the chance of failure miniscule. Noe let us look more closely at the quantum part of the algorithm. Some of the key quantum operations(which we will soon discuss) can be thought os as looking for certain kinds of patterns in a superposition of states. Because of this, it is helpful to think of the algorithm as having two stages. In the first stage, the \\(n\\) classical bits of the input are \"unpacked\" into an exponentially large superposition, which is expressly set up as to have an underlying pattern or regularity that, if detected, would solve the task at hand. The second stage then consists of a suitable set of quantum operations, followed by a measurement, which reveals the hidden pattern. The algorithm to factor a large integer \\(N\\) can be viewed as a sequence of reductions: FACTORING is reduced to finding a nontrivial square root of 1 modulo \\(N\\) . Finding such a root is reduced to computing the order of a random integer modulo \\(N\\) . The order of an integer is precisely the period of a particular periodic superposition . Finally, periods of superposition can be found by the quantum FFT . The Quantum Fourier Transform The FFT, where \\(\\omega\\) is a complex \\(M\\) th root of unity(the extra factor of \\(\\sqrt{M}\\) has the effect of ensuring that is the \\(|\\alpha_i|&#94;2\\) add up to 1, then so do the \\(|\\beta_i|&#94;2\\) ). Although the proceeding equation suggests an \\(O(M&#94;2)\\) algorithm, the classical FFT is able to perform this calculation in just \\(O(M\\log{M})\\) steps, and it is this speedup that has the profound effect of making digital signal processing practically feasible. We will now see that quantum computers can implement the FFT exponentially faster, in \\(O(\\log&#94;2M)\\) time! But waut, how can any algorithm take time less than \\(M\\) , the length of the input? The point is that we can encode the input in a superposition of just \\(m = \\log{M}\\) qubits; after all, this superposition of \\(2m\\) amplitude values. Starting from this input superposition \\(\\alpha\\) , the quantum Fourier transform(QFT) manipulates it appropriately in \\(m = \\log M\\) stages. At each stage the superposition evolves so that it encodes the intermediate results at the same stage of the classical FFT (whose circuit, with \\(m = \\log M\\) stages, is reproduced from Chapter 2). This can be achieved with m quantum operations per stage. Ultimately, after m such stages and \\(m&#94;2 = log&#94;2 M\\) elementary operations, we obtain the superposition \\(\\beta\\) that corresponds to the desired output of the QFT. So far we have only considered the good news about the QFT: its amazing speed. Now it is time to read the fine print. The classical FFT algorithm actually outputs the M complex numbers \\(\\beta_0,... , \\beta_{M-1}\\) . In contrast, the QFT only prepares a superposition \\(\\beta = P_{M_{j=0 −1} \\beta_j}\\) . And, as we saw earlier, these amplitudes are part of the \"private world\" of this quantum system. Thus the only way to get our hands on this result is by measuring it! And measuring the state of the system only yields \\(m = \\log M\\) classical bits: specifically, the output is index \\(j\\) with probability \\(|\\beta_j|&#94;2\\) . So, instead of QFT, it would be more accurate to call this algorithm quantum Fourier sampling . Moreover, even though we have confined our attention to the case \\(M = 2m\\) in this section, the algorithm can be implemented for arbitrary values of M, and can be summarized as follows: Quantum Fourier sampling is basically a quick way of getting a very rough idea about the output of the classical FFT, just detecting one of the larger components of the answer vector. In fact, we don't even see the value of that component—we only see its index. How can we use such meager information? In which applications of the FFT is just the index of the large components enough? This is what we explore next. Periodicity Suppose that the input to the QFT, \\(\\alpha = (\\alpha_0, \\alpha_1,... , \\alpha_{M−1})\\) , is such that \\(\\alpha_i = \\alpha_j\\) whenever \\(i \\equiv j \\pmod k\\) , where \\(k\\) is a particular integer that divides \\(M\\) . That is, the array \\(\\alpha\\) consists of \\(M/k\\) repetitions of some sequence \\((\\alpha_0, \\alpha_1,..., \\alpha_{k−1})\\) of length k. Moreover, suppose that exactly one of the \\(k\\) numbers \\(\\alpha_0,... , \\alpha_{k−1}\\) is nonzero, say \\(\\alpha_j\\) . Then we say that \\(\\alpha\\) is periodic with period \\(k\\) and offset \\(j\\) . It turns out that if the input vector is periodic, we can use quantum Fourier sampling to compute its period! This is based on the following fact, proved in the next lines: Suppose the input to quantum Fourier sampling is periodic with period \\(k\\) , for some \\(k\\) that divides \\(M\\) . Then the output will be a multiple of \\(M/k\\) , and it is equally likely to be any of the \\(k\\) multiples of \\(M/k\\) . Now a little thought tells us that by repeating the sampling a few times (repeatedly preparing the periodic superposition and doing Fourier sampling), and then taking the greatest common divisor of all the indices returned, we will with very high probability get the number \\(M/k\\) — and from it the period \\(k\\) of the input! Quantum Circuits So quantum computers can carry out a Fourier transform exponentially faster than classical computers. But what do these computers actually look like? What is a quantum circuit made up of, and exactly how does it compute Fourier transforms so quickly? Elementary quantum gates An elementary quantum operation is analogous to an elementary gate like the AND or NOT gate in a classical circuit. It operates upon either a single qubit or two qubits. One of the most important examples is the Hadamard gate , denoted by \\(H\\) , which operates on a single qubit. Notice that in either case, measuring the resulting qubit yields \\(0\\) with probability \\(1/2\\) and \\(1\\) with probability \\(1/2\\) . But what happens if the input to the Hadamard gate is an arbitrary superposition \\(\\alpha_0 |0> + \\alpha_1 |1>\\) ? The answer, dictated by the linearity of quantum physics, is the superposition \\(\\alpha_0H( 0 ) + \\alpha_1H( 1 ) = \\alpha_0\\sqrt2 \\alpha_1 |0> + \\alpha_0\\sqrt{−2} \\alpha_1 |1>\\) . And so, if we apply the Hadamard gate to the output of a Hadamard gate, it restores the qubit to its original state! Another basic gate is the controlled-NOT , or CNOT . It operates upon two qubits, with the first acting as a control qubit and the second as the target qubit. The CNOT gate flips the second bit if and only if the first qubit is a 1. Thus CNOT( 00 ) = 00 and CNOT( 10 ) = 11 : Yet another basic gate, the controlled phase gate, is described below in the subsection describing the quantum circuit for the QFT. Now let us consider the following question: Suppose we have a quantum state on n qubits, \\(\\alpha = P_x\\in\\{0,1\\}_n \\alpha_x x\\) . How many of these \\(2n\\) amplitudes change if we apply the Hadamard gate to only the first qubit? The surprising answer is—all of them! The new superposition becomes \\(\\beta = P_x\\in\\{0,1\\}_n \\beta_x x\\) , where \\(\\beta_0y = \\alpha_0y\\sqrt{2} + \\alpha_1y and \\beta_1y = \\alpha_0y\\sqrt{−2}\\alpha_1y\\) . Looking at the results more closely, the quantum operation on the first qubit deals with each \\(n − 1\\) bit suffix \\(y\\) separately. Thus the pair of amplitudes \\(\\alpha_0y\\) and \\(\\alpha_1y\\) are transformed into \\((\\alpha_0y + \\alpha_1y)/\\sqrt2\\) and \\((\\alpha_0y −\\alpha_1y)/\\sqrt2\\) . This is exactly the feature that will give us an exponential speedup in the quantum Fourier transform. Two basic types of quantum circuits A quantum circuit takes some number n of qubits as input, and outputs the same number of qubits. In the diagram these n qubits are carried by the n wires going from left to right. The quantum circuit consists of the application of a sequence of elementary quantum gates (of the kind described above) to single qubits and pairs of qubits. At a high level, there are two basic functionalities of quantum circuits that we use in the design of quantum algorithms: Quantum Fourier Transform These quantum circuits take as input n qubits in some state \\(\\alpha\\) and output the state \\(\\alpha\\) resulting from applying the QFT to \\(\\alpha\\) . Classical Functions Consider a function f with n input bits and m output bits, and suppose we have a classical circuit that outputs f(x). Then there is a quantum circuit that, on input consisting of an n-bit string x padded with m 0's, outputs x and f(x): Understanding quantum circuits at this high level is sufficient to follow the rest of this chapter. The next subsection on quantum circuits for the QFT can therefore be safely skipped by anyone not wanting to delve into these details. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 7"},{"url":"posts/books/algorithms-part-6/","text":"Chapter 8: NP-Complete problems Search problems A set of problems that can not be solved in time better than an exhaustive search. Satisfiability SAT , is a problem of great practical importance, applications ranging from chip testing to computer design to image analysis and software engineering. It is also a canonical hard problem. Consider this Boolean formula in conjugative normal form , $$(x \\lor y \\lor z)(x \\lor \\bar y)(y \\lor \\bar z)(z \\lor \\bar x)(\\bar x \\lor \\bar y \\lor \\bar z)$$ It is a collection of clauses , each consisting of several literals , A satisfying truth assignment is an assignment of false or true to each variable, so that every clause is true . SAT : Given a Boolean formula in CNF, either find a satisfying truth value, or report that none exist. In the above example, no solution exists.But how we decide this in general. The number of possibilities is exponential. A search problem is specified by an algorithm \\(\\mathcal C\\) that takes two inputs, \\(I\\) and a proposed solution \\(S\\) , and runs in time polynomial in \\(|I|\\) . We say \\(S\\) is a solution to \\(I\\) if and only if \\(\\mathcal C(I,S) = true\\) . Horn formula . If all clauses contain at most one positive literal, then the Boolean formula is called a Horn formula, and a satisfying truth assignment can be found by the greedy algorithm in Section 5.3. Alternatively, if all clauses have only two literals, then graph theory comes into play, and SAT can be solved in linear time by finding the strongly connected components of a particular graph constructed from the instance. The traveling salesman problem In TSP we are given \\(n\\) vertices \\(1,...n\\) and all \\(n(n-1)/2\\) distance between them, as well as budget \\(b\\) . We are asked to find a tour , a cycle that passes through every vertex exactly once, of total cost b or less, or to report that no such tour exists. That is we seek a permutation of the vertices such that when they are toured in this order, the total distance covered is at most b: $$d_{\\tau(1),\\tau(2)} + d_{\\tau(2),\\tau(3)} ... d_{\\tau(n),\\tau(1)} \\leq b$$ We have defined TSP as a search problem , when in reality it is an optimization problem , in which the shortest path is sought. The reason is, the framework for search problems encompasses optimization problems like TSP in addition to true search problems like SAT. This does not change its difficulty at all, because the two versions reduce to one another. Euler and Rudrata When can a graph be drawn without lifting the pencil from the paper? If and only if the graph is connected and every vertex, with the possible exception of two vertices(the start and final vertices of the walk), has even degree. EULER PATH : Given a graph, find a path that contains each edge exactly once, It follows from Euler's observation, and a little more thinking, that this search problem can be solved in polynomial time. RUDRATA CYCLE : Given a graph, find a cycle that visits each vertex exactly once - or report that no such cycle exists. Euler's problem can be solved in polynomial time, however for Rudrata's problem no polynomial solution is known. Cuts and bisections A cut is a set of edges whose removal leaves a graph disconnected. MINIMUM CUT : Given a graph and a budget \\(b\\) , find a cut with at most \\(b\\) edges. This generally leaves just a singleton vertex on one side. BALANCED CUT : Given a graph with \\(n\\) vertices and a budget \\(b\\) , partition the vertices into two sets \\(S\\) and \\(T\\) such that \\(|S|, |T|>n/3\\) and such that there are at most b edges between \\(S\\) and \\(T\\) . Another hard problem. Very important application: clustering . Integer Linear Programming ILP : Given \\(A\\) and \\(b\\) , find a nonnegative integer vector \\(\\mathbf x\\) satisfying the inequalities \\(Ax <= b\\) , or report that none exists. Special case, ZERO-ONE EQUATIONS Find a vector \\(\\mathbb x\\) of \\(0\\) 's and \\(1\\) 's satisfying \\(\\mathbb{Ax = 1}\\) , where \\(\\mathbb A\\) is an \\(m \\times n\\) matrix with 0-1 entries and \\(\\mathbb 1\\) is the m-vector of all 1's. Three-dimensional matching BIPARTITE MATCHING : Given a bipartite graph with \\(n\\) nodes on each side, find a set of \\(n\\) disjoint edges, or decide that no such exists. 3D MATCHING : In this new setting there are 3 different sets and the compatibilities among them are specified by a triplet. We want to find n disjoint triplets. Independent set, vertex cover and clique INDEPENDENT SET : Given a graph and an integer \\(g\\) , aim is to find \\(g\\) vertices that are independent, that is no two of which have an edge between them. VERTEX COVER , Given a graph and a budget \\(b\\) , the idea is to find \\(b\\) vertices that cover(touch) every edge. CLIQUE , given a graph and a goal \\(g\\) , find a set of \\(g\\) vertices such that all possible edges between them are present. Longest Path LONGEST PATH(TAXICAB RIP-OFF) : Given a graph \\(G\\) with non-negative edge weights and two distinguished vertexes \\(s\\) and \\(t\\) , along with a goal \\(g\\) . We are asked to find a path from \\(s\\) to \\(t\\) with total weight at least \\(g\\) . To avoid trivial solutions we require that the path be simple, i.e. containing no repeated vertices. Knapsack and subset sum KNAPSACK : we are given integer weights \\(w_1,.... w_n\\) and integer values \\(v_1,... v_n\\) for \\(n\\) items. We are also given a capacity \\(W\\) and a goal \\(g\\) . We seek a set of items whose total weight is at most \\(W\\) and whose total value is at least \\(g\\) . If no such set exists, we should say no. SUBSET SUM , Find a subset of a given set of integers that add up yo exactly \\(W\\) . NP-complete problems Hard problems, easy problems The various problems on the right can be solved by different types of algorithms, these problems are easy for a variety of reasons. In contrast, the problems on the left are all difficult for the same reasons! They are all the same problem, just in different disguises! They are all equivalent . P and NP We have already defined the search problem formally. We denote the class of all search problems by NP . The class of all search problems that can be solved in polynomial time is denoted by P . P = polynomial NP = nondeterministic polynomial time Reductions, again A reduction from search problem A to search problem B is a polynomial time algorithm f that transforms any instance I of A into an instance f(I) of B ., together with another polynomial time algorithm h that maps any solution S of f(I) back into a solution h(S) of I . A search problem is NP-complete if all other search problems reduce to it. Factoring The task of finding all prime factors of a given integer. The difficulty in factoring is of a different nature than that of the other hard search problems. Nobody believes that factoring is NP-complete . One difference, the definition does not contain the clause, \"or report that none exist\". A number can always be factored into primes. Another difference, factoring succumbs to the power of quantum computation . while other NP-complete problems do not seem to. The Reductions $$\\underline{\\mathrm{RUDRATA}(s,t)\\mathrm{-PATH} \\to \\mathrm{RUDRATA\\,CYCLE}}$$ $$\\underline{\\mathrm{3SAT} \\to \\mathrm{INDEPENDENT\\,SET}}$$ 3SAT , example $$(\\bar x \\lor y \\lor \\bar z)(x \\lor \\bar y \\lor z)(x \\lor y \\lor z)(z \\lor \\bar x)(\\bar x \\lor \\bar y)$$ INDEPENDENT SET , a graph and a number g. The above graph has been constructed as follows Graph \\(G\\) has a triangle for each clause(or just an edge, if the clause has two literals), with vertices labeled by the clause's literals, and has additional edges between any two vertices that represent opposite literals. The goal \\(g\\) is set to the number of clauses. $$\\underline{\\mathrm{SAT} \\to \\mathrm{3SAT}}$$ Replace, $$(a_1 \\lor a_2 \\lor ... \\lor a_k)$$ with, $$(a_1 \\lor a_2 \\lor y_1)(\\bar y_1 \\lor a_3 \\lor y_3)(\\bar y_2 \\lor a_4 \\lor y_3)...(\\bar y_{k-3} \\lor a_{k-1} \\lor a_k ),$$ $$\\underline{\\mathrm{INDEPENDENT\\,SET} \\to \\mathrm{VERTEX\\,COVER}}$$ Some reductions rely on ingenuity to relate two very different problems. Others simply record the fact that one problem is a thin disguise of another. To reduce \\(\\mathrm{INDEPENDENT\\,SET}\\) to \\(\\mathrm{VERTEX\\,COVER}\\) we just need to notice that a set of nodes \\(S\\) is a vertex cover of graph \\(G = (V,E)\\) (that is \\(S\\) touches every edge in \\(E\\) ) if and only if the remaining nodes, \\(V-S\\) , are an independent set of \\(G\\) . Therefore, to solve an instance \\((G,g)\\) of \\(\\mathrm{INDEPENDENT\\,SET}\\) , simple look for a vertex cover of \\(G\\) with \\(|V|-g\\) nodes. If such a vertex cover exists, then take all nodes not in it. If no such vertex cover exists, then \\(G\\) cannot possibly have an independent set of size \\(g\\) . $$\\underline{\\mathrm{INDEPENDENT\\,SET} \\to \\mathrm{CLIQUE}}$$ Define the complement of a graph \\(G\\) to contain precisely those edges that are not in \\(G\\) . Then, a set of nodes is an Independent set in \\(G\\) , if and only if it is a clique in complement of \\(G\\) . Therefore, the solution to both is identical. $$\\underline{\\mathrm{3SAT} \\to \\mathrm{3D\\,MATCHING}}$$ = a boolean variable. $$\\underline{\\mathrm{3D\\,MATCHING} \\to \\mathrm{ZOE}}$$ $$\\underline{\\mathrm{ZOE} \\to \\mathrm{SUBSET\\,SUM}}$$ When we look at a \\(\\mathrm{ZOE}\\) (like the one shown above), we are looking for a set of columns of \\(A\\) that, added together, make up the all-1'a vector. But if we think of the columns as binary integers(read from top to bottom), we are looking for a subset of the integers that add up to the binary integers with all 1's , i.e. 511. And this is an instance of \\(\\mathrm{SUBSET\\,SUM}\\) . The reduction is complete! Except for one detail, carry. Because of carry, n-bit binary integers can add up to \\(2&#94;n -1\\) ,even when the sum of the corresponding vectors is not all 1's. But this is easy to fix! Think of the column vectors not as integers in base 2, but as integers in base \\(n+1\\) , one more than the number of columns. This way, since at most n integers are added, and all their digits are 0 and 1, there can be no carry, and our reduction works. $$\\underline{\\mathrm{ZOE} \\to \\mathrm{ILP}}$$ $$\\underline{\\mathrm{ZOE} \\to \\mathrm{RUDRATA\\,CYCLE}}$$ $$\\underline{\\mathrm{ZOE} \\to \\mathrm{ILP}}$$ $$\\underline{\\mathrm{RUDRATA\\,CYCLE} \\to \\mathrm{TSP}}$$ $$\\underline{\\mathrm{ANY\\,PROBLEM\\,IN\\,NP} \\to \\mathrm{SAT}}$$ Chapter 9: Coping with NP completeness Intelligent Exhaustive Search Backtracking Based on the observation that it is often possible to reject a solution by looking at just a small part of it. An example SAT problem. The associated algorithm, $$ Start\\,with\\,some\\,problem\\,P_0\\\\ Let\\, \\mathcal{S} = \\{P_0\\},\\,the\\,set\\,of\\,active\\,subproblems.\\\\ Repeat\\,while\\,\\mathcal{S}\\,is\\,nonempty:\\\\ \\quad \\underline{choose}\\,a\\,subproblem\\,P \\in\\,\\mathcal{S}\\,and\\,remove\\,it\\,from\\,\\mathcal{S}\\\\ \\quad \\underline{expand}\\,it\\,into\\,smaller\\,subproblems\\,P_1,P_2...P_k\\\\ \\quad For\\,each\\,P_i:\\\\ \\quad \\quad If\\,\\underline{test}(P_i)\\,succeeds:\\quad halt\\,and\\,announce\\,this\\,solution\\\\ \\quad \\quad If\\,\\underline{test}(P_i)\\,fails:\\quad discard\\, P_i\\\\ \\,\\\\ \\quad \\quad Otherwise:\\,add\\,P_i\\,to\\,\\mathcal{S}\\\\ Announce\\,that\\,there\\,is\\,no\\,solution. $$ Branch and Bound The same principle from search problems to optimization. $$ Start\\,with\\,some\\,problem\\,P_0\\\\ Let\\, \\mathcal{S} = \\{P_0\\},\\,the\\,set\\,of\\,active\\,subproblems.\\\\ bestSoFar = \\infty\\\\ Repeat\\,while\\,\\mathcal{S}\\,is\\,nonempty:\\\\ \\quad \\underline{choose}\\,a\\,subproblem\\,(partial\\,solution)\\,P \\in\\,\\mathcal{S}\\,and\\,remove\\,it\\,from\\,\\mathcal{S}\\\\ \\quad \\underline{expand}\\,it\\,into\\,smaller\\,subproblems\\,P_1,P_2...P_k\\\\ \\quad For\\,each\\,P_i:\\\\ \\quad \\quad If\\,P_i\\,is\\,a\\,complete\\,solution:\\quad update\\,bestSoFar\\\\ \\quad \\quad else\\,if\\,\\underline{lowerbound}(P_i)\\le bestSoFar:\\quad add\\,P_i\\,to\\,\\mathcal{S}\\\\ return \\quad bestSoFar $$ Let's see how this works for the travelling salesman problem in a graph \\(G = (V,E)\\) with edge lengths \\(d_e > 0\\) . A partial solution is a simple path \\(a \\to b\\) passing through some vertices \\(S \\subseteq V\\) , where \\(S\\) includes the endpoints \\(s\\) and \\(b\\) . We can denote such a partial solution by the tuple \\([a,S,b]\\) , infact, \\(a\\) will be fixed throughout the algorithm. The corresponding subproblem is to find the best completion of the tour, that is the cheapest complementary path \\(b \\to a\\) with intermediate nodes \\(V - S\\) . Notice that the initial problem is of the form \\([a, \\{a\\}, a]\\) for any \\(a \\in V\\) of our choosing. At each step of the branch-and-bound algorithm, we extend a particular partial solution \\([a,S,b]\\) by a single edge \\((b,x)\\) , where \\(x \\in V-S\\) . There can be up to \\(|V-S|\\) ways to do this, and each of these branches leads to a subproblem of the form \\([a,S\\cup\\{x\\}, x]\\) . How can we lower-bound the cost of completing a partial tour \\([a,S,b]\\) ? Many sophisticated methods have been developed for this, but let's look at a rather simple one. The remainder of the tour consists of a path through \\(V-S\\) , plus edges from \\(a\\) and \\(b\\) to \\(V-S\\) . therefore, its cost is at least the sum of the following: The lightest edge from \\(a\\) to \\(V-S\\) . The lightest edge from \\(b\\) to \\(V-S\\) . The minimum spanning tree of \\(V-S\\) . (Do you see why?) And this lower bound can be computed quickly by a minimum spanning tree algorithm. Approximation algorithms Approximation factor, $$\\alpha_{\\mathcal{A}} = max_I\\frac{\\mathcal{A}(I)}{OPT(O)}$$ Vertex Cover $$\\mathrm{VERTEX\\,COVER}\\\\ Input: \\text{ An undirected graph } G = (V,E)\\\\ Output: \\text{ A subset of the vertices } S \\subseteq V \\text{ that touches every edge.}\\\\ Goal: \\text{ Minimize } |S|$$ $$Find\\,a\\,maximal\\,matching\\, M \\subseteq E\\\\ Return\\; S = \\{all\\,endpoints\\,of\\,edges\\,in\\,M\\}$$ Clustering We have some data that we want to divide into groups. We need to define distances between these data points. These distances can be euclidean distances, or even distances as a result of similarity tests. Assume that we have such distances and they satisfy these metric properties. \\(d(x,y) \\geq 0\\) for all \\(x, y\\) . \\(d(x, y) = 0\\) , if and only if \\(x=y\\) . \\(d(x,y) = d(y,x)\\) . ( Trianfle inequality ) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) \\(\\underline(k-\\mathrm{CLUSTER})\\) Input: Points \\(X = \\{x_1...x_n\\}\\) with underlying distance metric \\(d(\\cdot,\\cdot)\\) ; integer \\(k\\) . Output: A partition of the points into \\(k\\) clusters \\(C_1,...C_k\\) . Goal: Minimize the diameter of the clusters, $$max_j max_{x_a,x_b \\in C_j} d(x_a, x_b)$$ . Pick any point \\(\\mu_1 \\in X\\) as the first cluster center. for \\(i = 2\\) to \\(k\\) : \\(\\quad\\) Let \\(\\mu_i\\) be the point in \\(X\\) \\(that\\) \\(is\\) farthest from \\(\\mu_1...\\mu_{i-1}\\) \\(\\quad\\) (i.e., that maximizes \\(min_{j<i}d(\\cdot,\\mu_j)\\) Create \\(k\\) clusters: \\(C_i = {\\) all \\(x\\inX\\) whose closest center is \\(\\mu_i}\\) . TSP If the dustances in a TSP satisfy the triangle inequality metric, we can approximate the solution with a factor of 2 by solving the minimum spanning tree problem instead. Knapsack Discard any item with weight \\( > W\\) Let \\(v_{max} = max_iv_i\\) Rescale values \\(\\hat{v_i} = \\lfloor v_i \\cdot \\frac{n}{cv_max}\\rfloor\\) Run the dynamic programming algorithm with values \\({\\hat{v_i}}\\) Output the resulting choice of items. The approximability hierarchy Those for which, like the TSP, no finite approximation ratio is possible. Those for which an approximation ratio is possible, but there are limits to how small this can be. \\(\\mathrm{VERTEX\\,COVER},k-\\mathrm{CLUSTER}\\) , and the TSP with triangle inequality belong here. (For these problems we have not established limits to their approximability, but these limits do exist, and their proofs constitute some of the most sophisticated results in this field.) Down below we have a more fortunate class of NP -complete problems for which approximability has no limits, and polynomial approximation algorithms with error ratios arbitarily close to zero exist. \\(\\mathrm{KNAPSACK}\\) resides here. Finally, there is another class of problems, between the first two given here, for which the approximation ratio is about \\(\\log{n}\\) . \\(\\mathrm{SET\\,COVER}\\) is an example. Local Search Heuristics Let \\(s\\) be any initial solution while there is some solution \\(s'\\) in the neighbourhood of \\(s\\) \\(\\quad\\) for which \\(cost(s')<cost(s)\\) : replace \\(s\\) by \\(s'\\) return \\(s\\) Travelling Salesman, once more Notion of neighborhood of solutions in the search space of \\((n-1)!\\) different tours ? 2-change neighborhood of tour \\(s\\) : set of tours that can be obtained by removing two edges of \\(s\\) and then putting in two edges. \\(O(n&#94;2)\\) neighbors. In general, the search space might be riddled with local optima, and some of them may be of very poor quality. The hope is that with a judicious choice of neighborhood structures, most local optima will be reasonable. Whether this is the reality or merely misplaced faith, it is an empirical fact that local searcg algorithms are the tp performers on a broad range of optimization problems. Let's look at another such example. Graph partitioning Input: An undirected graph \\(G = (V,E)\\) with non-negative edge weights; a real number \\(\\alpha \\in (0,1/2)\\) . Output : A partition of the vertices into two groups \\(A\\) and \\(B\\) , each of size at least \\(\\alpha|V|\\) . Goal : Minimize the capacity of the cut \\((A,B)\\) . We need to decide upon a neighborhood structure for our problem, and there is one obvious way to do this. Let \\((A,B)\\) , with \\(|A|=|B|\\) , be a candidate solution, we will define its neighbors to be all solutions obtainable by swapping on ee pair of vertices across the cut, that is, all solutions of the form \\((A-\\{a\\}+\\{b\\}, B-\\{b\\}+\\{a\\})\\) where \\(a\\in A\\) and \\(b \\in B\\) . Here's an example of a local move. We now have a reasonable local search procedures, and we could just stop here. But there is still a lot of room for improvement in terms of the quality of the solutions produced. The search space includes some local optima that are quite far from the global solution. Here's one which has cost 2. What can be done about such suboptimal solutions? We could expand the neighborhood size to allow two swaps at a time, but this particular bad instance would still stubbornly resist. Instead, let's look at some other generic schemes for improving local search procedures. Dealing with local optima Randomization and restarts Simulated annealing , let \\(s\\) be any starting solution repeat \\(\\quad\\) randomly choose a solution \\(s'\\) in the neighborhood of \\(s\\) \\(\\quad\\) if \\(\\Delta=cost(s')-cost(s)\\) is negative: \\(\\quad\\quad\\) replace \\(s\\) by \\(s'\\) \\(\\quad\\) else: \\(\\quad\\) replace \\(s\\) by \\(s'\\) with probability \\(e&#94;{-\\Delta/T}\\) . If \\(T\\) is zero, this is identical to our previous local search. But if \\(T\\) is large, then moves that increase the cost are occasionally accepted. What value of \\(T\\) should be used? The trick is to start \\(T\\) large and then gradually reduce it to zero. Thus initially, the local search can wander around quite freely, with only a mild preference for low-cost solutions. As time foes on, this preference becomes stronger, and the system mostly sticks to the lower-cost region of the search space, with occasional excursions out of it to escape local optima. Eventually, when the temperature drops further, the system converges on a solution. Simulated annealing is inspired by the physics of crystallization. When a substance is to be crystallized, it starts in liquid state, with its particles in relatively unconstrained motion. Then it is slowly cooled, and as this happens, the particles gradually move into more regular configurations. This regularity becomes more and more pronounced until finally a crystal lattice is formed. The benefits of simulated annealing comes at a significant cost: because of the changing temperature and the initial freedom of movement, many more local moves are needed until convergence. Moreover, it is quite an art to choose a good timetable by which to decrease the temperature, called annealing schedule . But in many cases where the quality of solutions improves significantly. the tradeoff is worthwhile. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 6"},{"url":"posts/books/algorithms-part-5/","text":"Chapter 7: Linear Programming and reductions Linear programming describes a broad class of optimization tasks in which both the constraints and the optimization criterion are linear functions . It turns out an enormous number of problems can be expressed in this way. An introduction to linear programming Eample : Profit maximization We represent the situation be a linear program as follows, Objective function : $$max\\; x_1 + 6x_2$$ Constraints : $$x_1 \\leq 200 \\\\ x_2 \\leq 300 \\\\ x_1 + x_2 \\leq 400 \\\\ x_1, x_2 \\geq 0$$ Solving linear problems, Simplex Method : Move from vertex to vertex(generally starting at origin), optimizing the objective function. Stop when no neighbor gives better results. Here is the updated linear program, $$max\\; x_1 + 6x_2+13x_3 \\\\ x_1 \\leq 200 \\\\ x_2 \\leq 300 \\\\ x_1 + x_2 + x_3 \\leq 400 \\\\ x_2 + 3x_3 \\leq 600 \\\\ x_1, x_2, x_3 \\geq 0$$ Example : Production planning An example with large number of variables and constraints. Integer Linear Programming is hard Example : Optimum bandwidth allocation Variants of Linear Programmin A general linear programming problem has many degrees of freedom, It can be either a maximization or a minimization problem. Its constraints can be equations and/or inequalities. The variables are often restricted to be non-negative, but the can also be unrestricted in sign. All these variants can easily be reduced to one another vio simple transformations. 1. To turn a maximization problem into a minimization(or vice-versa), just multiply the coefficients of the objective function by -1. 2. To turn an inequality constraint like \\(\\sum_{i=1}&#94;na_ix_i \\leq b\\) into an equation, introduce a new variable \\(s\\) and use $$\\sum_{i=1}&#94;na_ix_i+s=b,\\quad\\quad s \\geq 0$$ This is called a slack variable for the inequality. As justification, observe that a vector \\((x_1...x_n)\\) satisfies the original inequality constraint if and only if there is some \\(s \\geq 0\\) for which it satisfies the new equality constraint. 3. To change an equality constraint into inequalities is easy : rewrite \\(ax=b\\) as the equivalent pair of constraints \\(ax \\leq b\\) and \\(ax \\geq b\\) . 4. Finally, to deal with a variable \\(x\\) that is unrestricted in sign, do the following, * Introduce two non-negative variables, \\(x&#94;+, x&#94;- \\geq 0\\) . * Replace \\(x\\) , wherever it occurs in the constraints or the objective function, by \\(x&#94;+-x&#94;-\\) . This way \\(x\\) can take on any real value by appropriately adjusting the new variables. More precisely, any feasible solution to the original LP involving \\(x\\) can be mapped to a feasible solution to the new LP involving \\(x&#94;+, x&#94;-\\) , and vice-versa. Flows in Networks Shipping Oil Maximizing flow 1. It doesn't violate edge capacities, \\(0 < f_e < c_e\\) for all \\(e \\in E\\) . 2. For all nodes \\(u\\) except \\(s\\) and \\(t\\) , the amount of flow entering \\(u\\) equals the amount leaving \\(u\\) : $$\\sum_{(w,u)\\in E}f_{wu} = \\sum_{(u,z)\\in E}f_{uz}$$ In other words, flow is conserved . A closer look at the algorithm, in each iteration, simplex looks for an \\(s-t\\) path whose edges \\((u,v)\\) can be of two types, 1. \\((u,v)\\) is in the original network, and is not yet at full capacity. 2. The reverse edge \\((u,v)\\) is in the original network, and there is some flow along it. Bipartite Matching Duality Turns out, every linear maximization problem has a dual minimization problem. Duality theorem : If a linear program has a bounded optimum, then so does its dual, and the two optimum values coincide. Zero Sum Games Various conflict situations in life can be represented by matrix games. For ex. rock-paper-scissors can be specified by the payoff matrix . Now, if they play repeatedly, they have to employ a mixed strategy , which can be specified by the vector \\(\\mathbf x = (x_1, x_2, x_3)\\) for first player and \\(\\mathbf y = (y_1, y_2, y_3)\\) for the two players. Therefore, for any given round, the expected payoff is $$\\sum_{i,j}G_{ij}\\cdot Prob[\\text{Row plays } i, \\text{Column plays } j] = \\sum_{i,j}G_{ij}x_i, y_j$$ Row wants to maximize this, while Column wants to minimize it. If both Row and Column force a \"completely random strategy\" , both of them will get an expected payoff of zero. This is in fact a consequence of linear programming duality. The simplex algorithm Let v be any vertex of the feasible region. while there is a neighbor v' of v with better objective value: set v = v' Any setting of the \\(x_i\\) 's can be represented by an \\(n\\) -tuple of real numbers and plotted in \\(n\\) -dimensional space. A linear equation involving the \\(x_i\\) 's defines a hyperplane in this same space \\(\\mathbb R&#94;n\\) and the corresponding linear equality defines a half-space , all points that are either precisely on the hyperplane or lie on one particular side of it. Finally, the feasible region of the linear program is specified by a set of inequalities and is therefore the intersection of the corresponding half-spaces, a convex polyhedron. Verices and neighbors in n-dimensional space Each vertex is the unique point at which some subset of hyperplanes meet. Alternatively, Pick a subset of the inequalities If there is a unique point that satisfies them with equality, and this point happens to be feasible, then it is a vertex . Two vertices are neighbors if they have \\(n-1\\) defining inequalities in common. The algorithm On each iteration, simplex has two tasks: 1. Check whether the current vertex is optimal(and is so, halt). 2. Determine where to move next. Loose ends The starting vertex , turns out finding a starting vertex can be reduced to an LP and solved by simplex . Degeneracy , geometrically, this means that the vertex is at the intersection of more than \\(n\\) faces of polyhedron(say \\(n+1\\) ). Algebraically, it means that if we choose any one of the \\(n+1\\) sets of \\(n\\) inequalities and solve the corresponding system of \\(n\\) linear equations in \\(n\\) unknowns, we'll get the same solution in all \\(n+1\\) cases. This is a serious problem: simplex may return a suboptimal degenerate vertex simply because all its neighbors are identical to it and thus offer no better objective. And if we modify simplex to detect degeneracy and continue to hop from vertex to vertex, despite the lack of any improvement in the cost, it may end up looping forever. This can be solved by perturbation , jolt one of the planes a little so that the vertex splits up in two. Unboundedness , in some cases the objective function can be made arbitrarily large. If this is the case, simple will discover it, in exploring the neighbor of a vertex, it will notice that taking out an inequality and adding another leads to an undetermined system of equations that has infinite number of solutions. And in fact the space of solutions contains a whole line along which the objective can become larger and larger, all the way to infinity . In this case the simplex halts and complains. The running time of simplex Consider a generic LP, max \\(c&#94;Tx\\) such that \\(Ax \\leq 0\\) and \\(x \\geq 0\\) , where there are \\(n\\) variables and \\(A\\) contains \\(m\\) inequality constraints. A naive implementation can give an unappetizing time of \\(O(mn&#94;4)\\) . How? Find out...!!! Fortunately, there is a much better way, where this can be reduced to \\(O(mn)\\) . By employing the strategy of transforming to local view of a vertex. Linear programming in polynomial time Simplex is exponential,but performs well in practice.It is considered a paradox, can be solved in practice, but not in theory. Ellipsoid Algorithm , Confine the solution into smaller and smaller ellipsoids. however, this could not compete well with simplex in practice. The paradox deepened: A problem with two algorithms, one that is efficient in theory, and one that is efficient in practice. Interior point method , dashes to the optimum corner, not be hopping from corner to corner, but by cutting a clever path in the interior of the polyhedron. And it does perform well in practice. The fierce competition between the two approaches resulted in the development of very fast code for linear programming. Postscript : circuit evaluation We are given a Boolean circuit , that is , a dag of gates of the following types, Input gates have indegree zero, with value true or false . AND gates and OR gates have indegree 2. NOT gates have indegree 1. For example, This an be reduced to an LP by the following substitutions, And, \\(0 \\geq x_g \\geq 1\\) , for all the gates. We don,t need to maximize anything, we just need to find out \\(x_g\\) corresponding to the output gate. This is the most general problem that can be solved in polynomial time. Hence, the fact that CIRCUIT VALUE reduces to LP means that all problems that can be solved in polynomial time! if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 5"},{"url":"posts/robotics/biologically-inspired-robots/","text":"Bio Robots OpenRatSLAM : an open source brain-based SLAM system Feb 2013 Source RatSLAM, OpenRatSLAM, SLAM, Navigation, Mapping, Brain-based, Appearance-based, ROS, Open-source, Hippocampus RatSLAM is a navigation system based on the neural processes underlying navigation in the rodent brain, capable of operating with low resolution monocular image data. This paper describes OpenRatSLAM, an open source version of RatSLAM with bindings to ROS SLAM(Simultaneous Localization and Mapping) , at the core based on SIFT or SURF features. This implementation is based on RatSLAM, leveraging tools like OpenCV and ROS. Modular, detailed, integrated with ROS and rviz , works online and offline. RatSLAM Pose Cells, Local View Cells and Experience Map OpenRatSLAM, code Pose Cell Network : represents pose in response to odometric and local view connections. This also makes decisions about the experience map node and link creation. Local View Cells : determines whether a scene is novel or familiar by image comparison techniques. Mostly based on template matching. Experience map : manages graph building, graph relaxation and path planning. Visual Odometry : For image only datasets, provides an odometric estimate based on changes in the visual scene. OpenRatSLAM parameters and tuning Iterative tuning by minimizing loss. Using OpenRatSLAM Examples of datasets this is used with, and some results. Future work Watch In Action Biologically Inspired App roaches to Robotics March 1997 Source Big gap between fantasy and reality in terms of Autonomous Robots. Inspirations from insects : agility, adaptability, simplicity Focuses on walking like an insect. From Biology to Robotics Studies done at various levels of integration and inspiration. Distributed Gait Control A Distributed Neural Network Controller A Stick Insect Controller Evolved Locomotion Controllers Use genetic algorithms to evolve the neural networks for controlling the locomotion. Rough Terrain Locomotion The First Takeoff of a Biologically Inspired At-Scale Robotic Insect April 2008 Source Actuators, aerial robotics, biologically inspired robotics, microrobotics Goal is to create an insect-sized, truly micro air vehicle. Harvard Microrobotic Fly Fig. (a) Conceptual drawing highlighting the four primary mechanical and aero-mechanical components. Fig. (b) First insect-scale flying robot able to takeoff. INSECT-FLIGHT Dipteran thoracic mechanics is discussed. Creation of a Robotic Insect Actuation Using peizoceramic materials. Transmission Airfoils Watch In Action Towards Dynamic Trot Gait Locomotion—Design, Control, and Experiments with Cheetah-cub, a Compliant Quadruped Robot Alexander Spröwitz , Alexandre Tuleu, Massimo Vespignani, Mostafa Ajallooeian, Emilie Badri, Auke Jan Ijspeert :July 2013 Source Cheetah Cub : novel compliant quadruped robot. Watch In Action Fastest of its kind with speeds upto \\(1.42ms&#94;{-1}\\) . The implementation of multi-segment , compliant legs presents a major biological solution. Webots model description Control Uses Central pattern generators(CPG) Results Gait Pattern Generation and Stabilization for Humanoid Robot Based on Coupled Oscillators Inyong Ha, Yusuke Tamura, and Hajime Asama : Sep 2011 Source Achieve balanced walking for a DarwIn-OP by gait pattern generation and stabilization using coupled oscillators. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"robotics","title":"Biologically Inspired Robots"},{"url":"posts/machine-intelligence/neural-networks-for-computer-vision/","text":"Very minimal notes on some papers or articles that I recently read. Mainly for logging purposes. Image Recognition Very Deep Convolutional Networks For Large-Scale Image Recognition Karen Simonyan, Andrew Zisserman : Apr 2015 Source Implementation Introduces the VGG network that won ImageNet in 2014 . Deeper ConvNets. Takes input as (224 X 224) RGB and mean image subtracted as preprocessing. Two final FC hidden layers, followed by one FC layer with 1000 outputs. Number of total trainable parameters turn out to be 144 million for VGG-19. All the hidden layers use ReLU activations. Deeper networks with small filters result in more regularization and less parameters. Optimise multinomial logistic regression objective using mini-batch gradient descent with momentum. At the end introduces ensemble models by averaging softmax predictions from multiple models. Going Deeper with Convolutions Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich : Sep 2014 Google DeepMind Source Introduces \"Inception\" with improved utilization of computing resources. \"We need to go deeper\" : But deeper networks come with a cost of large number of parameters, which makes the model prone to overfitting, and dramatically increased use of computational resources. Fundamental idea : sparsely connected architectures, even inside the convolutions. However, the computing infrastructure is very inefficient when it comes to numerical calculations on sparse data structures. And non-uniform sparse structures require careful engineering! Architecture GoogLeNet 22 trainable Layers(100 total layers), low memory footprint. Auxillary classifiers are used to allow for efficient gradient propagation. These are used only at training time. Deep Residual Learning for Image Recognition Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun : Dec 2015 Microsoft Research Source Presents residual learning framework( ResNet ) to ease the training of networks that are substantially deeper(152 layers!) than those used previously. How to win ImageNet in 2015. Problem with deeper networks : Vanishing Gradients : Addressed by intermediate normalization. Problem with deeper networks : Degradation , not caused by overfitting.. Introduces residual learning framework by using shortcut connections that can perform identity mapping. Using Identity mapping as precondition allows the network to easily learn the identity, if it is a desired mapping. This helps in simplifying networks. Plain Network architecture, mainly based on VGG nets. Residual Network architecture, insert shortcuts to the plain network. The model shows no optimization difficulty even with > 1000 layers..!! Finally discusses improvements for detection and localization tasks. Rethinking the Inception Architecture for Computer Vision Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna : Dec 2015 Google DeepMind Source Improving upon Inception module and GoogLeNet. General guiding principles Avoid representational bottlenecks, especially early in the network. Higher dimensional representations are easier to process locally within a network. Spatial aggregation can be done over lower dimensional embeddings without much or any loss in representational power. Balance the width and depth of the network. Factorizing Convolutions with Large Filter Size Factorize into smaller convolutions. This results in reduced parameter count. Does this replacement result in any loss of expressiveness? Spatial Factorization into Asymmetric Convolutions Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi : Aug 2016 Google DeepMind Source Combining Residual networks with Inception architecture . Uniform Inception-v4 blocks are introduced for cleaner architecture. Xception: Deep Learning with Depthwise Separable Convolutions François Chollet : Apr 2017 Source Google Inc. Building on top of the inception modules. An attempt to make things efficient by decoupling operations for cross-channel correlations and spatial correlations. This introduces the Depthwise separable convolutions . The Xception architecture then takes these layers and builds a complete network for ImageNet task, with better reported performane than Inception v3 . Deep Visualization Visualizing and Understanding Convolutional Networks Matthew D Zeiler, Rob Fergus L : Nov 2013 Source Understanding why CNNs perform well on Image Classification tasks. Visualizing with a Deconvnet Feature Visualization Feature Evolution during training Feature Invariance Occlusion Sensitivity Correspondence Analysis Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks Anh Nguyen, Jason Yosinski, Jeff Clune : May 2016 Source Researchers have been using activation maximization techniques until now. This assumes that each neuron detects only one type of feature. But, we know neurons can be multifaceted . Here multifaceted feature visualization (MFV) is introduced. Systematically visualize all facets of a neuron. Improve image quality of synthesized images with natural and globally consistent colors. Center biased regularization is used so that the synthesized images dont have many repeated object fragments. This is done by first producing a blurry image, then updating the center pixels more than the edge ones, producing a final image that is sharp and has a centrally-located object. This image would have far fewer duplicated fragments. Visualizing the multifaceted nature of hidden neurons Discusses various optimization techniques to produce better images in detail : center biased regularization, mean image initialization. How transferable are features in deep neural networks? Jason Yosinski, Jeff Clune, Yoshua Bengio, Hod Lipson : Nov 2014 Source First-layer features always resembles either Gabor filters or color blobs. We also often use the initial layers of a network to initialize other networks(for a different task) in transfer learning . This raises a few questions, *Can we quantify the degree to which a particular layer is general or specific? Does the transition occur suddenly at a single layer, or is it spread out over several layers? Where does this transition take place: near the first, middle, or last layer of the network? Figure 1: Overview of the experimental treatments and controls. Top two rows : The base networks are trained using standard supervised backprop on only half of the ImageNet dataset (first row: A half, second row: B half). The labeled rectangles (e.g. \\(W_{A1}\\) ) represent the weight vector learned for that layer, with the color indicating which dataset the layer was originally trained on. The vertical, ellipsoidal bars between weight vectors represent the activations of the network at each layer. Third row : In the selffer network control, the first \\(n\\) weight layers of the network (in this example, \\(n = 3\\) ) are copied from a base network (e.g. one trained on dataset B), the upper \\(8 − n\\) layers are randomly initialized, and then the entire network is trained on that same dataset (in this example, dataset B). The first n layers are either locked during training (\"frozen\" selffer treatment \\(B3B\\) ) or allowed to learn (\"fine-tuned\" selffer treatment \\(B3B&#94;+\\) ). This treatment reveals the occurrence of fragile coadaptation , when neurons on neighboring layers co-adapt during training in such a way that cannot be rediscovered when one layer is frozen. Fourth row : The transfer network experimental treatment is the same as the selffer treatment, except that the first n layers are copied from a network trained on one dataset (e.g. A) and then the entire network is trained on the other dataset (e.g. B). This treatment tests the extent to which the features on layer n are general or specific. Figure 2: The results from this paper's main experiment. Top : Each marker in the figure represents the average accuracy over the validation set for a trained network. The white circles above \\(n = 0\\) represent the accuracy of baseB. There are eight points, because we tested on four separate random A/B splits. Each dark blue dot represents a BnB network. Light blue points represent BnB+ networks, or fine-tuned versions of BnB. Dark red diamonds are AnB networks, and light red diamonds are the fine-tuned AnB+ versions. Points are shifted slightly left or right for visual clarity. Bottom : Lines connecting the means of each treatment. Conclusively, transfer learning can be very effective for lower layers for general dissimilar objectives, and for higher layers as well in case of similar objectives. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Neural Networks for Computer Vision"},{"url":"posts/machine-intelligence/research-notes-deep-learning/","text":"Very minimal notes on some papers or articles that I recently read. Mainly for logging purposes. Image Recognition and Convnet Architectures Style Transfer, Part 1 Style Transfer, Part 2 Neural Network Architectures Object Detection and Image Segmentation, Part 1 Object Detection and Image Segmentation, Part 2","tags":"machine-intelligence","title":"Research Notes:: Deep Learning"},{"url":"posts/robotics/robotics-research/","text":"Biologically Inspired Robots Mobile Robots Soft Robotics","tags":"robotics","title":"Robotics Research"},{"url":"posts/books/algorithms-part-3/","text":"Chapter 3: Decomposition of Graphs Why Graphs The range of problems that can be solved by representing your problem in Graphs. Graph representations, Adjacency Matrix $$ a_{ij} = \\begin{cases} 1 \\text{ if there is an edge from } v_i \\text{ to } v_j \\\\ 0 \\text{ otherwise} \\end{cases}$$ Or, Adjacency List , \\(|V|\\) linked lists, one per vertex. The list for u holds the names of vertices to which u , has an outgoing edge. Depth first search in undirected Graphs Exploring mazes So, we need to simulate a piece of chalk(to check whether the node has been visited), and a string(to retrace our steps back home). The analogs that we have are, a boolean flag as a chalk, and a stack as a string(in this case its the recursive system stack). Running time, \\(O(|V| + |E|)\\) Connectivity in undirected graphs Identify and assign different integers to the different connected components in a undirected Graph. Previsit and Postvisit orderings Property : For any node \\(u\\) and \\(v\\) , the two intervals \\([pre(u), post(u)]\\) and \\([pre(v), post(v)]\\) are either disjoint or one is contained within the other. Depth-First search in Directed Graphs Types of edges Directed Acyclic Graphs Property : A directed graph has a cycle if and only if its depth-first search reveals a back edge. Property : In a dag, every edge leads to a vertex with a lower \\(post\\) number. Property : Every dag has at least one source and at least one sink. Strongly Connected Components Defining connectivity for directed graphs Two nodes u and v of a directed graph are connected if there is ap path from u to v and a path from v to u . This relation partitions V into disjoint sets that we call strongly connected components .The graph above has five of them. Property : Every directed graph is a dag of its strongly connected components. An efficient algorithm Property 1 : If the \\(explore\\) subroutine is started in a node \\(u\\) , then it will terminate precisely when all nodes reachable from \\(u\\) have been visited. Therefore, if we call explore on a node that lies somewhere in a sink strongly connected component(a strongly connected component that is a sink in the meta-graph), then we will retrieve exactly that component. But, how to find a node that we know for sure lies in a sink strongly connected component. How do we continue once the first component has been discovered. Property 2: The node that receives the highest \\(post\\) number in a depth-first search must lie in a source strongly connected component. which directly follows from, Property 3: If \\(C\\) and \\(C'\\) are strongly connected components, and there is an edge from a node in \\(C\\) to a node in \\(C'\\) , then the highest \\(post\\) number in \\(C\\) is bigger than the highest \\(post\\) number in \\(C'\\) . So, now we can determine whether a particular node lies in a source component of the meta graph. The opposite of what we need. Now, consider the reverse graph. It will have exactly the same strongly connected components as G. So if we find a part of source in the reverse graph, this node will be a part of a sink component in the original graph. Once we find the first strongly connected component a d deleted it from the graph, the next node with the highest post number will be a part of another sink component in G. The resulting algorithm, 1. Run depth-first search on \\(G&#94;R\\) . 2. Run the undirected connected components algorithm on \\(G\\) and during the depth-first search, process the vertices in decreasing order of their post numbers from step 1. Chapter 4: Paths in Graphs Distances The distance between two nodes is the length of the shortest path between them. Breadth first search Dijkstra's algorithm An adaptation of breadth-first search For any edge \\(e = (u,v) \\text{ of } E\\) , replace it by \\(l_e\\) edges of length 1, by adding \\(l_e - 1\\) dummy nodes between \\(u\\) and \\(v\\) . Therefore, we can compute distances in graph by running BFS on the new graph. We can do this by setting an estimated time of arrival for each new node in the frontier. The nodes are then being processed on the basis of earliest time. The right data structure to do this is a priority queue (usually implemented by a heap ). Running time \\(O(|V| + |E|)\\log|V|\\) Which heap is best ? Priority Queue Implementations Array Simplest implementation of a priority queue is as an unordered array of key values for all potential elements. Binary Heap Here elements are stored in a complete binary tree. In addition, a special ordering constraint is enforced: the key of any node of the tree is less than or equal to that of its children , i.e. the root always contains the smallest element. d-ary heap Identical to a binary heap, except that the nodes have d children instead of just two. Shortest paths in the presence of negative edges Note : The presence of a negative cycle means we cannot answer the question of shortest paths in the given graph. Shortest paths in dags if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 3"},{"url":"posts/books/algorithms-part-4/","text":"Chapter 5: Greedy Algorithms !Thinking Ahead. Minimum spanning trees Property 1 Removing a cycle edge cannot disconnect a graph. The tree with minimum total weight is then known as minimum spanning tree . Formally, Input : An undirected graph \\(G = (V, E)\\) ; edge weights \\(w_e\\) . Output : A tree \\(T = (V, E')\\) , with \\(E' \\subseteq E\\) , that minimizes \\(weight(T) = \\sum_{e \\in E'}w_e\\) . A greedy approach Kruskal's algorithm Repeatedly add the next lightest edge that doesn't produce a cycle. The cut property Cut Property Suppose edges \\(X\\) are part of a minimum spanning tree of \\(G = (V, E)\\) . Pick any subset of nodes S for which \\(X\\) does not cross between \\(S\\) and \\(V-S\\) , and let \\(e\\) be the lightest edge across this partition. Then \\(X \\cup \\{e\\}\\) is part of some \\(MST\\) . Kruskal's algorithm We need to use a data structure for representing disjoint sets, supporting the following operations, makeset(x) : create a singelton set containing just x . find(x) : to which set does x belong. union(x,y) : merge the sets containing x and y . A data structure for disjoint sets Union by rank $$\\underline{procedure\\, makeset(x)}\\\\ \\pi(x) = x \\\\ rank(x) = 0 \\\\ \\, \\\\ \\underline{function\\, find(x)} \\\\ while\\quad x \\neq \\pi(x): x = \\pi(x) \\\\ return\\; x \\\\ \\, \\\\ \\underline{procedure\\, union(x,y)} \\\\ r_x = find(x) \\\\ r_y = find(y) \\\\ if\\quad r_x = r_y:\\, return \\\\ if\\quad rank(r_x) > rank(r_y) : \\\\ \\quad \\pi(r_y) = r_x \\\\ else: \\\\ \\quad \\pi(r_x) = r_y \\\\ \\quad if\\quad rank(r_x) = rank(r_y): rank(r_y) = rank(r_y) + 1 $$ The given structure has the following properties. Property 1 For any \\(x, rank(x) < rank(\\pi(x))\\) . Property 2 Any root node of rank \\(k\\) has at least \\(2&#94;k\\) nodes in its tree. Property 3 If there are \\(n\\) elements overall, there can be at most \\(n/2&#94;k\\) nodes of rank \\(k\\) . Path compression $$ \\\\ \\underline{function\\, find(x)} \\\\ if\\quad x \\neq \\pi(x): \\pi(x) = find(\\pi(x)) \\\\ return\\; \\pi(x) \\\\ $$ During each find , when a series of parent pointers are followed up to the root, we will change all these pointers so that they point directly to the root. This simple alteration results in doing slightly more work per find operation. However, the amortized cost of each operation turns out to be just barely more than \\(O(1)\\) . Prim's algorithm In most general terms, any algorithm working on the following general schema is guaranteed to work. $$X = \\{\\,\\}\\text{ edges picked so far} \\\\ repeat\\; until\\quad |X| = |V|-1 :\\\\ \\quad \\text{pick a set} S \\subset V \\text{ for which X has no edges between S and V - S} \\\\ \\quad let\\; e \\in E \\text{ be the minimum-weight edge between S and V - S} \\\\ X = X \\cup \\{e\\} $$ Alternative to Kruskal's algorithmfor finding Minimum Spanning Trees. This is very similar to Dijkstra, only that the priorities are decided differently. Huffman coding Variable length encoding of symbols, depending on frequency of the particular symbol. Should be prefix-free , i.e. no codeword can be a prefix of another codeword. Any prefix-free encoding can be represented by a full binary tree. The two symbols with the smallest frequencies must be the bottom of the optimal tree. $$\\underline{procedure\\; \\text{Huffman}(f)} \\\\ Input:\\quad \\text{An array $f[1...n]$ of frequencies} \\\\ Output:\\quad \\text{An encoding tree with n leaves} \\\\ \\, \\\\ \\text{let H be a priority queue of integers, ordered by } f \\\\ for\\; i = 1\\, to\\, n:\\; insert(H, i) \\\\ for\\; k=n+1\\, to\\, 2n-1: \\\\ \\quad i = deletemin(H), j = deletemin(H) \\\\ \\quad \\text{create a node numbered k with children i,j} \\\\ \\quad f[k] = f[i] + f[j] \\\\ \\quad insert(H,k) \\\\ $$ Horn formulas Horn formulas are a framework for performing logical reasoning, expressing logical facts and deriving conclusions. Knowledge about variables is represented by two kinds of clauses: 1. Implications, whose left-hand side is an AND of any number of positive literals and whose right-hand side is a single positive literal. These express statements of the form \"if the conditions on the left hold, then the one on the right must also be true.\". For instance, \\((z\\land w)\\implies u\\) might mean \"if the colonel was asleep at 8 pm and the murder took place at 8 pm then the colonel is innocent.\" A degenerate type of implication is the singleton \" \\(\\implies x\\) ,\" meaning simply that x is true : \"the murder definitely occurred in the kitchen\". 2. Pure negative clauses , consisting of an OR of any number of negative literals, as in \\((\\bar u\\lor \\bar v \\lor \\bar y)\\) Given a set of clauses, we need to assign true/false values to the variables that satisfies all the clauses. The is called a satisfying assignment . So we have this given formula for finding a satisfying assignment. $$ \\\\ Input:\\quad \\text{a Horn formula} \\\\ Output:\\quad \\text{a satisfying assignment, if one exists} \\\\ \\, \\\\ \\text{set all variables to false} \\\\ \\, \\\\ \\text{while there is an implication that is not satisfied:} \\\\ \\quad \\text{set the right-hand variable of the implication to true} \\\\ \\, \\\\ \\text{if all pure negative clauses are satisfied: return the assignment} \\\\ \\text{else: return \"formula is not satisfiable\"} \\\\ $$ Set Cover $$ \\text{SET COVER} \\\\ Input: \\text{A set of elements $B$; sets } S_1,...S_m \\subseteq B. \\\\ Output: \\text{A selection of the $S_i$ whose union is $B$} \\\\ Cost: \\text{Number of sets picked.} \\\\ $$ The greedy algorithm will not be optimal, but it will be pretty close to it. Claim , Supppose \\(B\\) contains \\(n\\) elements and that the optimal cover consists of \\(k\\) sets. Then the greedy algorithm will use at most \\(k\\ln n\\) sets. The ratio between the greedy algorithm's solution and the optimal solution varies from input to input but is always less than \\(\\ln n\\) . There are certain inputs for which the ratio is very close to \\(\\ln n\\) . We call this maximum ratio the approximation factor of the greedy algorithm. Chapter 6: Dynamic Programming The sledgehammers of the algorithms class: Dynamic Programming and Linear Programming Shortest paths in dags, revisited The following routine can be used to calculate the shortest path in DAG. $$ \\\\ \\text{initialize all $dist(.)$ values to $\\inf$} \\\\ dist(s) = 0 \\\\ \\text{for each}\\quad v \\in V\\setminus\\{s\\}, \\text{in linearized order}: \\\\ \\quad dist(v) = min{(u,v)\\in E}\\{dist(u) + l(u,v)\\} $$ Dynamic programming is a very powerful algorithmic paradigm in which a problem is solved by identifying a collection of subproblems and tackling them one by one, smallest first, using the answers to subproblems to figure out larger ones, until the whole lot of them is solved. In dynamic programming we are not given a dag, it is implicit . Its nodes are the subproblems we define, and its edges are the dependencies between the subproblems. Longest increasing subsequence The problem can be represented as a DAG, containing all possible transitions; establish a node \\(i\\) for each element \\(a_i\\) , and add directed edges \\((i,j)\\) whenever it is possible for \\(a_i\\) and \\(a_j\\) to be consecutive elements in an increasing subsequence, that is, whenever \\(i < j\\) and \\(a_i < a_j\\) . So, for finding the longest subsequence, our goal is simply to find the longest path in the dag. $$\\\\ for\\quad j = 1, 2,... n: \\\\ \\quad L(j) = 1 + max\\{L(i): (i, j) \\in E\\} \\\\ return\\; max_jL(j) \\\\ $$ , where \\(L(j)\\) is the length of the longest path(the longest increasing subsequence) ending in \\(j\\) . The actual subsequence of nodes can also be determined by some bookkeeping(ex. note down \\(prev(j)\\) ), the next-to-last node on the longest path to j.) Edit distance The minimum number of edits required to convert a string to another string. A dynamic programming solution \\(E(i,j)\\) represents the subproblems of finding match between string \\(x[1...i]\\) and \\(y[1...j]\\) . Our final objective is to compute \\(E(m,n)\\) . For that we need to express \\(E(i,j)\\) in terms of smaller subproblems. Now, \\(E(i,j) = min\\{1 + E(i-1, j), 1 + E(i, j-1), diff(i,j) + E(i-1, j-1)\\}\\) where, \\(diff(i,j)\\) is 0 if \\(x[i] = y[i]\\) , and \\(1\\) otherwise. The above relation forms a table, which can easily be computed in time \\(O(mn)\\) . Knapsack A burglar wants to find out which items to carry, considering the weight and cost where he can carry up to a fixed amount of weight, maximizing the cost of items. Knapsack with repetition \\(K(w) =\\) maximum value achievable with a knapsack of capacity \\(w\\) . \\(K(w) = max_{i:w_i \\leq w}\\{K(w - w_i)+v_i\\}\\) , Algorithm: $$\\\\ K(0) = 0 \\\\ for\\quad w = 1 to\\; W : \\\\ \\quad K(w) = max\\{K(w-w_i) + v_i : w_i < w\\} \\\\ return\\; K(W) \\\\ $$ Knapsack without repetition \\(K(w,j) =\\) maximum value achievable using knapsack of capacity \\(w\\) and items \\(1...j\\) . \\(K(w,j) = max\\{K(w-w_j,j-1) + v_j, K(w, j-1)\\}\\) $$\\\\ \\text{initialize all } K(0,j) = 0 \\text{ and all } K(w,0) = 0 \\\\ for\\quad j=1\\; to\\; n: \\\\ \\quad for\\quad w=1\\; to\\; W : \\\\ \\quad \\quad if\\; w_j > w: K(w,j) = K(w,j-1) \\\\ \\quad \\quad else: K(w,j) = max\\{K(w,j-1), K(w-w_j,j-1)+v_j\\} \\\\ return\\; K(W,n) \\\\ $$ Chain Matrix Multiplication Matrix multiplication is not commutative, but is associative. Which means, \\(A \\times (B \\times C) = (A \\times B) \\times C\\) . Thus, we can compute product of four different matrices in many different ways, Some of the ways are much better(computationally) than others. Shortest Paths Shortest reliable paths Suppose we want the shortest path from \\(s\\) to \\(t\\) that uses at most \\(k\\) edges. Is there a quick way to adapt Dijkstra's algorithm to this new task? Not quite; since the algorithm focuses on the length of each shortest path without remembering the number of hops in the path, which is now a crucial information. In dynamic programming, we can now define, for each vertex \\(v\\) and each integer \\(i < k, dist(v,i)\\) to be the length of the shortest path from \\(s\\) to \\(v\\) that uses \\(i\\) edges. \\(dist(v,i) = min_(u,v)\\in E{dist(u, i-1) + l(u,v)}\\) . All pairs shortest paths Floyd-Warshall algorithm : We want to find the shortest paths between all pairs of vertices. Is there a good subproblem for solving this problem. Yes. We can start with just two starting nodes, and gradually expand the set of possible intermediate nodes. More concretely, number the vertices in \\(V\\) as \\(\\{1...n\\}\\) and let, \\(dist(1,j,k)\\) denote the length of shortest path from \\(i\\) to \\(j\\) in which only nodes \\(\\{1,2...k\\}\\) can be used as intermediates. Initially, \\(dist(1,j,0)\\) is the length of the direct edges between \\(i\\) and \\(j\\) if one exists, and is \\(\\inf\\) otherwise. This, using \\(k\\) gives us a shorter path from \\(i\\) to \\(j\\) if and only if \\(dist(i,k,k-1) + dist(k,j,k-1) < dist(i,j,k-1)\\) , in which case \\(dist(i,j,k)\\) should be updated accordingly. Here is the Floyd-Warshall algorithm -- and it takes \\(O|V|&#94;3\\) time. $$\\\\ for \\quad i=1 to n:\\\\ \\quad for \\quad j=1 to n:\\\\ \\quad \\quad dist(i,j,0) = \\infty\\\\ for\\;all \\quad (i,j) \\in E:\\\\ \\quad dist(i,j,0) = l(i,j)\\\\ for\\quad k=1\\;to\\;n:\\\\ \\quad for\\quad i=1\\;to\\;n:\\\\ \\quad \\quad for\\quad j=1\\;to\\;n:\\\\ \\quad \\quad \\quad dist(i,j,k)=min\\{dist(i,k,k-1)+dist(k,j,k-1), dist(i,j,k-1)\\}\\;to\\;n:\\\\ $$ The travelling salesman problem What sgould be the appropriate subproblem? For a subset of cities \\(S \\subseteq {1,2,....n}\\) that includes \\(l\\) , and \\(j \\in S\\) , let \\(C(S,j)\\) be the length of the shortest path visiting each node in \\(S\\) exactly once, starting at \\(l\\) and ending at \\(j\\) . When \\(|S| > 1\\) , we define \\(C(S,1) = \\infty\\) since the path cannot both start and end at \\(1\\) . Now, let's express \\(C(S,j)\\) in terms of smaller subproblems. We need to start at \\(1\\) and end at \\(j\\) ; what should we pick as the second-to-last city? It has to be some \\(i \\in S\\) , so the overall path length is the distance from \\(1\\) to \\(i\\) , namely \\(C(S-\\{j\\}, i) + \\text{the length of the final edge,}d_{ij}\\) . We must pick the best such \\(i\\) : $$C(S,j) = min_{i\\in S:i\\neq j} C(S-\\{j\\}, i) + d_{ij}$$ The subproblems are ordered by \\(|S|\\) . here's the code. $$C(\\{1\\}, 1) = 0\\\\ for \\quad s=2\\; to \\; n: \\quad for\\; all\\; subsets\\; S \\subseteq {1,2,...n}\\text{ of size } s \\text{ and containing } 1:\\\\ \\quad \\quad C(s,j) = \\infty\\\\ \\quad \\quad for\\; all\\; j \\in S,\\; j \\neq 1:\\\\ \\quad \\quad \\quad C(S,j) = min\\{C(S-\\{j\\},i)+d_{ij}:i\\in S,\\, i \\neq j\\}\\\\ return \\quad min_jC(\\{1,...n\\},j)+d_{j1} $$ There are at most \\(2&#94;m.n\\) subproblems, and each one takes linear time to solve. The total running time is therefore $O(n&#94;22&#94;m). Independent Sets in trees We need to find the largest independent set from a tree. Here is our algorithm, Start by rooting the tree at any node \\(r\\) . Now, each node defines a subtree - the one hanging from it. This immediately suggests subproblems, \\( I(u) =\\) size of largest independent set of subtree hanging from \\(u\\) . Our final goal is \\(I(r)\\) . So, \\(I(u)\\) turns out to be, $$I(u) = max \\bigl\\{1 + \\sum_{\\text{grandchildren}\\,w\\,\\text{of}\\,u}I(w), \\sum_{\\text{children}\\,w\\,\\text{of}\\,u}I(w)\\bigr\\}$$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 4"},{"url":"posts/books/algorithms-by-dasgupta-part1/","text":"Chapter 0: Prologue Books and algorithms Ideas that changed the world. Widespread use of decimal system. Enter Fibonacci 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...., Also, \\(F_n = F_{n-1} + F_{n-2}\\) And, \\(F_n ≈ 2&#94;{0.694n}\\) A naive implementation , with no caching of values.., fib1 Runtime --> \\(T(n) >= F_n\\) , exponential in n Can We Do Better,....? A Polynomial algorithm..., fib2 A loop based algorithm that remembers previous values in an array. Polynomial running time. More Careful Analysis What about addition of numbers Fibonacci values for large n. Adding two n-bit integers take time ~ n. So, \\(fib1 ≈ n.Fn\\) And, \\(fib2 ≈ n&#94;2\\) Big-O notation Right simplification of the analysis. Leave behind the lower order terms. General rules : Multiplicative constants can be omitted. \\(n&#94;a\\) dominates \\(n&#94;b, if a > b\\) Any exponential dominates any polynomial. \\(a&#94;n\\) dominates \\(n&#94;b\\) Likewise, any polynomial dominates any logarithm. \\(n\\) dominates \\(log(n)\\) Exercise 0.4 So now \\(F_n\\) can be computed by calculating \\(X&#94;n\\) where \\(X\\) is the square matrix. So, \\(Fn = O(log n)\\) But then, with careful analysis, Multiplication of large n-bit numbers \\(≈ O(n&#94;2)\\) Chapter 1: Algorithms with Numbers Two ancient problems: Factoring : Given a number N, express it as a product of its prime factors. Hard Primality : Given a number N, determine whether it is a prime. Easy Basic Arithmetic Addition The sum of any three single-digit numbers is at most two digits long. Given two binary numbers x and y, how does our algorithm take to add them? Depends on size of input, number of bits in x and y. Running time \\(= O(n), n =\\) number of bits in the numbers. Is there anything faster? No.. About word length and large numbers Multiplication and Division To multiply x and y , create an array of intermediate sums, each representing the product of x by a single digit if y . These values are appropriately left shifted and added up. Running time = Addition of n numbers of n-bits length = \\((n-1).O(n)\\) = \\(O(n&#94;2)\\) Another fascinating algorithm for multiplication: However, running time = \\(O(n&#94;2)\\) , n = number of bits. Modular Arithmetic $$x \\equiv y \\pmod N \\Leftrightarrow N divides (x - y)$$ Modular arithmetic is a system for dealing with restricted ranges of integers. Another interpretation is that modular arithmetic deals with all the integers, but divides into N equivalence classes, each of the form \\(\\{i+kN:k\\in \\mathbb Z\\}, i \\in [0, N-1]\\) . Modular addition and multiplication To add two numbers x and y modulo N , we start with regular addition. Since x and y are both in the range 0 to N - 1 , their sum is in the range 0 to 2(N-1) . If the sum exceeds N-1 , we merely need to subtract off N to bring it back to required range. So, running time \\(= O(n), n = log N\\) . To multiply two mod N numbers x and y, do regular multiplication, reduce the answer to modulo N. The product can be as large as \\((N-1)&#94;2\\) , at most 2n bits large. Need to compute the remainder using quadratic time division algorithm. Multiplication thus remains quadratic. Division , however is tricky, whenever legal, it can be managed in quadratic time. Modular exponentiation We want to compute \\(x&#94;y \\pmod N\\) . Let n be the size(bits) of x, y and N . As with multiplication, the algorithm will halt after at most n recursive calls, and during each call it multiplies n-bit numbers, for a total running time of \\(O(n&#94;3)\\) . Euclid's algorithm for G.C.D Eculid's rule : If x and y are positive integers with \\(x >= y\\) , then \\(gcd(x, y) = gcd(x \\pmod y, y)\\) . Also, if \\(a > b\\) , then \\(a \\pmod b < a/2\\) . This means after any two consecutive iterations, both arguments are at the very least reduced to half.If they are initially n-bit, base case will be reached in at most 2n recursive calls. And each call involves a quadratic-time division. Running time \\(= O(n&#94;3)\\) . An extension to Euclid's algorithm A small extension to Euclid's algorithm is the key to dividing in the modular world. Modular division x is the multiplicative inverse of a modulo N , if \\(ax == 1 \\pmod N\\) If \\(gcd(a,N) > 1 , \\Rightarrow ax \\neq 1 \\pmod N \\forall x\\) , and therefor a cannot have a multiplicative inverse modulo N . When \\(gcd(a, N) = 1\\) , we say a and N are relatively prime . The extended Euclid's algorithm gives us integers x and y such that \\(ax + Ny = 1\\) , which means \\(ax \\equiv 1 (mod N)\\) . Thus x is a's sought inverse . Modular Division Theorem , a has multiplicative inverse modulo N , if and only if they are relatively prime, and it can be found by running extended Euclid theorem in time \\(O(n&#94;3)\\) . Primality Testing Here the theorem does not say anything about what happens if number is not prime. In fact, for some composite numbers, Pr(Algorithm returns yes when N is not prime) <= 1/2 We can thus choose k different random integers to test for primality testing, reducing Pr to \\(1/2&#94;k\\) . Generating random primes Due to such abundance of prime numbers, prime number generation is easy. Generate a random n-bit number. Check for primality. If not prime, repeat the process. Cryptography Rivest-Shamir-Adelman(RSA) : Blabber about private key and public key systems. Private-key schemes: one time pad and AES RSA Public key cryptography Based heavily upon number theory. Universal Hashing Hash Tables Give a key to any value . Hash function : How to define the mapping between key and value . Families of Hash Functions A family of hash functions with this property is called universal . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms by DasGupta, Part1"},{"url":"posts/books/algorithms-part-2/","text":"Chapter 2: Divide-and-Conquer Algorithms The divide and conquer strategy solves a problem by 1. Breaking it into sub-problems that are themselves smaller instances of the same type of problem. 2. Recursively solving these problems. 3. Appropriately combining their results. Multiplication For multiplying two n-bit integers x and y. \\(x = \\bbox[5px, border:2px solid black]{ x_L } \\quad \\bbox[5px, border:2px solid black]{ x_R } = 2&#94;{n/2}x_L + x_R\\) \\(y = \\bbox[5px, border:2px solid black]{ y_L } \\quad \\bbox[5px, border:2px solid black]{ y_R } = 2&#94;{n/2}y_L + y_R\\) then, \\(xy = (2&#94;{n/2}x_L + x_R)(2&#94;{n/2}y_L + y_R) = 2&#94;nx_Ly_L + 2&#94;{n/2}(x_Ly_R + x_Ry_L) + x_Ry_R\\) Now, we can compute xy by evaluating the RHS. Addition and multiplication by \\(2&#94;n\\) are linear time. Rest of the 4 multiplications can be done by recursively applying this algorithm. So, \\(T(n) = 4T(n/2) + O(n)\\) . Which results in \\(O(n&#94;2)\\) . By expanding the middle term, we can do with just three calculations, \\(x_Ly_L , x_Ry_R, (x_L+x_R)(y_L+y_R)\\) . since, \\(x_Ly_R + x_Ry_L = (x_L + x_R ) (y_L + y_R ) - x_Ly_L – x_Ry_R\\) . Resulting algorithm would then be \\(T(n) = 3T(n/2) + O(n)\\) , which is \\(O(n&#94;{1.59})\\) Height of the tree \\(= \\log_2 n\\) , since the length of the sub-problem gets halved at every level. Branching factor = 3. So, at any level k we will have \\(3&#94;k\\) to solve each of size \\(n/2&#94;k\\) . Therefore, time spent at level k is, \\(3&#94;k \\times O(\\frac n {2&#94;k}) = (\\frac 3 2)&#94;k \\times O(n)\\) Which is a geometric series. So, the sum then approximates to the last term of the series. That is \\(O(3&#94;{\\log_2 n})\\) , which can be written as \\(O(n&#94;{\\log_2 3})\\) , which is about \\(O(n&#94;{1.59})\\) . Can we do better ??? using Fast Fourier Transforms discussed later. Recurrence relations Consider this recurrence tree. Master's Theorem : If \\(T(n) = aT(\\lceil n/b \\rceil) + O(n&#94;d)\\) for some constants \\(a > 0, b > 1\\) , and \\(d \\ge 0\\) , then $$ T(n) = \\begin{cases} O(n&#94;d), \\text{ if } d > \\log_b a \\\\ O(n&#94;d\\log n), \\text{ if } d = \\log_b a \\\\ O(n&#94;{\\log_b a}), \\text{ if } d < \\log_b a \\end{cases}$$ Mergesort Sort an array by recursively sorting each half and merging the results. Since merge does constant amount of work per recursive call, overall time is $$ T(n) = 2T(n/2) + O(n), \\text{ or } O(n\\log n)$$ Here is an iterative version using a Queue. Medians Median = 50th percentile of a list of numbers. A randomized divide-and-conquer algorithm for selection For any number v , Split S into three categories: elements smaller than v \\((S_L)\\) , equal to v \\((S_v)\\) , greater than v \\((S_R)\\) , then $$ selection(S, k) = \\begin{cases} selection(S_L, k), \\quad\\quad\\quad\\quad\\quad\\quad \\text{if } k \\le |S_L| \\\\ v , \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad \\text{ if } |S_L| < k \\le |S_L| + |S_v| \\\\ selection(S_R, k - |S_L| - |S_v|), \\text{ if } k > |S_L| + |S_v| \\end{cases}$$ The three sub-lists can be computed in linear time, even in place. How to pick v ? Randomly from S . Matrix multiplication Symbolically, $$ Z_{ij} = \\sum_{k=1}&#94;n X_{ik}Y_{kj}$$ This implies the algorithm to be \\(O(n&#94;3)\\) Enter divide-and-conquer. Divide the matrices X and Y into 4 blocks. $$ X = \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix}, Y = \\begin{bmatrix}E & F \\\\ G & H\\end{bmatrix} $$ , Then, their product can be expressed as, $$ XY = \\begin{bmatrix}A & B \\\\ C & D\\end{bmatrix} = \\begin{bmatrix}AE+BG & AF+BH \\\\ CE+DG & CF+DH \\end{bmatrix} $$ Total running time can be described as, \\(T(n) = 8T(n/2) + O(n&#94;2), \\text{ which is again } O(n&#94;3)\\) . Turns out you can do this, $$ XY = \\begin{bmatrix}P_5+P_4-P_2+P_6 & P_1+P_2 \\\\ P_3+P_4 & P_1+P_5-P_3-P_7\\end{bmatrix} $$ where, \\(P_1 = A(F-H) \\quad\\quad P_5 = (A+D)(E+H)\\) \\(P_2 = (A+B)H \\quad\\quad P_6 = (B-D)(G+H)\\) \\(P_3 = (C+D)E \\quad\\quad P_7 = (A-C)(E+F)\\) \\(P_4 = D(G-E)\\) The new running time is, \\(T(n) = 7T(n/2) + O(n&#94;2), \\text{which is } O(n&#94;{\\log_2 7}) \\approx O(n&#94;{2.81})\\) Fast Fourier transform Next target, Polynomials . The general solution for polynomial multiplication works in \\(\\theta(d&#94;2)\\) time, where \\(d\\) is the degree of polynomials. An alternative representation of polynomials. Fact : A degree-d polynomial is uniquely characterized by its values at any \\(d+1\\) distinct points . So, we can specify a degree-d polynomial $$A(x) = a_0+a_1x+...+a_dx&#94;d$$ by any one of the following, 1. Its coefficients, \\(a_0, a_1,..., a_d\\) 2. The values \\(A(x_0), A(x_1), ..., A(x_d)\\) Now, taking in consideration the second form, the product has a degree \\(2d\\) , and is completely determined by its values at \\(2d+1\\) points. Since, those values are just products of the two polynomials at the given point. Thus, polynomial multiplication takes linear time in the value representation. Evaluation by divide-and-conquer The Trick : Choose the n points to be selected as positive-negative pairs, then the computations needed to be done overlap a lot. Specifically, if we could then recurse, we would have, $$T(n) = 2T(n/2) + O(n), \\text{which is } O(n\\log n)$$ But, recursing it at the second level and beyond seems impossible. Unless, of-course we use complex numbers. To get positive-negative pairs at subsequent levels, we can use the roots of \\(z&#94;n = 1\\) Which are, \\(1, \\omega, \\omega&#94;2, ... \\omega&#94;{n-1}, \\text{ where, } \\omega = e&#94;{2\\pi i/n}\\) So, if we choose these numbers, at every successive level of recursion we have pairs of positive-negative numbers Interpolation $$\\langle \\text{values} \\rangle = FFT(\\langle \\text{coefficients} \\rangle, \\omega)$$ , and $$\\langle \\text{coefficients} \\rangle = \\frac 1 n FFT(\\langle \\text{values} \\rangle, \\omega&#94;{-1}) $$ Details left,, See Fourier basis A closer look at the fast Fourier Transform The FFT takes as input a vector \\(a = (a_0, ... a_{n-1})\\) and a complex number \\(\\omega\\) whose powers are the complex root of unity. It multiplies this vector with the Matrix \\(M_n(\\omega)\\) , which has \\((j, k)_{th}\\) entry (starting row and column count at zero) \\(\\omega&#94;{jk}\\) . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 2"},{"url":"posts/books/fundamentals-of-computer-graphics-part-2/","text":"Chapter 5 : Linear Algebra Determinants Determinants as the area of a parallelogram and volume of a parallelepiped. We can see from Figure 5.6 that \\(|(b_c\\mathbf{b}\\mathbf{a})| = |c\\mathbf{a}|\\) , because these parallelograms are just sheared versions of each other. Solving for bc yields \\(b_c =|\\mathbf{ca}|/|\\mathbf{ba}|\\) . An analogous argument yields \\(a_c =|\\mathbf{bc}|/|\\mathbf{ba}|\\) . This is the two-dimensional version of Cramer's rule which we will revisit soon. Matrices A matrix is an array of numeric elements that follow certain arithmetic rules. Matrix Arithmetic Product with a scalar. Matrix addition. Matrix multiplication. Not commutative. Associative. Distributive. Operations on Matrices. Identity matrix. Inverse matrix. $$ (\\mathbf{AB})&#94;{-1} = \\mathbf{B}&#94;{-1}\\mathbf{A}&#94;{-1}$$ Transpose of matrix, $$ (\\mathbf{AB})&#94;{T} = \\mathbf{B}&#94;{T}\\mathbf{A}&#94;{T}$$ Also, $$ |{\\mathbf{AB}}| = |{\\mathbf{A}}|\\,|{\\mathbf{B}}| $$ $$ |{\\mathbf{A}&#94;{-1}}| = \\frac{1}{|{\\mathbf{A}}|} $$ $$ |{\\mathbf{A}&#94;T}| = |{\\mathbf{A}}| $$ Vector operations in Matrix form. Special types of Matrices Diagonal Matrix - All non-zero elements occur along the diagonal. Symmetrical Matrix - Same as its transpose. Orthogonal Matrix - All of its rows(and columns) are vectors of length 1 and are orthogonal to each other. Determinant os such a matrix is either +1 or -1. The idea of an orthogonal matrix corresponds to the idea of an orthonormal basis, not just a set of orthogonal vectors. Computing with Matrices and Determinants Determinants as areas. Laplace's Expansion. Computing determinants by calculating cofactors. Computing inverses $$\\begin{eqnarray} \\mathbf{A}&#94;{-1} = \\frac{1}{|{\\mathbf{A}}|}\\begin{bmatrix} a&#94;c_{11} & a&#94;c_{21} & a&#94;c_{31} & a&#94;c_{41} \\\\ a&#94;c_{12} & a&#94;c_{22} & a&#94;c_{32} & a&#94;c_{42} \\\\ a&#94;c_{13} & a&#94;c_{23} & a&#94;c_{33} & a&#94;c_{43} \\\\ a&#94;c_{14} & a&#94;c_{24} & a&#94;c_{34} & a&#94;c_{44} \\\\ \\end{bmatrix} \\end{eqnarray}$$ Linear Systems $$\\mathbf{Ax}=\\mathbf{b}$$ Cramer's rule, The rule here is to take a ratio of determinants, where the denominator is \\(|{\\mathbf{A}}|\\) and the numerator is the determinant of a matrix created by replacing a column of \\(\\mathbf{A}\\) with the column vector \\(\\mathbf{b}\\) . The column replaced corresponds to the position of the unknown in vector \\(\\mathbf{x}\\) . For example, \\(y\\) is the second unknown and the second column is replaced. Note that if \\(|{\\mathbf{A}}| = 0\\) , the division is undefined and there is no solution. This is just another version of the rule that if \\(\\mathbf{A}\\) is singular (zero determinant) then there is no unique solution to the equations. Eigenvalues and Matrix Diagonalization Square matrices have eigenvalues and eigenvectors associated with them. The eigenvectors are those non-zero vectors whose directions do not change when multiplied by the matrix. For example, suppose for a matrix \\(\\mathbf{A}\\) and vector \\(\\mathbf{a}\\) , we have $$ \\mathbf{Aa} = \\lambda\\mathbf{a} $$ This means we have stretched or compressed \\(\\mathbf{a}\\) , but its direction has not changed. The scale factor \\(\\lambda\\) is called the eigenvalue associated with eigenvector \\(\\mathbf{a}\\) . If we assume a matrix has at least one eigenvector, then we can do a standard manipulation to find it. First, we write both sides as the product of a square matrix with the vector \\(\\mathbf{a}\\) : $$ \\mathbf{Aa} = \\lambda\\mathbf{Ia} $$ where \\(\\mathbf{I}\\) is an identity matrix. This can be rewritten $$\\mathbf{Aa} − \\lambda\\mathbf{Ia} = 0$$ Because matrix multiplication is distributive, we can group the matrices: $$(\\mathbf{A} − \\lambda\\mathbf{I}) \\mathbf{a} = 0$$ This equation can only be true if the matrix \\((\\mathbf{A} − \\lambda\\mathbf{I})\\) is singular, and thus its determinant is zero. The elements in this matrix are the numbers in \\(\\mathbf{A}\\) except along the diagonal. Solving for \\(\\lambda\\) requires solving an n th degree polynomial in \\(\\lambda\\) . So we can only compute eigenvalues for matrices upto the order of 4 X 4 by analytical methods. For higher order matrices we need to use numerical solutions. An important special case where eigenvalues and eigenvectors are particularly simple is symmetric matrices (where \\(\\mathbf{A} = \\mathbf{A}_T\\) ). The eigenvalues of real symmetric matrices are always real numbers, and if they are also distinct, their eigenvectors are mutually orthogonal. Such matrices can be put into diagonal form : $$\\mathbf{A} = \\mathbf{QDQ}_T$$ where \\(\\mathbf{Q}\\) is an orthogonal matrix and \\(\\mathbf{D}\\) is a diagonal matrix. The columns of \\(\\mathbf{Q}\\) are the eigenvectors of \\(\\mathbf{A}\\) and the diagonal elements of \\(\\mathbf{D}\\) are the eigenvalues of \\(\\mathbf{A}\\) . Putting \\(\\mathbf{A}\\) in this form is also called the eigenvalue decomposition , because it decomposes \\(\\mathbf{A}\\) into a product of simpler matrices that reveal its eigenvectors and eigenvalues. Singular Value Decomposition $$\\mathbf{A} = \\mathbf{USV}_T$$ Here \\(\\mathbf{U}\\) and \\(\\mathbf{V}\\) are two, potentially different, orthogonal matrices, whose columns are known as the left and right singular vectors of \\(\\mathbf{A}\\) , and \\(\\mathbf{S}\\) is a diagonal matrix whose entries are known as the singular values of \\(\\mathbf{A}\\) . When \\(\\mathbf{A}\\) is symmetric and has all non-negative eigenvalues, the SVD and the eigenvalue decomposition are the same. Also, $$\\mathbf{M} = \\mathbf{AA}_T = (\\mathbf{USV}_T)(\\mathbf{USV}_T)_T = \\mathbf{US}(\\mathbf{V}_TV)\\mathbf{SU}_T = \\mathbf{US}&#94;2\\mathbf{U}_T$$ Chapter 6: Transformation Matrices 2D Linear Transformations $$\\begin{bmatrix}a_{11} & a_{12} \\\\ a_{21} & a_{22}\\end{bmatrix} \\begin{bmatrix}x \\\\ y\\end{bmatrix} \\begin{bmatrix}a_{11}x + a_{12}y \\\\ a_{21}x + a_{22}y\\end{bmatrix}$$ This kind of operation, which takes in a 2-vector and produces another 2-vector by a simple matrix multiplication, is a linear transformation . Scaling $$ \\mbox{scale}(s_x, s_y) = \\begin{bmatrix} s_x & 0 \\\\ 0 & s_y \\end{bmatrix}$$ Shearing $$ \\mbox{shear-x}(s) = \\begin{bmatrix} 1 & s \\\\ 0 & 1 \\end{bmatrix}$$ $$ \\mbox{shear-y}(s) = \\begin{bmatrix} 1 & 0 \\\\ s & 1 \\end{bmatrix}$$ Rotation $$ \\mbox{rotate}(\\phi) = \\begin{bmatrix} cos(\\phi) & -sin(\\phi) \\\\ sin(\\phi) & cos(\\phi) \\end{bmatrix}$$ Reflection $$ \\mbox{reflect-y} = \\begin{bmatrix} -1 & 0 \\\\ 0 & 1 \\end{bmatrix}$$ $$ \\mbox{reflect-x} = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}$$ Reflection is in fact just a rotation by \\(\\pi\\) radians. Composition and Decomposition of transforms Not commutative. Decomposition of transforms Symmetric Eigenvalue Decomposition $$\\mathbf{A} = \\mathbf{RSR}&#94;T$$ where \\(\\mathbf{R}\\) is an orthogonal matrix and \\(\\mathbf{S}\\) is a diagonal matrix; we will call the columns of \\(\\mathbf{R}\\) (the eigenvectors) by the names \\(\\mathbf{v}_1\\) and \\(\\mathbf{v}_2\\) , and we'll call the diagonal entries of \\(\\mathbf{S}\\) (the eigenvalues) by the names \\(\\lambda_1\\) and \\(\\lambda_2\\) . This symmetric 2 X 2 matrix has 3 degrees of freedom. One rotation angle and two scale values. Singular value Decomposition $$\\mathbf{A} = \\mathbf{USV}&#94;T$$ In summary, every matrix can be decomposed via SVD into a rotation times a scale times another rotation. Only symmetric matrices can be decomposed via eigenvalue diagonalization into a rotation times a scale times the inverse-rotation, and such matrices are a simple scale in an arbitrary direction. The SVD of a symmetric matrix will yield the same triple product as eigenvalue decomposition via a slightly more complex algebraic manipulation. Paeth Decomposition of Rotations $$\\begin{bmatrix} cos\\phi & -sin\\phi \\\\ sin\\phi & cos\\phi\\end{bmatrix} = \\begin{bmatrix}1 & \\frac{cos{\\phi}-1}{sin\\phi} \\\\ 0 & 1\\end{bmatrix} \\begin{bmatrix}1 & 0 \\\\ sin\\phi & 1\\end{bmatrix} \\begin{bmatrix}1 & \\frac{cos{\\phi}-1}{sin\\phi} \\\\ 0 & 1\\end{bmatrix}$$ 3D Linear Transformations Scaling $$ \\mbox{scale}(s_x, s_y, s_z) = \\begin{bmatrix} s_x & 0 & 0\\\\ 0 & s_y & 0\\\\ 0 & 0 & s_z\\end{bmatrix}$$ Rotation $$ \\begin{eqnarray} \\mbox{rotate-z}(\\phi) & = &\\begin{bmatrix} cos\\,\\phi & -sin\\,\\phi & 0\\\\ sin\\,\\phi & cos\\,\\phi & 0 \\\\ 0 & 0 & 1\\end{bmatrix} \\\\ \\mbox{rotate-x}(\\phi) & = & \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & cos\\,\\phi & -sin\\,\\phi \\\\ 0 & sin\\,\\phi & cos\\,\\phi\\end{bmatrix} \\\\ \\mbox{rotate-y}(\\phi) & = & \\begin{bmatrix} cos\\,\\phi & -sin\\,\\phi & 0\\\\ sin\\,\\phi & cos\\,\\phi & 0 \\\\ 0 & 0 & 1\\end{bmatrix}\\end{eqnarray}$$ Shear $$ \\begin{eqnarray} \\mbox{shear-z}(d_x, d_z) & = &\\begin{bmatrix} 1 & d_y & d_z\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix} \\end{eqnarray}$$ As with 2D transforms, any 3D transformation matrix can be decomposed using SVD into a rotation, scale, and another rotation. Any symmetric 3D matrix has an eigenvalue decomposition into rotation, scale, and inverse-rotation. Finally, a 3D rotation can be decomposed into a product of 3D shear matrices. Arbitrary 3D Rotations $$ \\begin{eqnarray} \\mathbf{R}_{uvw} & = &\\begin{bmatrix} x_u & y_u & z_u\\\\ x_v & y_v & z_v \\\\ x_w & y_w & z_w\\end{bmatrix} \\end{eqnarray} $$ $$\\mathbf{u}\\cdot\\mathbf{u} =\\mathbf{v}\\cdot\\mathbf{v} = \\mathbf{w}\\cdot\\mathbf{w} = 1\\\\ \\mathbf{u}\\cdot\\mathbf{v} =\\mathbf{v}\\cdot\\mathbf{w} = \\mathbf{w}\\cdot\\mathbf{u} = 0$$ $$\\mathbf{R}_{uvw}\\mathbf{u} = \\begin{bmatrix}\\mathbf{u}\\cdot\\mathbf{u} \\\\ \\mathbf{v}\\cdot\\mathbf{u} \\\\ \\mathbf{w}\\cdot\\mathbf{u}\\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\end{bmatrix} = x$$ Transforming Normal Vectors Surface normal vectors are perpendicular to the tangent plane of a surface. These normals do not transform the way we would like when the underlying surface is transformed. $$ \\mathbf{n}_N = (\\mathbf{n}&#94;T\\mathbf{M}&#94;{-1})&#94;T = (\\mathbf{M}&#94;{-1})&#94;T\\mathbf{n}$$ Translation and Affine Transformations $$ \\begin{bmatrix}x'\\\\y'\\\\1\\end{bmatrix} = \\begin{bmatrix}m_{11} & m_{12} & x_t \\\\ m_{21} & m_{22} & y_t \\\\ 0 & 0 & 1 \\end{bmatrix}\\begin{bmatrix}x \\\\ y\\\\1\\end{bmatrix} = \\begin{bmatrix}m_{11}x + m_{12}y + x_t \\\\ m_{21}x + m_{22}y + y_t \\\\ 1 \\end{bmatrix}$$ For vectors that represent directions, $$ \\begin{bmatrix}1 & 0 & x_t \\\\ 0 & 1 & y_t \\\\ 0 & 0 & 1 \\end{bmatrix}\\begin{bmatrix}x \\\\ y\\\\0\\end{bmatrix} = \\begin{bmatrix}x \\\\ y \\\\ 0 \\end{bmatrix}$$ It is interesting to note that if we multiply an arbitrary matrix composed of scales, shears, and rotations with a simple translation (translation comes second), we get $$ \\begin{bmatrix}1 & 0 & 0 & x_t \\\\ 0 & 1 & 0& y_t \\\\ 0 & 0 & 1 & z_t \\\\ 0 & 0 & 0 & 1\\end{bmatrix}\\begin{bmatrix}a_{11} & a_{12} & a_{13} & 0 \\\\ a_{21} & a_{22} & a_{23} & 0\\\\ a_{31} & a_{32} & a_{33} & 0 \\\\ 0 & 0 & 0 & 1\\end{bmatrix} = \\begin{bmatrix}a_{11} & a_{12} & a_{13} & x_t \\\\ a_{21} & a_{22} & a_{23} & y_t\\\\ a_{31} & a_{32} & a_{33} & z_t \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}$$ Thus, we can look at any matrix and think of it as a scaling/rotation part and a translation part because the components are nicely separated from each other. An important class of transforms are rigid-body transforms . These are composed only of translations and rotations, so they have no stretching or shrinking of the objects. Such transforms will have a pure rotation for the \\(a_{ij}\\) above. Inverses of Transformation Matrices $$ \\begin{array}0 \\mathbf{M} &= &\\mathbf{R}_1\\mbox{scale}(\\sigma_1, \\sigma_2, \\sigma_3)\\mathbf{R}_2,\\\\ \\mathbf{M}&#94;{-1} & = &\\mathbf{R}_2&#94;{T}\\mbox{scale}(1/\\sigma_1, 1/\\sigma_2, 1/\\sigma_3)\\mathbf{R}_1&#94;{T} \\end{array}$$ Coordinate Transformations All of the previous discussion has been in terms of using transformation matrices to move points around. We can also think of them as simply changing the coordinate system in which the point is represented. For example, in Figure 6.19, we see two ways to visualize a movement. In different contexts, either interpretation may be more suitable. For example, a driving game may have a model of a city and a model of a car. If the player is presented with a view out the windshield, objects inside the car are always drawn in the same place on the screen, while the streets and buildings appear to move backward as the player drives. On each frame, we apply a transformation to these objects that moves them farther back than on the previous frame. One way to think of this operation is simply that it moves the buildings backward; another way to think of it is that the buildings are staying put but the coordinate system in which we want to draw them—which is attached to the car—is moving. In the second interpretation, the transformation is changing the coordinates of the city geometry, expressing them as coordinates in the car's coordinate system. Both ways will lead to exactly the same matrix that is applied to the geometry outside the car. Coordinate frame , $$ \\mathbf{p } + u\\mathbf{u} + v\\mathbf{v} + w\\mathbf{w}$$ $$ \\mathbf{p}_{xy} = \\begin{bmatrix}\\mathbf{u} & \\mathbf{v} & \\mathbf{e} \\\\ 0 & 0 & 1\\end{bmatrix} \\mathbf{p}_{uv}$$ Chapter 7 : Viewing Viewing Transformations A camera transformation or eye transformation , which is a rigid body transformation that places the camera at the origin in a convenient orientation. It depends only on the position and orientation, or pose, of the camera. A projection transformation , which projects points from camera space so that all visible points fall in the range −1 to 1 in x and y. It depends only on the type of projection desired. A viewport transformation or windowing transformation , which maps this unit image rectangle to the desired rectangle in pixel coordinates. It depends only on the size and position of the output image. The Viewport Transformation $$ \\mathbf{M}_{vp} = \\begin{bmatrix}\\frac{n_x}2 & 0 & 0 & \\frac{n_x-1}2 \\\\ 0 & \\frac{n_y}2 & 0 & \\frac{n_y-1}2 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1\\end{bmatrix}$$ The Orthographic Projection Transformation $$ \\mathbf{M}_{ortho} = \\begin{bmatrix} \\frac2{r-l} & 0 & 0 & -\\frac{r+l}{r-l} \\\\ 0 & \\frac{2}{t-b} & 0 & -\\frac{t+b}{t-b} \\\\ 0 & 0 & \\frac{2}{n-f} & -\\frac{n+f}{n-f} \\\\ 0 & 0 & 0 &1\\end{bmatrix} $$ $$ \\begin{bmatrix} x_{pixel} \\\\ y_{pixel} \\\\ z_{canonical} \\\\ 1\\end{bmatrix} = (\\mathbf{M}_{vp}\\mathbf{M}_{ortho}) \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1\\end{bmatrix}$$ The Camera Transformation the eye position \\(\\mathbf{e}\\) , the gaze direction \\(\\mathbf{g}\\) , the view-up vector \\(\\mathbf{t}\\) . $$ \\begin{array}1 \\mathbf{w} &=& -\\frac{\\mathbf{g}}{||\\mathbf{g}||} \\\\ \\mathbf{u} & = & \\frac{\\mathbf{t} \\times \\mathbf{w}}{|| \\mathbf{t} \\times \\mathbf{w}||} \\\\ \\mathbf{v} & = & \\mathbf{w} \\times \\mathbf{u} \\end{array}$$ $$ \\begin{array}0 \\mathbf{M}_{cam} &=& \\begin{bmatrix} \\mathbf{u} & \\mathbf{v} & \\mathbf{w} & \\mathbf{e} \\\\ 0 & 0 & 0 & 1\\end{bmatrix}&#94;{-1} \\\\ &=& \\begin{bmatrix} x_u & y_u & z_u & 0 \\\\ x_v & v_v & z_V & 0 \\\\ x_w & y_w & z_w & 0 \\\\ 0 & 0 & 0 &1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 & 0 & -x_e \\\\ 0 & 1 & 0 &-y_e \\\\ 0 & 0 & 1 & -z_e \\\\ 0 & 0 & 0 & 1\\end{bmatrix}\\end{array}$$ The algorithm: $$ construct \\;\\mathbf{M}_{vp}\\\\ construct\\;\\mathbf{M}_{ortho}\\\\ construct\\;\\mathbf{M}_{cam} \\\\ \\mathbf{M} = \\mathbf{M}_{vp}\\mathbf{M}_{ortho}\\mathbf{M}_{cam}\\\\ \\mathbf{for}\\; each \\;line \\;segment (a_i, b_i) \\;\\mathbf{do}:\\\\ \\quad \\mathbf{p} = \\mathbf{Ma}_i \\\\ \\quad \\mathbf{q} = \\mathbf{Mb}_i \\\\ \\quad drawline(x_p, y_p, x_q, y_q)$$ Projective Transformations $$ y_s = \\frac{d}{z}y$$ $$ \\begin{bmatrix} \\bar x \\\\ \\bar y \\\\ \\bar z \\\\ \\bar w\\end{bmatrix} = \\begin{bmatrix} a_1 & b_1 & c_1 & d_1 \\\\ a_2 & b_2 & c_2 & d_2 \\\\a_3 & b_3 & c_3 & d_3 \\\\ e & f & g & h \\\\\\end{bmatrix} \\begin{bmatrix} z \\\\ y \\\\ z \\\\ 1\\end{bmatrix}$$ $$ (x', y', z') = (\\bar x/\\bar w, \\bar y/\\bar w, \\bar z/\\bar w) $$ Perspective Projection $$ \\mathbf{P} = \\begin{bmatrix} n & 0 & 0 & 0 \\\\ 0 & n & 0 & 0\\\\ 0 & 0 & n+f & -fn \\\\0 & 0 & 1 & 0\\end{bmatrix} $$ The first, second, and fourth rows simply implement the perspective equation. The third row, as in the orthographic and viewport matrices, is designed to bring the z -coordinate \"along for the ride\" so that we can use it later for hidden surface removal. In the perspective projection, though, the addition of a non-constant denominator prevents us from actually preserving the value of z —it's actually impossible to keep z from changing while getting x and y to do what we need them to do. Instead we've opted to keep z unchanged for points on the near or far planes. $$ \\mathbf{P}\\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\\\ z\\frac{n+f}{n} - f \\\\ \\frac z n \\end{bmatrix} \\sim \\begin{bmatrix} \\frac {nx}z \\\\ \\frac{ny}z \\\\ n+f -\\frac{fn}z \\\\ 1 \\end{bmatrix} $$ As you can see, x and y are scaled and, more importantly, divided by z . Because both n and z (inside the view volume) are negative, there are no \"flips\" in x and y . Although it is not obvious (see the exercise at the end of the chapter), the transform also preserves the relative order of z values between \\(z = n\\) and \\(z = f\\) , allowing us to do depth ordering after this matrix is applied. This will be important later when we do hidden surface elimination. Sometimes we will want to take the inverse of \\(\\mathbf{P}\\) , for example to bring a screen coordinate plus \\(z\\) back to the original space, as we might want to do for picking. The inverse is $$ \\mathbf{P}&#94;{-1} = \\begin{bmatrix} \\frac 1 n & 0 & 0 & 0 \\\\ 0 & \\frac 1 n & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\0 & 0 & -\\frac 1 {fn} & \\frac{n+f}{fn}\\end{bmatrix}$$ or, $$ \\mathbf{P}&#94;{-1} = \\begin{bmatrix} f & 0 & 0 & 0 \\\\ 0 & f & 0 & 0 \\\\ 0 & 0 & 0 & fn \\\\0 & 0 & -1 & n+f\\end{bmatrix}$$ $$ \\mathbf{M}_{per} = \\mathbf{M}_{ortho}\\mathbf{P} $$ So, the full set of matrices for perspective viewing is, $$ \\mathbf{M} = \\mathbf{M}_{vp}\\mathbf{M}_{ortho}\\mathbf{P}\\mathbf{M}_{cam} $$ The resulting algorithm is, $$ compute\\;\\mathbf{M}_{vp} \\\\ compute\\;\\mathbf{M}_{per} \\\\ compute\\; \\mathbf{M}_{cam} \\\\ \\mathbf{M} = \\mathbf{M}_{vp}\\mathbf{M}_{per}\\mathbf{M}_{cam} \\\\ \\mathbf{for}\\; each \\;line \\;segment \\;(\\mathbf{a}_i, \\mathbf{b}_i) \\mathbf{do}: \\\\ \\quad \\mathbf{p} = \\mathbf{Ma}_i \\\\ \\quad \\mathbf{q} = \\mathbf{Mb}_i \\\\ \\quad drawline(x_p/w_p, y_p/w_p, x_q/w_q, y_q/w_q)$$ $$ \\begin{array}0 \\mathbf{M}_{per} &=& \\begin{bmatrix} \\frac{2n}{r-l} & 0 & \\frac{l+r}{l-r} & 0 \\\\ 0 & \\frac{2n}{t-b} & \\frac{b+t}{b-t} & 0 \\\\ 0 & 0 & \\frac{f+n}{n-f} & \\frac{2fn}{f-n} \\\\ 0 & 0 & 1 &0\\end{bmatrix} \\\\ \\mathbf{M}_{OpenGL} &=& \\begin{bmatrix} \\frac{2|n|}{r-l} & 0 & \\frac{r+l}{r-l} & 0 \\\\ 0 & \\frac{2|n|}{t-b} & \\frac{t+b}{t-b} & 0 \\\\ 0 & 0 & \\frac{|n|+|f|}{|n|-|f|} & \\frac{2|f||n|}{|n|-|f|} \\\\ 0 & 0 & -1 &0\\end{bmatrix} \\end{array}$$ Some Properties of the Perspective Transform An important property of the perspective transform is that it takes lines to lines and planes to planes. In addition, it takes line segments in the view volume to line segments in the canonical volume. Field-of-View if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Fundamentals of Computer Graphics, Part 2"},{"url":"posts/books/algorithms-by-dasgupta/","text":"Introduction and Number Theory : Chapter 0 - 1 Divide and Conquer : Chapter 2 Graphs and Trees : Chapter 3 - 4 Greedy Algorithms and Dynamic Programming : Chapter 5 - 6 Linear Programming : Chapter 7 NP-Complete problems : Chapter 8 - 9 Quantized Algorithms : Chapter 10","tags":"books","title":"Algorithms by DasGupta"},{"url":"posts/books/fundamentals-of-computer-graphics-part-1/","text":"Chapter 1: Introduction Graphics Areas Core areas: Modeling Rendering Animation Other related ares: - User interaction - Virtual reality - Visualization - Image processing - 3D scanning - Computational photography Major Applications Video Games Cartoons Visual Effects Animated Films CAD/CAM Simulation Medical Imaging Information visualization Graphics API's Need to deal with at least two different API's : Graphics API and a User Interface API Graphics Pipeline A special software/hardware subsystem that efficiently draws 3D primitives in perspective. Usually optimized for processing triangles with shared vertices. Basic operations map 3D vertex locations to 2D screen positions and shade the triangles so that they both look realistic and appear in proper back to front order. Although drawing from back to front was once one of the most challenging research issues in Computer Graphics , now it is almost always solved by z-buffer . It turns out that the geometric manipulation used in the graphics pipeline can be accomplished almost entirely in a 4D coordinate space composed of three traditional geometric coordinates and a fourth homogeneous coordinate that helps with perspective viewing. These 4D vectors are manipulated using 4 X 4 matrices and 4-vectors. The pipeline, therefore consists of machinery for effectively processing and composing such matrices and vectors. This 4D coordinate system is certainly the biggest intellectual hurdle to jump when first learning computer graphics. Numerical Issues IEEE Floating point standards, allows programmer to make many convenient assumptions about numeric conditions to be handled. Three special values: infinity, -infinity and NaN Efficiency There are no magic rules... Write the code in a straightforward way. Compute results on the fly. Compile in optimized code. Use profiling tools to find bottlenecks Examine data structures to look for ways to improve locality. If possible make data unit sizes match to cache/page size on the target architecture. If profiling reveals bottleneck in computations, examine the assembly code generated by the compiler. rewrite the source code to solve any problems. Designing and Coding Graphics programs Class Design , vector2, vector3, hvector, rgb, transform, image, Float vs Double , Debugging Graphics Programs , The Scientific method , Look at the output, develop a hypothesis, test it, fix it. Images as coded debugging output , Data visualization for debugging Chapter 2 : Miscellaneous Math The cleaner the math, The cleaner the code. Sets and Mappings Mappings as in Functions. Cartesian product, Common sets and notations such as real numbers, non-negative real numbers, ordered pairs in real 2D plane, points in n-dimensional Cartesian space, integers, the set of 3D points on the unit sphere. Inverse mappings and bisections. Intervals, open and closed, set operations on intervals. Logarithms. Quadratic Equations Trigonometry Angles, Trigonometric functions, Pythagorean theorem, polar coordinates. Useful identities , Shifting identities, Pythagorean identities, Addition and subtraction identities, half-angle identities, product indentions, Law of sines, cosines and tangents, area of triangle. Vectors A vector describes a length and a direction. Vector operations, Cartesian coordinates. Dot product, cross product. Orthogonal bases and coordinate frames. Curves and surfaces 2D Implicit curves, Gradient, derivatives. Implicit lines, curves, 3D surfaces, surface normal, planes, 3D Quadric surfaces. 2D Parametric curves, 3D parametric curves Linear interpolation Triangles Barycentric coordinates, 2D triangles, 3D triangles. Chapter 3: Raster Images Pixel : Picture element Raster is just a 2D array of pixels. Images can also be in vector format. Such images are resolution independent and are used where precession is important and photographic images and complex shading is not needed. Raster Devices Output Display Transmissive: Liquid Crystal Display(LCD) Emissive : Light Emitting Diode (LED) Hardcopy Binary : Ink-jet Continuous tone : Dye sublimation printer Input 2D array sensor : digital camera iD array sensor : flatbed scanner Displays Emissive : Use pixels that directly emit controllable amounts of light. Transmissive : Requires a light source to illuminate them. Generally a backlight in case of LCD, or a lamp in case of a projector. Screen resolution. Hardcopy Devices Ink jet printer, thermal dye transfer, pixel density Input Devices Camera, Scanner Images, Pixels and Geometry Image as a function(mapping) from coordinate space to pixel value. Pixel Values : Pixel value ranges and different image formats like 1-bit grayscale : text and other images where intermediate grays are not desired (high resolution required); 8-bit RGB fixed-range color (24 bits total per pixel) : web and email applications, consumer photographs; 8- or 10-bit fixed-range RGB (24–30 bits/pixel) : digital interfaces to computer displays; 12- to 14-bit fixed-range RGB (36–42 bits/pixel) : raw camera images for professional photography; 16-bit fixed-range RGB (48 bits/pixel) : professional photography and printing; intermediate format for image processing of fixed-range images; 16-bit fixed-range grayscale (16 bits/pixel) : radiology and medical imaging; 16-bit \"half-precision\" floating-point RGB : HDR images; intermediate format for real-time rendering; 32-bit floating-point RGB : general-purpose intermediate format for software rendering and processing of HDR images. Resulting artifacts , Clipping: When pixels that would otherwise be brighter than the maximum value set are clipped too the maximum value. Quantization/Banding:* When formats with fixed precession are used, it causes visible jumps in intensity or color. Monitor intensities and Gamma displayed intensity = (maximum intensity) \\(\\alpha_{\\gamma}\\) , RGB Color Alpha Compositing Blending for partially covering pixels and transparent pixes. Image Storage lossless vs lossy formats. jpeg : lossy, compresses based on thresholds in human visual system. Works well for natural images. tiff : binary images, lossless compressed, 8 or 16 bit RGB ppm : lossless, uncompressed, 8-bit RGB, png : set of lossless formats, good set of open source management tools. Chapter 4 : Ray Tracing Rendering rendering is a process that takes as its input a set of objects and produces as its output an array of pixels. Image-order vs Object-order rendering. Ray tracing is an image-order algorithm. Basic ray tracing algorithm A basic ray tracer has three parts: ray generation, which computes the origin and direction of each pixel's viewing ray based on the camera geometry; ray intersection, which finds the closest object intersecting the viewing ray; shading, which computes the pixel color based on the results of ray intersection. $$\\bbox { \\mbox{for each pixel:}\\\\ \\quad \\mbox{compute viewing ray} \\\\ \\quad \\mbox{find first object hit by ray and its surface normal n} \\\\ \\mbox{set pixel color to value computed from hit point, light, and n} } $$ Perspective Computing Viewing Rays The Viewpoint and the image plane. Ray Object Intersection Ray-Sphere intersection: Ray-triangle intersections: Using barycentric coordinates. Ray-polygon intersection: Ray-object intersection: Shading A shading model. Lambertian Shading Blinn-Phong shading Lambertian shading is view independent. It does not have specular reflections that many surfaces have. $$ \\begin{array}1 \\mathbf{h} &=& \\frac{\\mathbf{v} + \\mathbf{l}}{||\\mathbf{v} + \\mathbf{l}||}, \\\\ L &=& k_dI\\mbox{max}(0, \\mathbf{n\\cdot l}) + k_sI\\mbox{max}(0, \\mathbf{n\\cdot h})&#94;p\\end{array},\\\\ \\text{where}, \\\\ \\, \\\\ \\begin{array}2 h &=& \\mbox{half vector.} \\\\ k_d &=& \\mbox{diffuse coefficient, surface color} \\\\ k_s &=& \\mbox{specular coefficient, or specular color} \\\\ I &=& \\mbox{light intensity} \\\\ L &=& \\mbox{pixel color} \\\\ p &=& \\mbox{Phong exponent, (typical values, 10-eggshell, 100 - mildly shiny, 1000 - really glossy, 10000-nearly mirror like)} \\end{array}$$ Ambient Shading $$ L = k_aI_a + k_d I \\mbox{max}(0, \\mathbf{n \\cdot l}) + k_s I \\mbox{max}(0, \\mathbf{n \\cdot h})&#94;p,\\\\ \\text{where}, \\\\ k_a = \\mbox{Ambient coefficient of the surface, or \"ambient color\"} \\\\ I_a = \\mbox{Ambient light intensity}$$ Multiple Point Lights Superposition - the effect caused by more than one light source is simply the sum of the effects of the light sources individually. $$ L = k_aI_a + \\sum_{i=1}&#94;N[k_d I_i \\mbox{max}(0, \\mathbf{n \\cdot l}_i) + k_s I_i \\mbox{max}(0, \\mathbf{n \\cdot h}_i)&#94;p ] $$ A Ray tracing program $$\\bbox { \\mbox{for each pixel:}\\\\ \\quad \\mbox{compute viewing ray} \\\\ \\quad \\mbox{if (ray hits an object with } t \\in [0, \\infty)) \\text { then} \\\\ \\quad \\quad \\mbox{ Compute}\\, \\mathbf{n} \\\\ \\quad \\quad \\mbox{ Evaluate shading model and set pixel to that color } \\\\ \\quad \\mbox{else} \\\\ \\quad \\quad \\mbox{set pixel color to background color} } $$ Object oriented design for a Ray-tracing program Some discussion on Surface class, hit method, bounding box and Material class. Shadows $$\\bbox{ \\mathbf{function} \\;raycolor\\;(\\text{ray } \\mathbf{e} + t\\mathbf{d}, \\text{real }t_0, \\text{real } t_1)\\\\ \\text{hit-record}\\; rec,\\,srec\\\\ \\mathbf{if} (scene\\rightarrow hit(\\mathbf{e} + t\\mathbf{d}, t_0, t_1, rec)) \\mathbf{then} \\\\ \\quad \\mathbf{p} = \\mathbf{e} + (rec.t)\\mathbf{d}\\\\ \\quad \\text{colot} c = rec.k_a\\cdot I_a\\\\ \\quad \\quad \\mathbf{if} (not\\; scene\\rightarrow hit(\\mathbf{p} + s\\mathbf{l}, \\infty, srec)) \\mathbf{then} \\\\ \\quad \\quad \\text{vector3 } \\mathbf{h} = normalized(normalized(\\mathbf{l}) + normalized(\\mathbf{-d})) \\\\ \\quad \\quad c = c + rec.k_d I \\text{max}(0 , rec.\\mathbf{n\\cdot l}) + (rec.k_s)I(rec.\\mathbf{n\\cdot h})_{rec.p}\\\\ \\quad \\mathbf{return } \\; c\\\\ \\mathbf{else} \\\\ \\quad \\mathbf{return }\\; \\text{background-color} } $$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Fundamentals of Computer Graphics, Part 1"},{"url":"posts/books/fundamentals-of-computer-graphics/","text":"Fundamentals of Computer Graphics : Chapter 1 - 4 Introduction, Basic Maths, Raster Images and Introduction to Ray Tracing. Fundamentals of Computer Graphics : Chapter 5 - 7 Linear Algebra, Transformation Matrices and View Transformations Fundamentals of Computer Graphics : Chapter 7 - 6","tags":"books","title":"Fundamentals of Computer Graphics"},{"url":"posts/books/elements-of-statistical-learning-part-1/","text":"Chapter 1: Introduction Motivation towards statistical learning and belief in data. What's next. Chapter 2: Overview of Supervised Learning Variable types and terminology Quantitative vs Qualitative output. Regression and Classification Simple approaches : Least Squares and Nearest Neighbors Linear Models and Least Squares \\(\\hat Y = \\hat \\beta_0 + \\sum_{j=1}&#94;pX_j\\hat\\beta_j\\) Least squares by solving normal equations. Nearest Neighbor Methods Voronoi tessellation From Least Squares to Nearest Neighbors Statistical Decision Theory Local Methods in High Dimensions The curse of Dimensionality, Bellman Statistical Models, Supervised Learning and Function Approximation A Statistical Model for the Joint Distribution Pr(X, Y ) Supervised Learning Function Approximation Structured Regression Models Difficulty of the Problem Classes of Restricted Estimators Roughness Penalty and Bayesian Methods regularization Kernel Methods and Local Regression Basis Functions and Dictionary Methods Model Selection and the Bias–Variance Tradeoff Chapter 3: Linear Methods Of Regression Introduction Linear Regression Models and Least Squares Solution from normal form F statistic Example : prostrate cancer The Gauss-Markov Theorem Proof that the Least Squares estimate for the parameters, \\(\\beta\\) has the least variance. Multiple Regression from Simple Univariate Regression Multiple Outputs Subset Selection Best-Subset Selection Forward and Backward-Stepwise Selection Forward-Stagewise Selection Example : Prostrate Cancer (Continued) Shrinkage Methods Ridge Regression : L2 regularization The Lasso : L1 regularization Discussion : Subset Selection, Ridge Regression and the Lasso Least Angle Regression Methods Using Derived Input Directions Principal Components Regression Partial Least Squares Discussion : A Comparison of Selection and Shrinkage Methods Multiple Outcomes Shrinkage and Selection ☠ More on Lasso and Related Path Algorithms ☠ Incremental Forward Stagewise Regression Piecewise-Linear Path Algorithms The Dantzig selector The Grouped Lasso Further Properties of Lasso Pathwise Coordinate Optimization Computational Considerations Fitting is usually done using Cholesky decomposition of matrix \\(X&#94;TX\\) . Chapter 4: Linear Methods of Classification Introduction Linear Regression of an Indicator Matrix Linear Discriminant Analysis Regularized Discriminant Analysis Computations for LDA Reduced-Rank Linear Discriminant Analysis Logistic Regression Fitting Logistic Regression Models Example : South African Heart Disease Quadratic Approximations and Inference \\(L_1\\) Regularized Logistic Regression Logistic Regression or LDA ? Separating Hyperplanes Rosenblatt's Perceptron Learning Algorithm Optimal Separating Hyperplanes ☠ Chapter 5: Basis Expansions and Regularization Introduction Piecewise Polynomials and Splines Natural Cubic Splines Example: South African Heart Disease (Continued) Example: Phoneme Recognition Filtering and Feature Extraction Smoothing Splines Degrees of Freedom and Smoother Matrices Automatic Selection of the Smoothing Parameters Fixing the Degrees of Freedom The Bias–Variance Tradeoff Nonparametric Logistic Regression Multidimensional Splines Regularization and Reproducing Kernel Hilbert Spaces ☠ Spaces of Functions Generated by Kernels Examples of RKHS Penalized Polynomial Regression Gaussian Radial Basis Functions Support Vector Classifiers Wavelet Smoothing ☠ Wavelet Smoothing and the Wavelet Transform Adaptive Wavelet Filtering Chapter 6: Kernel Smoothing Methods One-Dimensional Kernel Smoothers Local Linear Regression Local Polynomial Regression Selecting the Width of the Kernel Local Regression in \\({\\mathbb R}&#94;p\\) Structured Local Regression Models in \\({\\mathbb R}&#94;p\\) Structured Kernels Structured Regression Functions Kernel Density Estimation and Classification Kernel Density Estimation Kernel Density Classification The Naive Bayes Classifier Radial Basis Functions and Kernels Mixture Models for Density Estimation and Classification Computational Considerations if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Elements Of Statistical Learning, Part 1"},{"url":"posts/books/introduction-to-philosophy/","text":"These are just some bullet notes from the Coursera course Introduction to philosophy What Is Philosophy Working out the best way to thinking about things. The philosophical question. Philosophy: Difficult, Important and Everywhere Is it 'Fundamental'? No,.. Yes,..? Is it 'Important'? No,.. Yes,.? How Do We Do It? Arguments to your questions Do we have free will? Is there a right way to think about things? How do we know we can get to the right way just by thinking,.? What Is Knowledge? And Do We Have Any? Basic Constituents of Knowledge Propositional vs Ability knowledge Conditions for propositional knowledge Truth Belief Knowledge : Something more than just getting it right. Intuitions About Knowledge The Anti-Luck Intuition The Ability Intuition The Classical Account of Knowledge and the Gettier Problem Classical definition od knowledge Justified, True, Belief Gettier CounterExamples Knowledge cannot be merely justified true belief It might just be a matter of luck that your belief is true, irreverent of your justification. Examples The Stopped Clock!! A Sheep Behind a Sheep Shaped Object. Formula For Creating Gettier Cases - is easy!! Additional Conditions !! @@ NO FALSE LEMMAS : Farley complicated and boring Do We have any knowledge? Radical Skepticism, we don't know nearly as much as we think we do. We have as much knowledge as we take ourselves to have. Brain-in-a-vat Hypothesis : The Matrix How do we know that its not true.? Quite far fetched. Lots of arguments. And similar problems... Still not answerable to a simple solution. Minds, Brains and Computers What is it to have a mind? Theories of Mind Cartesian (or Substance) Dualism, by Descartes Mind is made of fundamentally different substance to the body. The mind is made of immaterial stuff and the body is made of material stuff. Princess Elizabeth of Bohemia & other problems of causation Physical things can only be affected/changed by interaction with other physical things Physicalism , all that exists is physical stuff. Identity Theory of physicalism having a mental state consists in being a particular physical state, mental and physical states are identical. Type identity and Token Identity Type identity offers a strong research prograam, it says that type of physical states are identical to type of mental states. A problem of type identity theory Hilary Putnam, claimed that type-identity would find the identical physical state with mental state of being in pain, for humans It might be something entirely different physical state for octopus for example, but the same mental state of being in pain. Mental states are multiply realizable. Functionalism Chairs can be made of many different things, shapes, sizes, look completely different But what makes them identifiable as chairs is the job that they do. Mind as a Computer With Functionalism, it has become very popular to think about the mind as analogous to a computer. It tries to argue that, like computers, minds are information processing units that take information of some kind and turn it into information of other kind. Turing Machines Identify the between machine and man. When the machine is able to fool the interrogator, then the computer has reached the level of functional complexity required to have a mind. Objections , A machine with a huge database with answers to all the questions. Would we call it a 'thinking' machine.? There can be beings that cannot persuade the questioner that they are human, but who we nevertheless want to count as minded. The Turing test relies on language, and a very narrow criteria for minds. John Searle's Chinese Room You get a symbol that you dont understand, you have a code book that tells what other symbol to respond with when you see a symbol. On the other hand, there is a person who is conversing with you in Chinese. But you don't even know that you are in a communicative act. Computers work by processing symbols. Symbols have syntactic and semantic properties. Computers are manipulating machines, more importantly, they are only aware of the syntactic properties of the symbol. We program the computer to operate on the syntactic structure of the symbol. The problem is that the computer does not 'know' the semantic content about the symbols that it is manipulating. If our mind is indeed a machine, where is the 'programmer' who deciphers meanings of symbols that our mind process? Representation is a three way relation. X represents Y to Z; the beer-mug represents my position on field to my friends. However, in case of the mind this neural activity represents a dog to ??? Morality: Objective, Relative or Emotive The status of morality Here we ask the question, what are we doing when we make moral judgments. The Questions Are they sorts of judgments that can be true or false - or are they mere opinions? If they are true /false, what makes them true /false? If they are true, are they objectively true? Objectivism Our moral judgments are the sorts of things that can be true or false, and what makes them true or false are facts that are generally independent of what are or what cultural groups we belong to - they are objective moral facts. Objection : How do you account for moral disputes between two people then? Relativism Our moral judgments are indeed true or false, but they're only true or false relative to something that can vary between people. Objections : How do you explain or keep track of moral progress then? Subjectivism , a form of relativism Out moral judgments are indeed true or false, but they're only true or false relative to the subjective feelings of the person who makes them. \"X is bad\" = \"I dislike X\" Cultural Relativism , a form of relativism Our moral judgments are indeed true or false, but they are only true or false relative to the culture of the person who makes them. \"X is bad\" = \"X is disapproved of in my culture\" Emotivism Moral judgments are neither objectively true/false or relatively true/false. They're direct expressions of our emotive reactions. Objections : How do you account for the moral decisions that we make and conclusions we arrive at based on our cognitive abilities. Should you believe what you hear Testimony and Miracles The Enlightenment : intellectual autonomy Hume : naturalistic philosophy Never believe that a miracle has occurred, on the basis of a testimony What is testimony? Any situation in which you believe something on the basis of what someone else asserts, either verbally or in writing. A lot of what we believe about the world is based on the testimony of other people. Hume assumes that you should only trust testimony when you have evidence that the testifier is likely to be right. Evidentialism : A wise man,... proportions his belief to the evidence. On Miracle, A miracle is a violation of the laws of nature. Thomas Ried argued, that trusting testimony is analogous to trusting your senses. we don't only trust our senses when we have evidence that they're likely to be right. Kant, Enlightenment is man's emergence from his self-incurred immaturity. Immaturity is the inability to use one's own understanding without the guidance of another. The motto of enlightenment is therefore : Have courage to use your own understanding. Intellectual autonomy : Think for yourself. Is your beliefs are based merely on testimony, they will not amount to knowledge. Are Scientific Theories true Time Travel and Philosophy Reading","tags":"books","title":"Introduction To Philosophy"},{"url":"posts/books/learning-how-to-learn/","text":"These are just some bullet notes from the Coursera course Introduction to philosophy What is learning Focused and Diffuse modes of thinking Procrastination Memory Importance of Sleep Chunking Recall Illusions of Competence Acetylcholine : focused learning Dopamine : motivation serotonin Overlearning, Choking, Eenstellung, Interleaving Illusions of Competence Deliberate learning Transfer and Library of Chunks Procrastination procrastination and memory Zombie Mode: Habits The Cue, Routine, Reward and Belief Process VS Product Memory Long term memory the power of repetition Using your visual and spatial memory systems Meaningful groups and Memory Palace Learning Keep learning Create metaphors and analogy Don't Panic No need to envy!! Change!! Teamwork Hard start - Jump to Easy","tags":"books","title":"Learning how to Learn"},{"url":"posts/books/notes-on-opengl/","text":"Transformations Translation : (x, y, z) $$ \\begin{bmatrix} 1 & 0 & 0 & x \\\\ 0 & 1 & 0 & y \\\\ 0 & 0 & 1 & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Scale : (x, y, z) $$ \\begin{bmatrix} x & 0 & 0 & 0 \\\\ 0 & y & 0 & 0 \\\\ 0 & 0 & z & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Rotation x : $$ \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & cos(\\theta) & -sin(\\theta) & 0 \\\\ 0 & sin(theta) & cos(theta) & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Rotation y : $$ \\begin{bmatrix} cos(\\theta) & 0 & sin(\\theta) & 0 \\\\ 0 & 1 & 0 & 0 \\\\ -sin(\\theta) & 0 & cos(theta) & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Rotation z : $$ \\begin{bmatrix} cos(\\theta) & -sin(\\theta) & 0 & 0 \\\\ sin(theta) & cos(theta) & 0 & 0 \\\\ 0 & 0 & 1 & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Vertex Specifications Specify vertex data. Create buffer Data: const float vertexPositions[] = {...} Initialize vertex Buffer: glGenBuffers(1, &posiionBufferObject) glbindbuffer(GL_ARRAY_BUFFER, positionbufferObject) glbufferData(GL_ARRAY_BUFFER, sizeof(vertexpositions), vertexpositions, BufferobjectUsageHint) BufferobjectUsagehint: GL__STATIC_DRAW : Static data, only intend to set it once GL_STREAM_DRAW : Dynamic data, intend to update it constantly, generally once per frame glbindbuffer(0) Specify vertex data: glbindbuffer(GL_ARRAY_BUFFER, positionbufferobject) glenablevertexattribarray(0) glvertexattribarray(0, 4, GL_FLOAT, GL_FALSE, 0, 0) Display: gldrawarrays(GL_TRIANGLES, 0, 3) glbufferSubData() : Change buffer data value Vertex Array Objects: OpenGL Objects that store all of the state needed to make one or more draw calls. This includes attribute array setup information from glVertexAttribArray , buffer objects used for attribute arrays, and GL_ELEMENT_ARRAY_BUFFER binding, which is a buffer object that stores the index arrays, if needed Pipeline Vertex Specification Vertex Proocessing and Vertex Shader Culling Rasterization Fragment Processing if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Notes On Opengl"},{"url":"posts/books/elements-of-statistical-learning/","text":"Elements Of Statistical Learning, Part 1 Elements Of Statistical Learning, Part 2 Elements Of Statistical Learning, Part 3","tags":"books","title":"Elements Of Statistical Learning"},{"url":"posts/gallery/sketch_2/","text":"Some recent sketches, Part 2","tags":"gallery","title":"sketch_2"},{"url":"posts/articles/blogging-like-a-hacker/","text":"Edit: After the blog post I have moved to Pelican , mostly because of my affinity for python. ❤️ So, finally I was able to settle up for a blog after months of procrastination with multiple frameworks and platforms. I had earlier tried to use Tumblr . But, I wanted to be able to explore different areas, like sharing my views on technology that I am currently interested in, music that I am currently digging in, some random art that I create and so on. Tumblr turned out to be a great platform for sharing my art, but for the same reasons did not look like a place where I could write about deep neural networks, natural language and computer vision. Though there are some blogs there that do just that . Then I tried Wordpress, but was never able to settle down on something satisfying and never actually pushed anything. It just had too much to fiddle with, so many options, so many plugins. :confused: This was very difficult for someone like me who opens 20 new browser tabs reading a single post and then bookmarks them all for reading later.:innocent: Then I spend two weeks doing Django tutorials . It was an interesting experience as this was my first time dealing with Python and web frameworks as well. but, in the end, I realized that these are just as many knobs, even if I keep the features minimal, it was too much work for me as I did not wanted to spend so much time building web technology(i would rather complete Skyrim). :grin: Then, after abandoning my quest for several months, I came across this awesome article about writing programming blogs, and how it is important for being a part of the technical community today. And, naturally, I had another 25 tabs open looking for advice on starting a tech blog and most feasible platforms to do so today. There I found this post. It talks about using jekyll with github pages as a blogging platform. Though I already \"knew\" about it, but I only thought of as a cleaner way of viewing your README files written in markdown. As I read through that article, it was clear to me that I would be able to settle in with this. It was simple to setup, free and simple to host, works with markdown which everybody uses, no necessary knobs to fiddle with databases and hosting providers. It was a great resource as it also listed out other links that I could follow to customize as much as I wanted. So, I opened up another browser window and started searching for some good themes, which brought me back to the themes originally suggested here . So, this website was created using the theme lanyon , which derives from poole . Jekyll, Poole and Lanyon are all characters from The Strange Case of Dr. Jekyll and Mr. Hyde . I started with forking the theme to my repo, following this article. However, before actually posting anything I had to setup up a local environment for jekyll also discussed in the article. Customizations Added support for Disqus comments. Added Google Analytics support. Changed some icons. Added sections for Timeline and resume Added sections for Art gallery.","tags":"articles","title":"Blogging like a hacker"},{"url":"posts/books/head-first-design-patterns/","text":"Strategy Pattern Defines a family of algorithms, encapsulates each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it. Observer Pattern Defines one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated. Decorator Pattern Attach additional responsibilities to an object dynamically. Decorators provide a flexible alternative to subclassing for existing functionality. Java IO classes Factory Method Pattern Defines an interface for creating an object, but lets subclasses decide which class to instantiate. factory Method lets a class defer instantiation to subclass. Abstract Factory Method Pattern Provides an interface for creating families of related or dependent objects without specifying their concrete classes. Singleton Pattern Ensure a class only has one instance and provide a global point of access to it. Command Pattern Encapsulates a request as an object, thereby letting you parameterize clients with different requests, queue or log requests and support undo-able operations. Transactions Adapter Pattern Converts the interface of a class into another interface clients expect. Lets classes work together that couldn't otherwise because of incompatible interface. Facade pattern Provides a unified interface to a set of interfaces in a subsystem. Facade defines a higher-level interface that makes the subsystem easier to use. Template Method Pattern Define the skeleton of an algorithm in n operation, deferring some steps to subclasses. Template Method lets subclass redefine certain steps of an algorithm without changing the algorithm's structure. Iterator Pattern Provide a way to access the elements of an aggregate object sub sequentially without exposing its underlying representation. Composite Pattern Compose objects into tree structures to reresent part-whole heriarchies. Composite lets clients treat individual objects and compositions of objects uniformly. State Pattern It Allows an object to alter its behavior when its internal state changes. The object will appear to change its class. Proxy Pattern Provides a surrogate or placeholder for another object to control access to it.","tags":"books","title":"Head First Design Patterns"},{"url":"posts/gallery/fractals_1/","text":"Some fun with fractals","tags":"gallery","title":"fractals_1"},{"url":"posts/gallery/sketch_1/","text":"Some recent sketches, Part 1","tags":"gallery","title":"sketch_1"},{"url":"posts/gallery/misc/","text":"Some misc. cutouts and experiments.","tags":"gallery","title":"misc"},{"url":"posts/gallery/monochrome/","text":"Some black and white stuff, with colors","tags":"gallery","title":"monochrome"},{"url":"posts/gallery/in_making_3/","text":"Some early creations, Part 3","tags":"gallery","title":"in_making_3"},{"url":"posts/gallery/in_making_2/","text":"Some early creations, Part 2","tags":"gallery","title":"in_making_2"},{"url":"posts/gallery/in_making_1/","text":"Some early creations, Part 1","tags":"gallery","title":"in_making_1"}]}