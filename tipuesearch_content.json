{"pages":[{"url":"pages/peterpan/","text":"","tags":"pages","title":"PeterPan"},{"url":"pages/untitled1/","text":"","tags":"pages","title":"Untitled1"},{"url":"pages/graffiti1/","text":"","tags":"pages","title":"graffiti1"},{"url":"pages/magazines/","text":"","tags":"pages","title":"magazines"},{"url":"pages/nightclub/","text":"","tags":"pages","title":"nightClub"},{"url":"pages/portrait1_2/","text":"","tags":"pages","title":"portrait1_2"},{"url":"pages/portrait1_filter/","text":"","tags":"pages","title":"portrait1_filter"},{"url":"pages/graffiti201/","text":"","tags":"pages","title":"graffiti2~01"},{"url":"pages/graffiti3_filter01/","text":"","tags":"pages","title":"graffiti3_filter~01"},{"url":"pages/graffiti301/","text":"","tags":"pages","title":"graffiti3~01"},{"url":"pages/greeklovers01/","text":"","tags":"pages","title":"greekLovers~01"},{"url":"pages/landscape12_electromagnetic01/","text":"","tags":"pages","title":"landscape12_electromagnetic~01"},{"url":"pages/landscape12_ultraviolet01/","text":"","tags":"pages","title":"landscape12_ultraviolet~01"},{"url":"pages/landscape1201/","text":"","tags":"pages","title":"landscape12~01"},{"url":"pages/noface101/","text":"","tags":"pages","title":"noFace1~01"},{"url":"pages/portrait11_filter01/","text":"","tags":"pages","title":"portrait11_filter~01"},{"url":"pages/portrait7_negative01/","text":"","tags":"pages","title":"portrait7_negative~01"},{"url":"pages/portrait701/","text":"","tags":"pages","title":"portrait7~01"},{"url":"pages/silhouette3_electromagnetic01/","text":"","tags":"pages","title":"silhouette3_electromagnetic~01"},{"url":"pages/silhouette3_negative01/","text":"","tags":"pages","title":"silhouette3_negative~01"},{"url":"pages/splash_ufilter01/","text":"","tags":"pages","title":"splash_ufilter~01"},{"url":"pages/splash01/","text":"","tags":"pages","title":"splash~01"},{"url":"pages/woodpecker201/","text":"~01.jpg)","tags":"pages","title":"woodpecker(2)~01"},{"url":"pages/graffiti_mrdj_filter/","text":"","tags":"pages","title":"Graffiti_mrDJ_filter"},{"url":"pages/graffiti_mrdj/","text":"","tags":"pages","title":"graffiti_mrDJ"},{"url":"pages/wonderwoman_2/","text":"","tags":"pages","title":"wonderWoman_2"},{"url":"pages/69_filter01/","text":"","tags":"pages","title":"69_filter~01"},{"url":"pages/6901/","text":"","tags":"pages","title":"69~01"},{"url":"pages/batman_filter01/","text":"","tags":"pages","title":"Batman_filter~01"},{"url":"pages/batman01/","text":"","tags":"pages","title":"Batman~01"},{"url":"pages/boat1/","text":"","tags":"pages","title":"Boat1"},{"url":"pages/girl103_filtered201/","text":"","tags":"pages","title":"Girl103_filtered2~01"},{"url":"pages/girl103_filtered01/","text":"","tags":"pages","title":"Girl103_filtered~01"},{"url":"pages/ironman_filter_201/","text":"","tags":"pages","title":"IronMan_filter_2~01"},{"url":"pages/ironman_filter01/","text":"","tags":"pages","title":"IronMan_filter~01"},{"url":"pages/ironman01/","text":"","tags":"pages","title":"IronMan~01"},{"url":"pages/johnnybravo/","text":"","tags":"pages","title":"JohnnyBravo"},{"url":"pages/window_filtered01/","text":"","tags":"pages","title":"Window_filtered~01"},{"url":"pages/window01/","text":"","tags":"pages","title":"Window~01"},{"url":"pages/wonderwoman01/","text":"","tags":"pages","title":"WonderWoman~01"},{"url":"pages/animalcomposition102/","text":"","tags":"pages","title":"animalComposition1~02"},{"url":"pages/boy102/","text":"","tags":"pages","title":"boy102"},{"url":"pages/composition_10901/","text":"","tags":"pages","title":"composition_109~01"},{"url":"pages/dragonsonthewall/","text":"","tags":"pages","title":"dragonsOnTheWall"},{"url":"pages/face0101/","text":"","tags":"pages","title":"face01~01"},{"url":"pages/face0301/","text":"","tags":"pages","title":"face03~01"},{"url":"pages/feline_1/","text":"","tags":"pages","title":"feline_1"},{"url":"pages/feline_1_filtered/","text":"","tags":"pages","title":"feline_1_filtered"},{"url":"pages/fly/","text":"","tags":"pages","title":"fly"},{"url":"pages/forest_electromagnetic01/","text":"","tags":"pages","title":"forest_electromagnetic~01"},{"url":"pages/forest_negative01/","text":"","tags":"pages","title":"forest_negative~01"},{"url":"pages/forest01/","text":"","tags":"pages","title":"forest~01"},{"url":"pages/girl12_filter01/","text":"","tags":"pages","title":"girl12_filter~01"},{"url":"pages/girl1201/","text":"","tags":"pages","title":"girl12~01"},{"url":"pages/portrait1101/","text":"","tags":"pages","title":"portrait11~01"},{"url":"pages/thingfish/","text":"","tags":"pages","title":"thingFish"},{"url":"pages/wonderwoman0101/","text":"","tags":"pages","title":"WonderWoman~01~01"},{"url":"pages/portrait_angelina_edited/","text":"","tags":"pages","title":"portrait_angelina_edited"},{"url":"pages/portrait_ash/","text":"","tags":"pages","title":"Portrait_Ash"},{"url":"pages/scarlett/","text":"","tags":"pages","title":"Scarlett"},{"url":"pages/architecture_1201/","text":"","tags":"pages","title":"architecture_12~01"},{"url":"pages/mface_28/","text":"","tags":"pages","title":"mFace_28"},{"url":"pages/mface_03/","text":"","tags":"pages","title":"mFace_03"},{"url":"pages/mface_09/","text":"","tags":"pages","title":"mFace_09"},{"url":"pages/mface_16/","text":"","tags":"pages","title":"mFace_16"},{"url":"pages/mface_17/","text":"","tags":"pages","title":"mFace_17"},{"url":"pages/mface_25/","text":"","tags":"pages","title":"mFace_25"},{"url":"pages/mface_32/","text":"","tags":"pages","title":"mFace_32"},{"url":"pages/frac_01/","text":"","tags":"pages","title":"frac_01"},{"url":"pages/frac_05/","text":"","tags":"pages","title":"frac_05"},{"url":"pages/frac_08/","text":"","tags":"pages","title":"frac_08"},{"url":"pages/frac_13/","text":"","tags":"pages","title":"frac_13"},{"url":"pages/gallery/","text":"","tags":"pages","title":"Gallery"},{"url":"pages/bio/","text":"A self motivated and passionate engineer who is interested in computer graphics, simulations, machine intelligence, computer vision and everything in between. On the other side I am very much into video games(all kind), music(all kind), visual art(all kind) and (philosophy of)sciences(almost all kind). I had a very boring start when I joined Bachelors in Mechanical, IIT Roorkee. Although it is an awesome place, I found out that my passions don't lie in the gear box, (or the machining lab for that matter). Pretty soon I found myself consuming lots of games and music. Started playing with some game engines and created a very basic 3D Flight Simulator . And that was all I did in my time there(apart from the other things that engineering students do). Fortunately, I got hired at VizExperts India , an information visualization company with roots in desktop graphics. That was the time when I realized how cool programming can be!!! From there on, it has been quite a journey. We primarily worked on our in-house 3D GIS based planning and simulation engine built on an open source renderer, OpenSceneGraph which has been called with different names since then, we will just call it GeorbIS . I worked on everything from frontend UI framework to rendering and simulation engine to 3D computational filters. It really brought back all the lost love i had for classical physics in the form of Matrix transformations.Did a lot of app level features with direct involvement with the clients. I also had a small role in VizSim platform, a distributed simulation engine that provides real time sensor data fusion and visualization. There I got introduced to OpenCV and computer vision in general and implemented my first object detection and tracking pipeline. It was very cool. After that, we started working on VizGame , a gamified training platform built on top of Unreal Engine . It used our GeorbIS framework as a data backend for creating procedurally populated, highly realistic terrains with GIS data. Here, again, my role went from laying out the Game design to implementing multiplayer(Co-presence) in VR. And by this time I was also involved in mentoring other people who were like me a few years back. In the mean time I was getting more and more interested towards data science and machine intelligence. So, I decided to pursue my interests with self learning, with a vision of somehow managing to merge my experience with computer graphics and simulation to the field of computer vision and robotics. Lets see how far we can get.!!!! For a more professional looking resume, click here .","tags":"bio","title":"Bio"},{"url":"posts/books/how-the-backpropogation-algorithm-works/","text":"Notes for the book . Source code for the book. Chapter 2: How the backpropogation algorithm works Was introduced in the 70's, but came into light with this paper . Today, it is the workhorse of learning in neural networks. Warm up: a fast matrix-based approach to computing the output from a neural network First, the notations, For weights, For biases and activations, These are related, $$\\begin{eqnarray} a&#94;{l}_j = \\sigma\\left( \\sum_k w&#94;{l}_{jk} a&#94;{l-1}_k + b&#94;l_j \\right), \\tag{23}\\end{eqnarray}$$ which can be rewritten in vectorized form as, $$\\begin{eqnarray} a&#94;{l} = \\sigma(w&#94;l a&#94;{l-1}+b&#94;l). \\tag{25}\\end{eqnarray}$$ This form is more compact and practical as we will be using libraries that provide fast matrix multiplication and vectorization capabilities. The two assumptions we need about the cost function The goal of backpropogation is to calculate the partial derivatives \\(\\partial C / \\partial w\\) and \\(\\partial C / \\partial b\\) . Here is an example of cost function we will be using(there can and will be others). $$\\begin{eqnarray} C = \\frac{1}{2n} \\sum_x \\|y(x)-a&#94;L(x)\\|&#94;2, \\tag{26}\\end{eqnarray}$$ Now, the assumptions, The cost function can be written as an average \\(C = \\frac{1}{n} \\sum_x C_x\\) over cost \\(C_x\\) for individual training examples. The cost function can be written as a function of the outputs from the neural network: $$\\begin{eqnarray} C = \\frac{1}{2} \\|y-a&#94;L\\|&#94;2 = \\frac{1}{2} \\sum_j (y_j-a&#94;L_j)&#94;2, \\tag{27}\\end{eqnarray}$$ The Hadamard product, \\(s \\odot t\\) \\(s \\odot t\\) represents the elementwise product of two vectors. $$\\begin{eqnarray} \\left[\\begin{array}{c} 1 \\\\ 2 \\end{array}\\right] \\odot \\left[\\begin{array}{c} 3 \\\\ 4\\end{array} \\right] = \\left[ \\begin{array}{c} 1 * 3 \\\\ 2 * 4 \\end{array} \\right] = \\left[ \\begin{array}{c} 3 \\\\ 8 \\end{array} \\right]. \\tag{28}\\end{eqnarray}$$ The four fundamental equations behind backpropagation First, we define the error in the \\(j&#94;{th}\\) neuron in the \\(l&#94;{th}\\) layer, \\(\\delta&#94;l_j\\) $$\\begin{eqnarray} \\delta&#94;l_j \\equiv \\frac{\\partial C}{\\partial z&#94;l_j}. \\tag{29}\\end{eqnarray}$$ An equation for the error in the output layer, \\(\\delta&#94;L\\) : $$\\begin{eqnarray} \\delta&#94;L_j = \\frac{\\partial C}{\\partial a&#94;L_j} \\sigma'(z&#94;L_j). \\tag{BP1}\\end{eqnarray}$$ Which can again be rewritten in vectorized form, $$\\begin{eqnarray} \\delta&#94;L = \\nabla_a C \\odot \\sigma'(z&#94;L). \\tag{BP1a}\\end{eqnarray}$$ where, in case of a quadratic cost function, we have \\(\\nabla_a C = (a&#94;L-y)\\) .So, $$\\begin{eqnarray} \\delta&#94;L = (a&#94;L-y) \\odot \\sigma'(z&#94;L). \\tag{30}\\end{eqnarray}$$ An equation for the error \\(\\delta&#94;l\\) in terms of the error in the next layer, \\(\\delta&#94;{l+1}\\) : $$\\begin{eqnarray} \\delta&#94;l = ((w&#94;{l+1})&#94;T \\delta&#94;{l+1}) \\odot \\sigma'(z&#94;l), \\tag{BP2}\\end{eqnarray}$$ Suppose we know the error \\(\\delta&#94;{l+1}\\) at the \\(l+q&#94;{\\rm th}\\) layer. When we apply the transpose weight matrix, \\((w&#94;{l+1})&#94;T\\) , we can think intuitively of this as moving the error backward through the network, giving us some sort of measure of the error at the output of the \\(l&#94;{\\rm th}\\) layer. By combining \\((BP1)\\) and \\((BP2)\\) , we can compute the error \\(\\delta&#94;l\\) for any layer in the network. An equation for the rate of change of the cost with respect to any bias in the network $$\\begin{eqnarray} \\frac{\\partial C}{\\partial b&#94;l_j} = \\delta&#94;l_j. \\tag{BP3}\\end{eqnarray}$$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"How the backpropogation algorithm works"},{"url":"posts/machine-intelligence/object-detection-and-image-segmentation/","text":"Deep Learning Image Segmentation Image segmentation review Source A review of segmentation at qure.ai Rich feature hierarchies for accurate object detection and semantic segmentation Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik : Oct 2014 Source Introduces R-CNN, Regions with CNN. Bridging the gap between image classification and object detection. Object detection with R-CNN Region proposals. Uses selective search . Propose a bunch of boxes in the image and see if any of them actually correspond to an object. Feature extraction. Extracts a 4096 dimensional feature vector from each region proposal by propagating a mean subtracted 227 X 227 RGB image through five conv layers and two fully connected layers. These test time detections are highly parallel and the costs can amortized costs are hence low. Training is done by supervised pre-training followed by domain-specific fine-tuning Finally, R-CNN runs a simpler linear regression on the region proposal to generate tighter bounding box coordinates to get our final results. Fast R-CNN Ross Girshick : Sep 2015 Source Implementation 9 X faster at training time. 213 X faster at test time. Streamline the previous process by jointly learning to classify object proposals and refine their spatial locations. Advantages: Higher detection quality than R-CNN and SPPnet. Training is single stage, using a multi-task loss. Training can update all network layers. No disk storage is required for feature caching. Architecture The RoI pooling layer : Run the CNN just once per image and then find a way to share that computation across the ~2000 proposals. Initializing from pre-trained networks. with some modifications. Fine tuning for detection. Hierarchical sampling. Multi-task loss. Classification loss + boounding box regression offsets. Mini-batch Sampling. Back-propagation through RoI pooling layers. SGD hyperparameters. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun : Jan 2016 Microsoft Research Source Implementation Eliminating the bottleneck, region proposals as inputs. Introduces Region Proposal Networks (RPNs) that share convolutional layers with object detection networks. While training we alternate between the region proposal task and object detection task while keeping the proposals fixed. Mask R-CNN Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick : Apr 2017 Facebook AI Research Source Implementation Extends Faster R-CNN by adding another branch that predicts the object mask along with the bounding boxes. Faster R-CNN does not provide pixel-to-pixel alignment between network inputs and outputs. To fix this a layer RoIAlign is proposed which replaces RoIPool layer used previously. The first stage is identical to Faster R-CNN. In the second stage, along with predicting the class and the box offset, Mask R-CNN also outputs a binary mask for each RoI. Multi-task loss is used : \\(L = L_{cls} + L_{bbox} + L_{mask}\\) . Masks are generated for every class without competition among classes. This decouples mask and class prediction. Different architectures are used as convolutional backbone , ResNet and ResNeXt A Review of Deep Learning Techniques Applied to Semantic Segmentation Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, Jose Garcia-Rodriguez : Apr 2017 Source Semantic Segmentation, Deep Learning, Scene Labeling, Object Segmentation This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. This also describes the terminology used as well as some background concepts, then some existing models are reviewed(2017). At last a set of promising future works are discussed. These techniques are not very mature as of yet, mainly because of a lack of unifying picture. CNN Architectures : AlexNet, VGG, GoogleNet, ResNet, etc.. 2D and 3D Datasets : PascalVOC , Microsoft COCO , and more,... Decoder Variants, Integrating Context Knowledge Instance Segmentation RGB-D Data and 3D Data Video Sequences DeepLab : Semantic Image Segmentation with Deep Convolution Nets, Atrous Convolution, and Fully Connected CRFs Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille : May 2017 Source Semantic Segmentation, Atrous Convolution, Conditional Random Fields Introduces upsampled filters(Altrous Convolution) as a tool in dense prediction tasks. Allows us to control the resolution at which feature responses are computed and also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. ???? // Read this again.. U-Net: Convolution Networks for Biomedical Image Segmentation Olaf Ronneberger, Philipp Fischer, Thomas Brox : May 2015 Source Focuses on end-to-end training for segmentation tasks, relying heavily on data augmentation. Fully Convolutional Networks for Semantic Segmentation Jonathan Long, Evan Shelhamer, Trevor Darrell : Mar 2015 Source One of the first works to use Fully Connected layers to create pixel heatmap as output. Introducing Upsampling or Convolution Transpose. From Image-level to Pixel-level Labeling with Convolutional Networks Pedro O. Pinheiro, Ronan Collobert : Apr 2015 Source Weakly supervised segmentation. Put more weights to pixels with known class labels. Uses part of model trained on ImageNet and trains for segmentation on PascalVOC. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Object Detection and Image Segmentation"},{"url":"posts/books/using-neural-nets-to-recognize-handwritten-digits/","text":"Notes for the book . Source code for the book. Chapter 1: Using neural nets to recognize handwritten digits Perceptrons $$\\begin{eqnarray} \\mbox{output} & = & \\left\\{ \\begin{array}{ll} 0 & \\mbox{if } \\sum_j w_j x_j \\leq \\mbox{ threshold} \\\\ 1 & \\mbox{if } \\sum_j w_j x_j > \\mbox{ threshold} \\end{array} \\right. \\tag{1}\\end{eqnarray}$$ Network of perceptrons First, simplify notation, \\(w \\cdot x \\equiv \\sum_j w_j x_j\\) Move, threshold into the network as bias , \\(b \\equiv -\\mbox{threshold}\\) $$\\begin{eqnarray} \\mbox{output} = \\left\\{ \\begin{array}{ll} 0 & \\mbox{if } w\\cdot x + b \\leq 0 \\\\ 1 & \\mbox{if } w\\cdot x + b > 0 \\end{array} \\right. \\tag{2}\\end{eqnarray}$$ Neural Nets as Logic Gates This network represent a NAND Gate NAND gates can do arbitrary computations, And so can the perceptrons, This is reassuring, as this shows that perceptron can be as powerful as any computing device. Bit is disappointing as it makes the perceptrons just another type of NAND . However, these perceptrons can learn . Sigmoid Neurons We want our network to do this, we would be able to learn if we repeat this process gradually improving our weights. However, perceptrons don't behave that way, changing the weights or bias may only completely flip the output, say 0 to 1. This makes it difficult to do gradual improvements to our network. Enter sigmoid , $$\\begin{eqnarray} \\sigma(z) \\equiv \\frac{1}{1+e&#94;{-z}}. \\tag{3}\\end{eqnarray}$$ and, \\(\\sigma(z) \\in [0,1]\\) Output of sigmoid neuron \\( = \\sigma(w \\cdot x+b)\\) Which is a smoothed out version of the step function represented by perceptrons . Using come calculus, $$\\begin{eqnarray} \\Delta \\mbox{output} \\approx \\sum_j \\frac{\\partial \\, \\mbox{output}}{\\partial w_j} \\Delta w_j + \\frac{\\partial \\, \\mbox{output}}{\\partial b} \\Delta b, \\tag{5}\\end{eqnarray}$$ \\(\\Delta \\mbox{output}\\) is a linear function with respect to \\(\\Delta w_j\\) and \\(\\Delta b\\) . This makes it easier to figure out how to change the weights to achieve some output. The architecture of neural networks Feedforward neural network A simple network to classify handwritten digits Learning with gradient descent The dataset . We use the following quadratic cost function , also called the mean squared error or just MSE , $$\\begin{eqnarray} C(w,b) \\equiv \\frac{1}{2n} \\sum_x \\| y(x) - a\\|&#94;2. \\tag{6}\\end{eqnarray}$$ To minimize this function, we use gradient descent , Gradient descent with two variables, We could use calculus to find the minima analytically, but it would become a nightmare as soon as the number of variables go up. So, let's start rolling a ball down the valley,.. $$\\begin{eqnarray} \\Delta C \\approx \\frac{\\partial C}{\\partial v_1} \\Delta v_1 + \\frac{\\partial C}{\\partial v_2} \\Delta v_2. \\tag{7}\\end{eqnarray}$$ We also define a gradient vector \\(\\nabla C\\) , $$\\begin{eqnarray} \\nabla C \\equiv \\left( \\frac{\\partial C}{\\partial v_1}, \\frac{\\partial C}{\\partial v_2} \\right)&#94;T. \\tag{8}\\end{eqnarray}$$ With this defined, we can rewrite, $$\\begin{eqnarray} \\Delta C \\approx \\nabla C \\cdot \\Delta v. \\tag{9}\\end{eqnarray}$$ This equation lets us choose \\(\\Delta v\\) so as to make \\(\\Delta C\\) negative. $$\\begin{eqnarray} \\Delta v = -\\eta \\nabla C, \\tag{10}\\end{eqnarray}$$ where \\(\\eta\\) is a small, positive parameter (known as the learning rate ). Then, we can combine \\((9)\\) and \\((10)\\) to give, \\(\\Delta C \\approx -\\eta \\nabla C \\cdot \\nabla C = -\\eta \\|\\nabla C\\|&#94;2\\) . So, we will use \\((10)\\) to compute \\(\\Delta v\\) , $$\\begin{eqnarray} v \\rightarrow v' = v -\\eta \\nabla C. \\tag{11}\\end{eqnarray}$$ doing this until - we hope - we reach a global minimum. This can also be written as, $$\\begin{eqnarray} w_k & \\rightarrow & w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k} \\tag{16}\\\\ b_l & \\rightarrow & b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l}. \\tag{17}\\end{eqnarray}$$ Calculating all the gradients can become slow, So we do that in batches, using stochastic gradient descent , We randomly choose a mini-batch of samples from the training inputs, \\(X_1, X_2, \\ldots,X_m\\) $$\\begin{eqnarray} \\frac{\\sum_{j=1}&#94;m \\nabla C_{X_{j}}}{m} \\approx \\frac{\\sum_x \\nabla C_x}{n} = \\nabla C, \\tag{18}\\end{eqnarray}$$ So now our update rule becomes, $$\\begin{eqnarray} w_k & \\rightarrow & w_k' = w_k-\\frac{\\eta}{m} \\sum_j \\frac{\\partial C_{X_j}}{\\partial w_k} \\tag{20}\\ b_l & \\rightarrow & b_l' = b_l-\\frac{\\eta}{m} \\sum_j \\frac{\\partial C_{X_j}}{\\partial b_l}, \\tag{21}\\end{eqnarray}$$ We do this update for all the training data, dividing it into batches. This completes a single epoch . Implementing our network to classify digits Clone the repo, git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git We will be using 10,000 images from the test set as our validation set . This will be used for hyper-parameter tuning . The Network class class Network ( object ): def __init__ ( self , sizes ): self . num_layers = len ( sizes ) # Number of layers self . sizes = sizes # Number of neurons in the respective layer self . biases = [ np . random . randn ( y , 1 ) for y in sizes [ 1 :]] self . weights = [ np . random . randn ( y , x ) for x , y in zip ( sizes [: - 1 ], sizes [ 1 :])] To create a Nueral Net with 2 neurons in the first layer, 3 neurons in the second layer, and 1 neuron in the final layer, net = Network ([ 2 , 3 , 1 ]) It then generates random initial bias and weights for the layers. We can calculate the activations of a given layer by, $$\\begin{eqnarray} a' = \\sigma(w a + b). \\tag{22}\\end{eqnarray}$$ Here we are vectorizing out operations to denote(and compute) them compactly. So, we can define the sigmoid activation in our code, def sigmoid ( z ): return 1.0 / ( 1.0 + np . exp ( - z )) and the feedforward function in the Network class, def feedforward ( self , a ): \"\"\"Return the output of the network, if `a` is the input\"\"\" for b , w in zip ( self . biases , self . weights ): a = sigmoid ( np . dot ( w , a ) + b ) return a Now, the main thing that we want our network to do is to learn, so we'll define an SGD method def SGD ( self , trainig_data , epochs , mini_batch_size , eta , test_data = None ): \"\"\"Train the neural network using mini-batch stochastic gradient descent. The \"training_data\" is a list of tuples \"(x,y)\" representing the training inputs and the desired outputs. If \"test_data\" is provided then the network will be evaluated against then test data after each epoch. This is good for tracking the progress, but slows things down\"\"\" if test_data : n_test = len ( test_data ) n = len ( trainig_data ) for j in xrange ( epochs ): random . shuffle ( trainig_data ) mini_batches = [ trainig_data [ k : k + mini_batch_size ] for k in xrange ( 0 , n , mini_batch_size )] for mini_batch in mini_batches : self . update_mini_batch ( mini_batch , eta ) if test_data : print ( \"Epoch {0}:{1}/{2}\" . format ( j , self . evaluate ( test_data ), n_test )) else : print ( \"Epocj {0} complete.\" . format ( j )) In the above code the training data is randomly divided into mini batches and for each batch the gradient step is applied using self.update_mini_batch(mini_batch, eta) . def update_mini_batch ( self , mini_batch , eta ): \"\"\"Update the network's weights and biases by applying gradient descent using backpropogation to a single mini batch. The \"mini_batch\" is a list of tuples \"(x,y)\", and \"eta\" is the learning_rate.\"\"\" nabla_b = [ np . zeros ( b . shape ) for b in self . biases ] nabla_w = [ np . zeros ( w . shape ) for w in self . weights ] for x , y in mini_batch : delta_nabla_b , delta_nabla_w = self . backprop ( x , y ) nabla_b = [ nb + dnb for nb , dnb in zip ( nabla_b , delta_nabla_b )] nabla_w = [ nw + dnw for nw , dnw in zip ( nabla_w , delta_nabla_w )] self . weights = [ w - ( eta / len ( mini_batch )) * nw for w , nw in zip ( self . weights , nabla_w )] self . biases = [ b - ( eta / len ( mini_batch )) * nb for b , nb in zip ( self . biases , nabla_b )] Here, most of the work is done by the line,(which is explained in the next article in the series) delta_nabla_b , delta_nabla_w = self . backprop ( x , y ) We can now load some data using the helper scripts in the repo, >>> import mnist_loader >>> training_data , validation_data , test_data = \\ ... mnist_loader . load_data_wrapper () And then create a network, >>> import network >>> net = network . Network ([ 784 , 30 , 10 ]) Finally, we can use SGD to learn from the MNIST data, >>> net . SGD ( trainig_data , epochs = 30 , mini_batch_size = 10 , eta = 3.0 , test_data = validation_data ) Here is the output you should expect, Epoch 0 : 9129 / 10000 Epoch 1 : 9295 / 10000 Epoch 2 : 9348 / 10000 ... Epoch 27 : 9528 / 10000 Epoch 28 : 9542 / 10000 Epoch 29 : 9534 / 10000 That is 95.42 percent accuracy in 28 epochs . Tuning the hyperparameters This can be challenging. The art of debugging is required here. The current state-of-the-art for this dataset is 99.79 percent. Towards Deep Learning How does the network does what it does? Possibly by, breaking down the problem into subproblems and finding those answers . But, this breaking down is done by the network automatically while learning, and we don't really have a say in it. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Using neural nets to recognize handwritten digits"},{"url":"posts/machine-intelligence/neural-network-architectures/","text":"Deep Learning Architectures Self-Normalizing Neural Networks Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter : Sep 2017 Source Deep learning is setting new benchmarks everyday with the help of RNNs and CNNs. However, looking at problems that are not related to vision or sequential tasks, gradient boosting, random forests, or support vector machines are winning most of the competitions(Eg. Kaggle, HIGGS Challenge ). With CNNs success, batch normalization and other stochastic regularization techniques has evolved into a standard. Both RNNs and CNNs can stabilize learning with weight sharing. However, this is not very useful with FNNs, and often leads to high variance. Self-Normalizing Neural Networks Definition 1 : A neural network is self-normalizing if it possesses a mapping \\(g : \\Omega \\mapsto\\Omega\\) for each activation \\(y\\) that maps mean and variance from one layer to the next and has a stable and attracting fixed point depending on \\((\\omega,\\tau)\\) in \\(\\Omega\\) . Furthermore, the mean and the variance remain in the domain \\(\\Omega\\) , that is \\(g(\\Omega)\\subseteq\\Omega\\) , where \\(\\Omega = \\{(\\mu,\\nu)|\\mu\\in[\\mu_{min}, \\mu{max}], \\nu\\in[\\nu_{min}, \\nu{max}]\\}\\) . When iteratively applying the mapping \\(g\\) , each point within \\(\\Omega\\) converges to this fixed point. So, SNNs keep normalization of activations when propagating them through layers of the network. Constructing SNNs : The activation function, SELU $$\\text{selu}(x) = \\lambda\\begin{cases}x, & \\text{if } x \\ge 0 \\\\ \\alpha e&#94;x - \\alpha, & \\text{if } x \\leq 0 \\end{cases}$$ This activation allows to construct a mapping \\(g\\) with properties that lead to SNNs. They cannot be derived with (scaled) ReLUs, sigmoid units, \\(tanh\\) units and leaky ReLUs. For weight initialization \\(\\omega=0\\) and \\(\\tau=1\\) for all units in higher layer is proposed. New Dropout techniques are introduced. Benchmarks compared for UCI repository datasets, outperforming FNNs with and without normalization techniques, such as batch, layer and weight normalization or specialized architectures such as ResNets. Also proved that SNNs do not face vanishing and exploding gradients problem and therefore work well for architectures with many layers. The best performaing SNNs are typically very deep in contrast to other FNNs. Understanding deep learning requires rethinking generalization Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals : Feb 2017 Source Neural networks have far more often trainable parameters than the number of samples they are trained on. Even then they exhibit small generalization errorr i.e. difference between \"training error\" and \"test error\". Effective Capacity Of Neural Networks Randomization tests. Standard architectures were trained on a copy of data where the true labels were replaced by random labels. Deep neural networks easily fit random labels i.e. the they achieve 2 test error. The test error was of course no better than random chance as there was no correlation between the training and test labels. Also replacing the true images with random pixels(Gaussian noise), we observe that CNNs continue to fit the data with zero training error. This has the following implications: The effective capacity of neural networks is sufficient for memorizing the entire dataset. Even optimization on random labels remains easy. In fact, training time increases only by a small constant factor compared with training on the true labels. Randomizing the labels is solely a data transformation, leaving all other properties of the learning problem unchanged. The role of regularization Explicit regularization may improve generalization performance, but is neither necessary not by itself sufficient for controlling generalization error. \\(l_2\\) regularization sometimes even helps optimization, illustrating its poorly understoof nature in deep learning. Finite sample expressivity Theorem 1. There exists a two-layer neural network with ReLU activations and \\(2n+d\\) weights that can represent any function on a sample of size \\(n\\) in \\(d\\) dimensions. Implicit Regularization : An Appeal To Linear Models Arguments showing that it is not necessarily easy to understand the source of generalization for linear models either. Do all global minima generalize equally well? Is there a way to determine when one global minimum will generalize whereas another will not? In case of a linear model, even the curvature of the loss function would be the same. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Neural Network Architectures"},{"url":"posts/machine-intelligence/style-transfer-part-2/","text":"Deep Learning Style Transfer Artistic style transfer for videos Manuel Ruder, Alexey Dosovitskiy, Thomas Brox : Apr 2016 Source The previously discussed techniques have been applied to videos on per frame basis. However, processing each frame of the video independently leads to flickering and false discontinuities, since the solution of the style transfer task is not stable. To regularize the transfer temporal constraints using optical flow are introduced. Notation \\(\\mathbf p&#94;{(i)}\\) is the \\(i&#94;{th}\\) frame of the original video. \\(\\mathbf a\\) is the style image. \\(\\mathbf x&#94;{(i)}\\) are the stylized frames to be generated. \\(\\mathbf {x'}&#94;{(i)}\\) is the initialization of the style optimization algorithmat frame \\(i\\) . Short-term consistency by initialization Most basic way to yield temporal consistency is to initialize the optimization for the frame \\(i+1\\) with the stylized frame \\(i\\) . Does not perform very well if there are moving objects in the scene, so we use optical flow. \\(\\mathbf {x'}&#94;{(i+1)}=\\omega_i&#94;{i+1}\\mathbf x&#94;{(i)}\\) . Here \\(\\omega_i&#94;{i+1}\\) denotes the function tha warps a given image using the optical flow field that was estimated between \\(\\mathbf p&#94;{(i)}\\) and \\(\\mathbf p&#94;{(i+1)}\\) . DeepFlow and EpicFlow , both based on Deep Matching are used for optical flow estimation. Temporal consistency loss Let \\(\\mathbf w = (u,v)\\) be the optical flow in forward direction and \\(\\mathbf {\\hat w}=(\\hat u, \\hat v)\\) the flow in backward direction. Then, \\(\\mathbf {\\tilde w}(x,y) = \\mathbf{w}((x,y) + \\mathbf{\\hat{w}}(x,y))\\) is the forward flow warped to the second image. In areas without disoclusion, this warped flow should be approximately the opposite of the backward flow. So, we can find the areas of disoclusions where \\(|\\mathbf{\\widetilde{w} + \\hat{w}}|&#94;2 > 0.01(|\\mathbf{\\widetilde{w}}|&#94;2+|\\mathbf{\\hat{w}}|&#94;2)+0.5\\) . and motion boundaries can be detected where \\(|\\Delta\\mathbf{\\hat{u}}|&#94;2+|\\Delta\\mathbf{\\hat{v}}|&#94;2>0.01|\\mathbf{\\hat{w}}|&#94;2+0.002\\) . So, temporal consistency loss function penalizes deviations from the warped image in regions where the optical flow is consistent and estimated with high confidence. $$\\mathcal{L}_{temporal}(\\mathbf{x,\\omega,c}) = \\frac1D\\sum_{k=1}&#94;Dc_k\\cdot(x_k-\\omega_k)&#94;2$$ Here, \\(\\mathbf{c}\\in [0,1]&#94;D\\) is per-pixel weighing of the loss and \\(D=W\\times{H}\\times{C}\\) is the dimensionality of the image. We define \\(\\mathbf{c}&#94;{(i-1,i)}\\) between frames \\(i-1\\) and \\(i\\) as \\(0\\) in disoccluded regions and the motion boundaries, and 1 everywhere else. So, overall loss takes the form, $$\\mathcal L_{shortterm}(\\mathbf{p}&#94;{(i)},\\mathbf{a},\\mathbf{x}&#94;{(i)}) = \\alpha\\mathcal{L}_{content}(\\mathbf{p}&#94;{(i)},\\mathbf{x}&#94;{(i)}) + \\beta\\mathcal{L}_{style}(\\mathbf{a},\\mathbf{x}&#94;{(i)}) + \\gamma\\mathcal{L}_{temporal}(\\mathbf{x}&#94;{(i)}, \\omega_{i-1}&#94;i(\\mathbf{x}&#94;{(i-1)}), \\mathbf{c}&#94;{(i-1,i)})$$ Long-term consistency The short-term model has the following limitation: when some areas are occluded in some frame and disoccluded later, these areas will likely change their appearance in the stylized video. So, we need to use a penalization for deviations from more distant frames too. \\(J\\) is the set of relative indices that each frame takes into account. So, the loss function is, $$\\mathcal L_{longterm}(\\mathbf{p}&#94;{(i)},\\mathbf{a},\\mathbf{x}&#94;{(i)}) = \\alpha\\mathcal{L}_{content}(\\mathbf{p}&#94;{(i)},\\mathbf{x}&#94;{(i)}) + \\beta\\mathcal{L}_{style}(\\mathbf{a},\\mathbf{x}&#94;{(i)}) + \\gamma\\sum_{j\\in J:i-j\\geq1}\\mathcal{L}_{temporal}(\\mathbf{x}&#94;{(i)}, \\omega_{i-j}&#94;i(\\mathbf{x}&#94;{(i-j)}), \\mathbf{c}_{long}&#94;{(i-j,i)})$$ where, \\(\\mathbf{c}_{long}&#94;{(i-j,i)}=\\text{max}(\\mathbf{c}&#94;{(i-j,i)} - \\sum_{k\\in J:i-k>i-j}\\mathbf{c}&#94;{(i-k,i)}, \\mathbf{0})\\) Multi-pass algorithm The image boundaries tend to have less contrast and less diversity than other areas. This is not a problem for mostly static videos, but with large camera motion, these effects can creep in towards the center, which leads to lower quality images over time. So, we use a multi-pass algorithm which processes the whole sequence in multiple passes and alternating directions. Each pass consists of a lower number of iterations without full convergence. The sequence is run in alternating directions with each flow and blended for some number of iterations till some convergence. The multi-pass algorithm can be combined with temporal consistency loss described above. Achieve good results if temporal loss is disabled in several initial passes and enabled in later passes after the images had stabilized. Long term motion estimate... Artifacts at image boundaries,... Implementation : https://github.com/manuelruder/artistic-videos Watch in action : https://youtu.be/vQk_Sfl7kSc Instance Normalization: The Missing Ingredient for Fast Stylization Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky : Sep 2016 Source Learn a generator network \\(g(x,z)\\) that can apply to a given input image \\(x\\) the style of another \\(x_0\\) . \\(g\\) is a convolutional neural network learned from examples \\(x_t\\) by solving $$\\text{min}_g\\frac1n\\sum_{t=1}n\\mathcal{L}(x_0, x_t, g(x_t, z_t)), \\text{where }z_t \\sim\\mathcal{N}(0,1)$$ Perceptual Losses for Real-Time Style Transfer and Super Resolution Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li : 2016 Source The system consists of two components : image transformation network \\(f_W\\) (deep resnet with encoder-decoder scheme parameterized by weights \\(W\\) ) and a loss network \\(\\phi\\) that is used to define several loss functions \\(l_i,...l_k\\) . The optimization problem becomes, $$W&#94;*=\\text{arg min}_W\\mathbf{E}_{x,\\{y_i\\}}[\\sum_{i=1}\\lambda_i l_i(f_W(x), y_i)]$$ Uses the loss network \\(\\phi\\) to define a feature reconstruction loss \\(l_{feat}&#94;{\\phi}\\) and style reconstruction loss \\(l_{style}&#94;{\\phi}\\) that measures differences in content and style between images. Simple loss functions : In addition to the perceptual losses discussed above(and described earlier), two simple loss functions that depend only on low level pixel information are used. Pixel Loss : Can only be used when ground truth is available. Total Variation Regularization : to encourage spatial smoothness. Implementation* : https://github.com/jcjohnson/fast-neural-style Stylizing Face Images via Multiple Exemplars Yibing Song, Linchao Bao, Shengfeng He, Qingxiong Yang, Ming-Hsuan Yang : Aug 2017 Source Existing methods using a single exemplar lead to inaccurate results when the exemplar does not contain sufficient stylized facial components for a given photo. Proposes a style transfer algorithm in which a Markov random field is used to incorporate patches from multiple exemplars. The proposed method enables the use of all stylization information from different exemplars. And, proposes an artifact removal methods based on an edge-preserving filter. It removes the artifacts introduced by inconsistent boundaries of local patches stylized from different exemplars. In addition to visual comparison conducted by existing methods, performs quantitative evaluations using both objective and subjective metrics to demonstrate effectiveness of the proposed method. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Style Transfer, Part 2"},{"url":"posts/machine-intelligence/style-transfer-part-1/","text":"Deep Learning Style Transfer A Neural Style Algorithm of Artistic Style Leon A. Gatys, Alexander S. Ecker, Matthias Bethge : Sep 2015 Source In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. Then we came across Deep Neural Networks. Higher layers in the network capture the high-level content in terms of objects and their arrangement in the input image. We represent these feature responses as content representation . $$\\mathcal L_{content}(\\vec p,\\vec x,l) = \\frac12\\sum_{i,j}{(F&#94;l_{ij} - P&#94;l_{ij})&#94;2}$$ For style we need to capture correlations(given by Gram matrix \\(G&#94;l \\in \\mathcal R&#94;{N_l \\times N_l}\\) where \\(G&#94;l_{ij} = \\sum_kF&#94;l_{ik}F&#94;l_{jk}\\) ) between different filter responses. This representation captures the texture information of the input, but not the global arrangement. This multi-scale representation is called style representation . $$E_l = \\frac1{4N&#94;2_lM&#94;2_l}\\sum_{ij}(G&#94;l_{ij}-A&#94;l_{ij})&#94;2$$ $$\\mathcal L_{style}(\\vec a,\\vec x) = \\sum_{l=0}&#94;Lw_lE_l$$ So, we can manipulate both content and style separately. The images are synthesised by finding an image that simultaneously matches the content representation of the photograph and the style representation of the respective piece of art. $$\\mathcal L_{total}(\\vec p,\\vec a,\\vec x) = \\alpha\\mathcal L_{content}(\\vec p,\\vec x) + \\beta\\mathcal L_{style}(\\vec a,\\vec x)$$ Gallleries Style Transfer Studies Implementations Neural Style, JC Johnson, Lua Improving the Neural Algorithm of Artistic Style Roman Novak, Yalroslav Nikulin : May 2016 Source Objectives addressed in this paper: Similar areas of the content image should be repainted in a similar way. Different areas should be painted differently. Useful Modifications, A better per-layer content/style weighting scheme. \\(w_l&#94;s = 2&#94;{D-d(l)},\\quad w_l&#94;c=2&#94;{d(l)}\\) This indicates that most important style properties come from bottom layers, while content is mostly represented by activations in the upper layers. Using more layers to capture more style properties. Used all 16 conv layers of VGG-19 for calculating Gram matrices. Using shifted activations when computing Gram matrices to eliminate sparsity and make individual entries more informative and also speed-up style transfer convergence. \\(G&#94;l=(F&#94;l+s)(F&#94;l+s)&#94;T\\) , (where \\(s=-1\\) for best results). Targeting correlations of features belonging to different layers to capture more feature interactions. \\(G&#94;{lk}=F&#94;l[up(F&#94;k)]&#94;T\\) , if \\(X_k \\leq X_l\\) This blows up the number of definitions of style( \\(G\\) ) to \\(2&#94;{16&#94;2}\\) for 16 layers of VGG-19. However, experiments also show that tieing in distant layers gives poor results. Correlation Chain Instead of considering all layer combinations, use only a \"chained\" representation, \\(\\{G&#94;{l,l-1}|l=2...16\\}.\\) So, only correlations with immediate neighbors are considered. Blurred Correlations While calculating correlations, the smaller feature layer is upsampled, but even after having the same dimensions, the feature maps may still correspond to features of different scales. To overcome this we use blurring. \\(G&#94;{lk}=F&#94;l[blur&#94;{l-k}\\circ up(F&#94;k)]&#94;T\\) This gives positive results, but it does complicate the objective function and results in slow and unreliable convergence. Some Modifications that did not work out in the end, Gradient Masking Amplifying Activations Adjacent Activations Correlations Content-aware Gram Matrices Gram Cubes Experiments Preserving Color in Neural Artistic Style Transfer Leon A. Gatys, Matthias Bethge, Aaron Hertzmann, Eli Shechtman : Jun 2016 Source The original style transfer method also copies the colors of the style image, which might be undesirable in many cases. Approach #1: Color histogram matching Transform style image \\((S)\\) to match the colors of content image \\((C)\\) . This produces a new style \\((S')\\) . The algorithm remains unchanged otherwise. We have several different options for the initial color transfer. Linear method, \\(\\mathbf x_{S'}\\leftarrow \\mathbf Ax_S+\\mathbf b\\) \\(\\mathbf b=\\mu_C- \\mathbf A\\mu_S\\) , where \\(\\mu_C\\) and \\(\\mu_S\\) are mean colors. \\(\\mathbf A\\Sigma_S \\mathbf A&#94;T=\\Sigma_C\\) , where \\(\\Sigma_C\\) and \\(\\Sigma_C\\) are pixel covariances. \\(\\mathbf A\\) can be computed using Cholesky decomposition, or by using Image Analogies. Color transfer before style transfer generally gives better results. Approach #2: Luminance-only transfer This approach is motivated by the observation that visual perception is far more sensitive to change in luminance than in color. \\(L_S\\) and \\(L_C\\) are luminance channels extracted from the style and content images. Use a YIQ color space, the color information represented by I and Q channels is combined with \\(L_T\\) to produce the final output image. \\(L_{S'}=\\frac {\\sigma_C}{\\sigma_S}(L_S - \\mu_S) + \\mu_C\\) Comparison Linear color transfer onto the style image, before style transfer. Limited by how well the color transfer from content to style works. Style transfer only in the luminance channel. Preserves the colors of content image perfectly. However, dependencies between the luminance and the color channels are lost in the output image. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"machine-intelligence","title":"Style Transfer, Part 1"},{"url":"posts/books/elements-of-statistical-learning-part-3/","text":"Chapter 14: Unsupervised Learning Introduction Learning without labels.. Association Rules Market Basket Analysis The Apriori Algorithm Unsupervised as Supervised Learning Data Pooling Generalized Association Rules Cluster Analysis Priority Matrices Dissimilarities Based on Attributes Object Dissimilarity Clustering Algorithms Combinatorial Algorithms K-means Gaussian Mixtures as Soft K-Means Clustering Vector Quantization K-medoids Hierarchical Clustering Self-Organizing Maps Principal Components, Curves and Surfaces Principal Components Principal Curves and Surfaces Spectral Clustering Kernel Principal Components Sparse Principal Components Non-Negative Matrix Factorization Independent Component Analysis and Exploratory Projection Pursuit Nonlinear Dimension Reduction and Multidimensional Scaling The Google PageRank Algorithm Chapter 15: Random Forests Definition of Random Forests Details of Random Forests Chapter 16: Ensemble Learning Boosting and Regularization Paths Learning Ensembles Chapter 17: Undirected Graphical Models Markov Graphs and Their Properties Undirected Graphical Models for Continous Variables Undirected Graphical Models for Discrete Variables Chapter 18: High Dimensional Problems: p >> N Diagonal Linear Discriminant Analysis and Nearest Shrunken Centroids Linear Classifiers and Quadratic Regularization Regularized Discriminant Analysis Logistic Regression with Quadratic Regularization The Support Vector Classifier Feature Selection Computational Shortcuts When p >> N Linear Classifiers with {L_1} Regularization Classification when Features are Unavailable High-Dimensional Regression: Supervised Principal Components Feature Assessment and the Multiple Testing Problem","tags":"books","title":"Elements Of Statistical Learning, Part 3"},{"url":"posts/books/elements-of-statistical-learning-part-2/","text":"Chapter 7: Model Assessment and Selection Introduction Bias, Variance and Model Complexity The Bias-Variance Decomposition Example : Bias-Variance Tradeoff Optimism of the Training Error Rate Estimates of In-Sample Prediction Error The Effective Number of Parameters Also known as effective degree of freedom \\(= trace(S)\\) , where \\(\\hat y=Sy\\) . The Bayesian Approach and BIC Minimum Description Length Vapnik-Chervonenkis Dimension ☠ Cross-Validation 👍 K-Fold Cross Validation The Wrong and Right Way to Do Cross-validation Does Cross-Validation Really Work? Bootstrap Methods Conditional or Expected Test Error? ☠ Chapter 8: Model Inference and Averaging Introduction: Provides a general exposition of maximum likelihood approach and the Bayesian method of inference. The Bootstrap and Maximum Likelihood A model-free, non-parametric method for prediction. Bayesian Methods Relationship Between the Bootstrap and Bayesian Inference ☠ The EM Algorithm The EM algorithm in General ☠ MCMC(Markov Chain Monte-Carlo) for sampling from the Posterior Bagging Stochastic Search : Bumping Chapter 9: Additive Models, Trees, and Related Methods Generalized Additive Models Provides an extension to linear models, making them more flexible while retaining much of their interpretability. Tree Based Methods Regression and Classification trees. Gini index and Cross Entropy loss Overfitting Lack of smoothness PRIM(Patient Rule Induction Method) : Bump Hunting MARS: Multivariate Adaptive Regression Splines Hierarchical Mixture of Experts Chapter 10: Boosting and Additive Trees Boosting Methods Combines the output of many \"weak\" classifiers to produce a powerful \"committee\" . AdaBoost Boosting Fits an Additive Model \"Off the Shelf\" Procedures for Data Mining Boosting Trees Numerical Optimization via Gradient Boosting Regularization Shrinkage Subsampling Chapter 11: Neural Networks Projection Pursuit Regression Neural Networks Fitting Neural Networks Issues in Training Neural Nets Initizlization Overfitting Scaling of the Inputs Number of hidden units and layers Multiple Minima Performance comparion Computational Considerations Chapter 12: Support Vector Machines and Flexible Discriminants The Support Vector Classifier maximizing margin. Computing the Support Vector Classifier ☠ Support Vector Machines and Kernals Computing the SVM for Classification The SVM as a Penalization Method Function Estimation and Reproducing Kernals ☠ SVMs and the Curse of Dimensionality A Path Algorithm for the SVM Classifier ☠ Support Vector Machines for Regression Regression and Kernals Generalizing Linear Discriminant Analysis Flexible Discriminant Analysis Penalized Discriminant Analysis Chapter 13: Prototype Methods and Nearest-Neighbors Prototype Methods K-means Clustering Learning Vector Quantization Gaussian Mixtures k-Nearest-Neighbors Classifiers Adaptive Nearest-Neighbors Methods if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Elements Of Statistical Learning, Part 2"},{"url":"posts/robotics/mobile-robots/","text":"Very minimal notes on some papers or articles that I recently read. Mainly for logging purposes. Robotics ROS tf : The Transform Library Tully Foote Open Source Robotics Foundation The need for tf : to provide a standard way to keep track of coordinate frames and transform data within the entire system to a component user without requiring knowledge of all the coordinate frames. Broadcaster and Listner modules. Closely related to scene graphs . There are several different sources of information regarding various coordinate frames in a system, coming from sensors connected to hardware. This data can come at different frequencies. tf must accept asynchronous inputs and be robust to delayed or lost information. Must be robust to a distributed computing environment with unreliable networking and non negligible latency. Ability to dynamically change the relationship between frames to account for dynamic/varying structure. Design Transforms and frames are represented as a graph with transforms as edges and frames as nodes. The graphs can be disconnected, and must be directed ,acyclic and quickly searchable. Limiting the graphs to trees enables this. Difference from scene graphs: they are made to be iterated across periodically, while tf is designed to be queried for values asynchronously. History is also required. This data collectively is called a Stamp . Broadcaster broadcasts messages every time an update is heard about a specific transform. Listner collects the values and interpolates using SLERP, without assuming the presence of a future frame. The interpolation is a critical ability, as it allows the system to be asynchronous and robust to lost packets. Transform Computation using chaining. \\(T_c&#94;a=T_a&#94;b\\timesT_b&#94;c\\) . Strengths : Efficiency, Flexibility Extensions : Support for velocity. Transforming data in time. Robot Grasping Robotic Grasping and Contact: A Review Source Survey of work done in last two decades. Functions of Human hand Explore : haptics Restrain : fixturing Manipulation : dexterous manipulation Closure properties of grasps Contact modelling the grap Force Analysis Contact model Kinematics of contact Contact compliance Measures of grasp performance Grasping and the kinematics of the hand Dynamics Mobile Robots Modular and Reconfigurable Mobile Robots Source Classification Modular robots with mobile configuration change(MCC) S-bots Uni-Rovers JL-I and JL-II Millibots AMOEBA Modular robots with whole body locomotion(WBL) Whole body locomotion in chain architecture CONRO/PolyBot GZ-I CKBot Whole body locomotion in a lattice architecture Macro robots in a lattice architecture Crystalline Odin I-Cubes Catoms Mini robots in a lattice archtecture Reconfigurable mechanisms in a lattice architecture Whole body locomotion in a hybrid architecture M-TRAN/iMobot Molecubes ATRON YaMOR SuperBot if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"robotics","title":"Mobile Robots"},{"url":"posts/books/algorithms-part-7/","text":"Chapter 10: Quntized Algorithms There is a catch ofcourse: this algorithm needs a quantum computer to execute. Qubits, superposition and measurment Such a superposition is the basic unit of encoded information in quantum computers. It is called a qubit . This linear superposition is however private to the electron. For us to get a glimpse of the electron's state, we must make a measurment , and when we do get a single bit of information, 0 or 1. How do we encode \\(n\\) bits of information? We could choose \\(k=2&#94;n\\) levels of the hydrogen atom. But a more promising option is to use \\(n\\) qubits. In this phenomenon lies the basic motivation for quantum computation. After all, if Nature is so extravagant at the quantum level, why should we base our computers on classical physics? Why not tap into this massive amount of effort being expended at the quantum level? But there is a fundamental problem: this exponentially large linear superposition is the private world of the electrons. Measuring the system only reveals \\(n\\) bits of information. As before, the probability that the outcome is a particular 500-bit string \\(x\\) is \\(|\\alpha_x|&#94;2\\) . And the new state after measurement is just \\(|x>\\) . The plan The input to a quantum algorithm consists of \\(n\\) classical bits, and the output also consists of \\(n\\) classical bits. It is while the quantum system is not being watched that the quantum effects take over and we have the benefit of Nature working exponentially hard on our behalf. If the input is an \\(n\\) -bit string \\(x\\) , then the quantum computer takes as input \\(n\\) qubits in state \\(|x>\\) . Then a series of quantum operations are performed, by the end of which the state of the \\(n\\) qubits has been transformed to some superposition \\(\\su_y\\alpha_y|y>\\) . Finally, a measurement is made, and the output is the n-bit string y with probability \\(|\\alpha_y|&#94;2\\) . Observe that this output is random . But this is not a problem, as we have seen before with randomized algorithms such as the one for primality testing. As long as \\(y\\) corresponds to the right answer with high enough probability, we can repeat the whole process a few times to make the chance of failure miniscule. Noe let us look more closely at the quantum part of the algorithm. Some of the key quantum operations(which we will soon discuss) can be thought os as looking for certain kinds of patterns in a superposition of states. Because of this, it is helpful to think of the algorithm as having two stages. In the first stage, the \\(n\\) classical bits of the input are \"unpacked\" into an exponentially large superposition, which is expressly set up as to have an underlying pattern or regularity that, if detected, would solve the task at hand. The second stage then consists of a suitable set of quantum operations, followed by a measurement, which reveals the hidden pattern. The algorithm to factor a large integer \\(N\\) can be viewed as a sequence of reductions: FACTORING is reduced to finding a nontrivial square root of 1 modulo \\(N\\) . Finding such a root is reduced to computing the order of a random integer modulo \\(N\\) . The order of an integer is precisely the period of a particular periodic superposition . Finally, periods of superposition can be found by the quantum FFT . The Quantum Fourier Transform The FFT, where \\(\\omega\\) is a complex \\(M\\) th root of unity(the extra factor of \\(\\sqrt{M}\\) has the effect of ensuring that is the \\(|\\alpha_i|&#94;2\\) add up to 1, then so do the \\(|\\beta_i|&#94;2\\) ). Although the proceeding equation suggests an \\(O(M&#94;2)\\) algorithm, the classical FFT is able to perform this calculation in just \\(O(M\\log{M})\\) steps, and it is this speedup that has the profound effect of making digital signal processing practically feasible. We will now see that quantum computers can implement the FFT exponentially faster, in \\(O(\\log&#94;2M)\\) time! But waut, how can any algorithm take time less than \\(M\\) , the length of the input? The point is that we can encode the input in a superposition of just \\(m = \\log{M}\\) qubits; after all, this superposition of \\(2m\\) amplitude values. Starting from this input superposition \\(\\alpha\\) , the quantum Fourier transform(QFT) manipulates it appropriately in \\(m = \\log M\\) stages. At each stage the superposition evolves so that it encodes the intermediate results at the same stage of the classical FFT (whose circuit, with \\(m = \\log M\\) stages, is reproduced from Chapter 2). This can be achieved with m quantum operations per stage. Ultimately, after m such stages and \\(m&#94;2 = log&#94;2 M\\) elementary operations, we obtain the superposition \\(\\beta\\) that corresponds to the desired output of the QFT. So far we have only considered the good news about the QFT: its amazing speed. Now it is time to read the fine print. The classical FFT algorithm actually outputs the M complex numbers \\(\\beta_0,... , \\beta_{M-1}\\) . In contrast, the QFT only prepares a superposition \\(\\beta = P_{M_{j=0 −1} \\beta_j}\\) . And, as we saw earlier, these amplitudes are part of the \"private world\" of this quantum system. Thus the only way to get our hands on this result is by measuring it! And measuring the state of the system only yields \\(m = \\log M\\) classical bits: specifically, the output is index \\(j\\) with probability \\(|\\beta_j|&#94;2\\) . So, instead of QFT, it would be more accurate to call this algorithm quantum Fourier sampling . Moreover, even though we have confined our attention to the case \\(M = 2m\\) in this section, the algorithm can be implemented for arbitrary values of M, and can be summarized as follows: Quantum Fourier sampling is basically a quick way of getting a very rough idea about the output of the classical FFT, just detecting one of the larger components of the answer vector. In fact, we don't even see the value of that component—we only see its index. How can we use such meager information? In which applications of the FFT is just the index of the large components enough? This is what we explore next. Periodicity Suppose that the input to the QFT, \\(\\alpha = (\\alpha_0, \\alpha_1,... , \\alpha_{M−1})\\) , is such that \\(\\alpha_i = \\alpha_j\\) whenever \\(i \\equiv j \\pmod k\\) , where \\(k\\) is a particular integer that divides \\(M\\) . That is, the array \\(\\alpha\\) consists of \\(M/k\\) repetitions of some sequence \\((\\alpha_0, \\alpha_1,..., \\alpha_{k−1})\\) of length k. Moreover, suppose that exactly one of the \\(k\\) numbers \\(\\alpha_0,... , \\alpha_{k−1}\\) is nonzero, say \\(\\alpha_j\\) . Then we say that \\(\\alpha\\) is periodic with period \\(k\\) and offset \\(j\\) . It turns out that if the input vector is periodic, we can use quantum Fourier sampling to compute its period! This is based on the following fact, proved in the next lines: Suppose the input to quantum Fourier sampling is periodic with period \\(k\\) , for some \\(k\\) that divides \\(M\\) . Then the output will be a multiple of \\(M/k\\) , and it is equally likely to be any of the \\(k\\) multiples of \\(M/k\\) . Now a little thought tells us that by repeating the sampling a few times (repeatedly preparing the periodic superposition and doing Fourier sampling), and then taking the greatest common divisor of all the indices returned, we will with very high probability get the number \\(M/k\\) — and from it the period \\(k\\) of the input! Quantum Circuits So quantum computers can carry out a Fourier transform exponentially faster than classical computers. But what do these computers actually look like? What is a quantum circuit made up of, and exactly how does it compute Fourier transforms so quickly? Elementary quantum gates An elementary quantum operation is analogous to an elementary gate like the AND or NOT gate in a classical circuit. It operates upon either a single qubit or two qubits. One of the most important examples is the Hadamard gate , denoted by \\(H\\) , which operates on a single qubit. Notice that in either case, measuring the resulting qubit yields \\(0\\) with probability \\(1/2\\) and \\(1\\) with probability \\(1/2\\) . But what happens if the input to the Hadamard gate is an arbitrary superposition \\(\\alpha_0 |0> + \\alpha_1 |1>\\) ? The answer, dictated by the linearity of quantum physics, is the superposition \\(\\alpha_0H( 0 ) + \\alpha_1H( 1 ) = \\alpha_0\\sqrt2 \\alpha_1 |0> + \\alpha_0\\sqrt{−2} \\alpha_1 |1>\\) . And so, if we apply the Hadamard gate to the output of a Hadamard gate, it restores the qubit to its original state! Another basic gate is the controlled-NOT , or CNOT . It operates upon two qubits, with the first acting as a control qubit and the second as the target qubit. The CNOT gate flips the second bit if and only if the first qubit is a 1. Thus CNOT( 00 ) = 00 and CNOT( 10 ) = 11 : Yet another basic gate, the controlled phase gate, is described below in the subsection describing the quantum circuit for the QFT. Now let us consider the following question: Suppose we have a quantum state on n qubits, \\(\\alpha = P_x\\in\\{0,1\\}_n \\alpha_x x\\) . How many of these \\(2n\\) amplitudes change if we apply the Hadamard gate to only the first qubit? The surprising answer is—all of them! The new superposition becomes \\(\\beta = P_x\\in\\{0,1\\}_n \\beta_x x\\) , where \\(\\beta_0y = \\alpha_0y\\sqrt{2} + \\alpha_1y and \\beta_1y = \\alpha_0y\\sqrt{−2}\\alpha_1y\\) . Looking at the results more closely, the quantum operation on the first qubit deals with each \\(n − 1\\) bit suffix \\(y\\) separately. Thus the pair of amplitudes \\(\\alpha_0y\\) and \\(\\alpha_1y\\) are transformed into \\((\\alpha_0y + \\alpha_1y)/\\sqrt2\\) and \\((\\alpha_0y −\\alpha_1y)/\\sqrt2\\) . This is exactly the feature that will give us an exponential speedup in the quantum Fourier transform. Two basic types of quantum circuits A quantum circuit takes some number n of qubits as input, and outputs the same number of qubits. In the diagram these n qubits are carried by the n wires going from left to right. The quantum circuit consists of the application of a sequence of elementary quantum gates (of the kind described above) to single qubits and pairs of qubits. At a high level, there are two basic functionalities of quantum circuits that we use in the design of quantum algorithms: Quantum Fourier Transform These quantum circuits take as input n qubits in some state \\(\\alpha\\) and output the state \\(\\alpha\\) resulting from applying the QFT to \\(\\alpha\\) . Classical Functions Consider a function f with n input bits and m output bits, and suppose we have a classical circuit that outputs f(x). Then there is a quantum circuit that, on input consisting of an n-bit string x padded with m 0's, outputs x and f(x): Understanding quantum circuits at this high level is sufficient to follow the rest of this chapter. The next subsection on quantum circuits for the QFT can therefore be safely skipped by anyone not wanting to delve into these details. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 7"},{"url":"posts/books/algorithms-part-6/","text":"Chapter 8: NP-Complete problems Search problems A set of problems that can not be solved in time better than an exhaustive search. Satisfiability SAT , is a problem of great practical importance, applications ranging from chip testing to computer design to image analysis and software engineering. It is also a canonical hard problem. Consider this Boolean formula in conjugative normal form , $$(x \\lor y \\lor z)(x \\lor \\bar y)(y \\lor \\bar z)(z \\lor \\bar x)(\\bar x \\lor \\bar y \\lor \\bar z)$$ It is a collection of clauses , each consisting of several literals , A satisfying truth assignment is an assignment of false or true to each variable, so that every clause is true . SAT : Given a Boolean formula in CNF, either find a satisfying truth value, or report that none exist. In the above example, no solution exists.But how we decide this in general. The number of possibilities is exponential. A search problem is specified by an algorithm \\(\\mathcal C\\) that takes two inputs, \\(I\\) and a proposed solution \\(S\\) , and runs in time polynomial in \\(|I|\\) . We say \\(S\\) is a solution to \\(I\\) if and only if \\(\\mathcal C(I,S) = true\\) . Horn formula . If all clauses contain at most one positive literal, then the Boolean formula is called a Horn formula, and a satisfying truth assignment can be found by the greedy algorithm in Section 5.3. Alternatively, if all clauses have only two literals, then graph theory comes into play, and SAT can be solved in linear time by finding the strongly connected components of a particular graph constructed from the instance. The traveling salesman problem In TSP we are given \\(n\\) vertices \\(1,...n\\) and all \\(n(n-1)/2\\) distance between them, as well as budget \\(b\\) . We are asked to find a tour , a cycle that passes through every vertex exactly once, of total cost b or less, or to report that no such tour exists. That is we seek a permutation of the vertices such that when they are toured in this order, the total distance covered is at most b: $$d_{\\tau(1),\\tau(2)} + d_{\\tau(2),\\tau(3)} ... d_{\\tau(n),\\tau(1)} \\leq b$$ We have defined TSP as a search problem , when in reality it is an optimization problem , in which the shortest path is sought. The reason is, the framework for search problems encompasses optimization problems like TSP in addition to true search problems like SAT. This does not change its difficulty at all, because the two versions reduce to one another. Euler and Rudrata When can a graph be drawn without lifting the pencil from the paper? If and only if the graph is connected and every vertex, with the possible exception of two vertices(the start and final vertices of the walk), has even degree. EULER PATH : Given a graph, find a path that contains each edge exactly once, It follows from Euler's observation, and a little more thinking, that this search problem can be solved in polynomial time. RUDRATA CYCLE : Given a graph, find a cycle that visits each vertex exactly once - or report that no such cycle exists. Euler's problem can be solved in polynomial time, however for Rudrata's problem no polynomial solution is known. Cuts and bisections A cut is a set of edges whose removal leaves a graph disconnected. MINIMUM CUT : Given a graph and a budget \\(b\\) , find a cut with at most \\(b\\) edges. This generally leaves just a singleton vertex on one side. BALANCED CUT : Given a graph with \\(n\\) vertices and a budget \\(b\\) , partition the vertices into two sets \\(S\\) and \\(T\\) such that \\(|S|, |T|>n/3\\) and such that there are at most b edges between \\(S\\) and \\(T\\) . Another hard problem. Very important application: clustering . Integer Linear Programming ILP : Given \\(A\\) and \\(b\\) , find a nonnegative integer vector \\(\\mathbf x\\) satisfying the inequalities \\(Ax <= b\\) , or report that none exists. Special case, ZERO-ONE EQUATIONS Find a vector \\(\\mathbb x\\) of \\(0\\) 's and \\(1\\) 's satisfying \\(\\mathbb{Ax = 1}\\) , where \\(\\mathbb A\\) is an \\(m \\times n\\) matrix with 0-1 entries and \\(\\mathbb 1\\) is the m-vector of all 1's. Three-dimensional matching BIPARTITE MATCHING : Given a bipartite graph with \\(n\\) nodes on each side, find a set of \\(n\\) disjoint edges, or decide that no such exists. 3D MATCHING : In this new setting there are 3 different sets and the compatibilities among them are specified by a triplet. We want to find n disjoint triplets. Independent set, vertex cover and clique INDEPENDENT SET : Given a graph and an integer \\(g\\) , aim is to find \\(g\\) vertices that are independent, that is no two of which have an edge between them. VERTEX COVER , Given a graph and a budget \\(b\\) , the idea is to find \\(b\\) vertices that cover(touch) every edge. CLIQUE , given a graph and a goal \\(g\\) , find a set of \\(g\\) vertices such that all possible edges between them are present. Longest Path LONGEST PATH(TAXICAB RIP-OFF) : Given a graph \\(G\\) with non-negative edge weights and two distinguished vertexes \\(s\\) and \\(t\\) , along with a goal \\(g\\) . We are asked to find a path from \\(s\\) to \\(t\\) with total weight at least \\(g\\) . To avoid trivial solutions we require that the path be simple, i.e. containing no repeated vertices. Knapsack and subset sum KNAPSACK : we are given integer weights \\(w_1,.... w_n\\) and integer values \\(v_1,... v_n\\) for \\(n\\) items. We are also given a capacity \\(W\\) and a goal \\(g\\) . We seek a set of items whose total weight is at most \\(W\\) and whose total value is at least \\(g\\) . If no such set exists, we should say no. SUBSET SUM , Find a subset of a given set of integers that add up yo exactly \\(W\\) . NP-complete problems Hard problems, easy problems The various problems on the right can be solved by different types of algorithms, these problems are easy for a variety of reasons. In contrast, the problems on the left are all difficult for the same reasons! They are all the same problem, just in different disguises! They are all equivalent . P and NP We have already defined the search problem formally. We denote the class of all search problems by NP . The class of all search problems that can be solved in polynomial time is denoted by P . P = polynomial NP = nondeterministic polynomial time Reductions, again A reduction from search problem A to search problem B is a polynomial time algorithm f that transforms any instance I of A into an instance f(I) of B ., together with another polynomial time algorithm h that maps any solution S of f(I) back into a solution h(S) of I . A search problem is NP-complete if all other search problems reduce to it. Factoring The task of finding all prime factors of a given integer. The difficulty in factoring is of a different nature than that of the other hard search problems. Nobody believes that factoring is NP-complete . One difference, the definition does not contain the clause, \"or report that none exist\". A number can always be factored into primes. Another difference, factoring succumbs to the power of quantum computation . while other NP-complete problems do not seem to. The Reductions $$\\underline{\\mathrm{RUDRATA}(s,t)\\mathrm{-PATH} \\to \\mathrm{RUDRATA\\,CYCLE}}$$ $$\\underline{\\mathrm{3SAT} \\to \\mathrm{INDEPENDENT\\,SET}}$$ 3SAT , example $$(\\bar x \\lor y \\lor \\bar z)(x \\lor \\bar y \\lor z)(x \\lor y \\lor z)(z \\lor \\bar x)(\\bar x \\lor \\bar y)$$ INDEPENDENT SET , a graph and a number g. The above graph has been constructed as follows Graph \\(G\\) has a triangle for each clause(or just an edge, if the clause has two literals), with vertices labeled by the clause's literals, and has additional edges between any two vertices that represent opposite literals. The goal \\(g\\) is set to the number of clauses. $$\\underline{\\mathrm{SAT} \\to \\mathrm{3SAT}}$$ Replace, $$(a_1 \\lor a_2 \\lor ... \\lor a_k)$$ with, $$(a_1 \\lor a_2 \\lor y_1)(\\bar y_1 \\lor a_3 \\lor y_3)(\\bar y_2 \\lor a_4 \\lor y_3)...(\\bar y_{k-3} \\lor a_{k-1} \\lor a_k ),$$ $$\\underline{\\mathrm{INDEPENDENT\\,SET} \\to \\mathrm{VERTEX\\,COVER}}$$ Some reductions rely on ingenuity to relate two very different problems. Others simply record the fact that one problem is a thin disguise of another. To reduce \\(\\mathrm{INDEPENDENT\\,SET}\\) to \\(\\mathrm{VERTEX\\,COVER}\\) we just need to notice that a set of nodes \\(S\\) is a vertex cover of graph \\(G = (V,E)\\) (that is \\(S\\) touches every edge in \\(E\\) ) if and only if the remaining nodes, \\(V-S\\) , are an independent set of \\(G\\) . Therefore, to solve an instance \\((G,g)\\) of \\(\\mathrm{INDEPENDENT\\,SET}\\) , simple look for a vertex cover of \\(G\\) with \\(|V|-g\\) nodes. If such a vertex cover exists, then take all nodes not in it. If no such vertex cover exists, then \\(G\\) cannot possibly have an independent set of size \\(g\\) . $$\\underline{\\mathrm{INDEPENDENT\\,SET} \\to \\mathrm{CLIQUE}}$$ Define the complement of a graph \\(G\\) to contain precisely those edges that are not in \\(G\\) . Then, a set of nodes is an Independent set in \\(G\\) , if and only if it is a clique in complement of \\(G\\) . Therefore, the solution to both is identical. $$\\underline{\\mathrm{3SAT} \\to \\mathrm{3D\\,MATCHING}}$$ = a boolean variable. $$\\underline{\\mathrm{3D\\,MATCHING} \\to \\mathrm{ZOE}}$$ $$\\underline{\\mathrm{ZOE} \\to \\mathrm{SUBSET\\,SUM}}$$ When we look at a \\(\\mathrm{ZOE}\\) (like the one shown above), we are looking for a set of columns of \\(A\\) that, added together, make up the all-1'a vector. But if we think of the columns as binary integers(read from top to bottom), we are looking for a subset of the integers that add up to the binary integers with all 1's , i.e. 511. And this is an instance of \\(\\mathrm{SUBSET\\,SUM}\\) . The reduction is complete! Except for one detail, carry. Because of carry, n-bit binary integers can add up to \\(2&#94;n -1\\) ,even when the sum of the corresponding vectors is not all 1's. But this is easy to fix! Think of the column vectors not as integers in base 2, but as integers in base \\(n+1\\) , one more than the number of columns. This way, since at most n integers are added, and all their digits are 0 and 1, there can be no carry, and our reduction works. $$\\underline{\\mathrm{ZOE} \\to \\mathrm{ILP}}$$ $$\\underline{\\mathrm{ZOE} \\to \\mathrm{RUDRATA\\,CYCLE}}$$ $$\\underline{\\mathrm{ZOE} \\to \\mathrm{ILP}}$$ $$\\underline{\\mathrm{RUDRATA\\,CYCLE} \\to \\mathrm{TSP}}$$ $$\\underline{\\mathrm{ANY\\,PROBLEM\\,IN\\,NP} \\to \\mathrm{SAT}}$$ Chapter 9: Coping with NP completeness Intelligent Exhaustive Search Backtracking Based on the observation that it is often possible to reject a solution by looking at just a small part of it. An example SAT problem. The associated algorithm, $$ Start\\,with\\,some\\,problem\\,P_0\\\\ Let\\, \\mathcal{S} = \\{P_0\\},\\,the\\,set\\,of\\,active\\,subproblems.\\\\ Repeat\\,while\\,\\mathcal{S}\\,is\\,nonempty:\\\\ \\quad \\underline{choose}\\,a\\,subproblem\\,P \\in\\,\\mathcal{S}\\,and\\,remove\\,it\\,from\\,\\mathcal{S}\\\\ \\quad \\underline{expand}\\,it\\,into\\,smaller\\,subproblems\\,P_1,P_2...P_k\\\\ \\quad For\\,each\\,P_i:\\\\ \\quad \\quad If\\,\\underline{test}(P_i)\\,succeeds:\\quad halt\\,and\\,announce\\,this\\,solution\\\\ \\quad \\quad If\\,\\underline{test}(P_i)\\,fails:\\quad discard\\, P_i\\\\ \\,\\\\ \\quad \\quad Otherwise:\\,add\\,P_i\\,to\\,\\mathcal{S}\\\\ Announce\\,that\\,there\\,is\\,no\\,solution. $$ Branch and Bound The same principle from search problems to optimization. $$ Start\\,with\\,some\\,problem\\,P_0\\\\ Let\\, \\mathcal{S} = \\{P_0\\},\\,the\\,set\\,of\\,active\\,subproblems.\\\\ bestSoFar = \\infty\\\\ Repeat\\,while\\,\\mathcal{S}\\,is\\,nonempty:\\\\ \\quad \\underline{choose}\\,a\\,subproblem\\,(partial\\,solution)\\,P \\in\\,\\mathcal{S}\\,and\\,remove\\,it\\,from\\,\\mathcal{S}\\\\ \\quad \\underline{expand}\\,it\\,into\\,smaller\\,subproblems\\,P_1,P_2...P_k\\\\ \\quad For\\,each\\,P_i:\\\\ \\quad \\quad If\\,P_i\\,is\\,a\\,complete\\,solution:\\quad update\\,bestSoFar\\\\ \\quad \\quad else\\,if\\,\\underline{lowerbound}(P_i)\\le bestSoFar:\\quad add\\,P_i\\,to\\,\\mathcal{S}\\\\ return \\quad bestSoFar $$ Let's see how this works for the travelling salesman problem in a graph \\(G = (V,E)\\) with edge lengths \\(d_e > 0\\) . A partial solution is a simple path \\(a \\to b\\) passing through some vertices \\(S \\subseteq V\\) , where \\(S\\) includes the endpoints \\(s\\) and \\(b\\) . We can denote such a partial solution by the tuple \\([a,S,b]\\) , infact, \\(a\\) will be fixed throughout the algorithm. The corresponding subproblem is to find the best completion of the tour, that is the cheapest complementary path \\(b \\to a\\) with intermediate nodes \\(V - S\\) . Notice that the initial problem is of the form \\([a, \\{a\\}, a]\\) for any \\(a \\in V\\) of our choosing. At each step of the branch-and-bound algorithm, we extend a particular partial solution \\([a,S,b]\\) by a single edge \\((b,x)\\) , where \\(x \\in V-S\\) . There can be up to \\(|V-S|\\) ways to do this, and each of these branches leads to a subproblem of the form \\([a,S\\cup\\{x\\}, x]\\) . How can we lower-bound the cost of completing a partial tour \\([a,S,b]\\) ? Many sophisticated methods have been developed for this, but let's look at a rather simple one. The remainder of the tour consists of a path through \\(V-S\\) , plus edges from \\(a\\) and \\(b\\) to \\(V-S\\) . therefore, its cost is at least the sum of the following: The lightest edge from \\(a\\) to \\(V-S\\) . The lightest edge from \\(b\\) to \\(V-S\\) . The minimum spanning tree of \\(V-S\\) . (Do you see why?) And this lower bound can be computed quickly by a minimum spanning tree algorithm. Approximation algorithms Approximation factor, $$\\alpha_{\\mathcal{A}} = max_I\\frac{\\mathcal{A}(I)}{OPT(O)}$$ Vertex Cover $$\\mathrm{VERTEX\\,COVER}\\\\ Input: \\text{ An undirected graph } G = (V,E)\\\\ Output: \\text{ A subset of the vertices } S \\subseteq V \\text{ that touches every edge.}\\\\ Goal: \\text{ Minimize } |S|$$ $$Find\\,a\\,maximal\\,matching\\, M \\subseteq E\\\\ Return\\; S = \\{all\\,endpoints\\,of\\,edges\\,in\\,M\\}$$ Clustering We have some data that we want to divide into groups. We need to define distances between these data points. These distances can be euclidean distances, or even distances as a result of similarity tests. Assume that we have such distances and they satisfy these metric properties. \\(d(x,y) \\geq 0\\) for all \\(x, y\\) . \\(d(x, y) = 0\\) , if and only if \\(x=y\\) . \\(d(x,y) = d(y,x)\\) . ( Trianfle inequality ) \\(d(x,y) \\leq d(x,z) + d(z,y)\\) \\(\\underline(k-\\mathrm{CLUSTER})\\) Input: Points \\(X = \\{x_1...x_n\\}\\) with underlying distance metric \\(d(\\cdot,\\cdot)\\) ; integer \\(k\\) . Output: A partition of the points into \\(k\\) clusters \\(C_1,...C_k\\) . Goal: Minimize the diameter of the clusters, $$max_j max_{x_a,x_b \\in C_j} d(x_a, x_b)$$ . Pick any point \\(\\mu_1 \\in X\\) as the first cluster center. for \\(i = 2\\) to \\(k\\) : \\(\\quad\\) Let \\(\\mu_i\\) be the point in \\(X\\) \\(that\\) \\(is\\) farthest from \\(\\mu_1...\\mu_{i-1}\\) \\(\\quad\\) (i.e., that maximizes \\(min_{j<i}d(\\cdot,\\mu_j)\\) Create \\(k\\) clusters: \\(C_i = {\\) all \\(x\\inX\\) whose closest center is \\(\\mu_i}\\) . TSP If the dustances in a TSP satisfy the triangle inequality metric, we can approximate the solution with a factor of 2 by solving the minimum spanning tree problem instead. Knapsack Discard any item with weight \\( > W\\) Let \\(v_{max} = max_iv_i\\) Rescale values \\(\\hat{v_i} = \\lfloor v_i \\cdot \\frac{n}{cv_max}\\rfloor\\) Run the dynamic programming algorithm with values \\({\\hat{v_i}}\\) Output the resulting choice of items. The approximability hierarchy Those for which, like the TSP, no finite approximation ratio is possible. Those for which an approximation ratio is possible, but there are limits to how small this can be. \\(\\mathrm{VERTEX\\,COVER},k-\\mathrm{CLUSTER}\\) , and the TSP with triangle inequality belong here. (For these problems we have not established limits to their approximability, but these limits do exist, and their proofs constitute some of the most sophisticated results in this field.) Down below we have a more fortunate class of NP -complete problems for which approximability has no limits, and polynomial approximation algorithms with error ratios arbitarily close to zero exist. \\(\\mathrm{KNAPSACK}\\) resides here. Finally, there is another class of problems, between the first two given here, for which the approximation ratio is about \\(\\log{n}\\) . \\(\\mathrm{SET\\,COVER}\\) is an example. Local Search Heuristics Let \\(s\\) be any initial solution while there is some solution \\(s'\\) in the neighbourhood of \\(s\\) \\(\\quad\\) for which \\(cost(s')<cost(s)\\) : replace \\(s\\) by \\(s'\\) return \\(s\\) Travelling Salesman, once more Notion of neighborhood of solutions in the search space of \\((n-1)!\\) different tours ? 2-change neighborhood of tour \\(s\\) : set of tours that can be obtained by removing two edges of \\(s\\) and then putting in two edges. \\(O(n&#94;2)\\) neighbors. In general, the search space might be riddled with local optima, and some of them may be of very poor quality. The hope is that with a judicious choice of neighborhood structures, most local optima will be reasonable. Whether this is the reality or merely misplaced faith, it is an empirical fact that local searcg algorithms are the tp performers on a broad range of optimization problems. Let's look at another such example. Graph partitioning Input: An undirected graph \\(G = (V,E)\\) with non-negative edge weights; a real number \\(\\alpha \\in (0,1/2)\\) . Output : A partition of the vertices into two groups \\(A\\) and \\(B\\) , each of size at least \\(\\alpha|V|\\) . Goal : Minimize the capacity of the cut \\((A,B)\\) . We need to decide upon a neighborhood structure for our problem, and there is one obvious way to do this. Let \\((A,B)\\) , with \\(|A|=|B|\\) , be a candidate solution, we will define its neighbors to be all solutions obtainable by swapping on ee pair of vertices across the cut, that is, all solutions of the form \\((A-\\{a\\}+\\{b\\}, B-\\{b\\}+\\{a\\})\\) where \\(a\\in A\\) and \\(b \\in B\\) . Here's an example of a local move. We now have a reasonable local search procedures, and we could just stop here. But there is still a lot of room for improvement in terms of the quality of the solutions produced. The search space includes some local optima that are quite far from the global solution. Here's one which has cost 2. What can be done about such suboptimal solutions? We could expand the neighborhood size to allow two swaps at a time, but this particular bad instance would still stubbornly resist. Instead, let's look at some other generic schemes for improving local search procedures. Dealing with local optima Randomization and restarts Simulated annealing , let \\(s\\) be any starting solution repeat \\(\\quad\\) randomly choose a solution \\(s'\\) in the neighborhood of \\(s\\) \\(\\quad\\) if \\(\\Delta=cost(s')-cost(s)\\) is negative: \\(\\quad\\quad\\) replace \\(s\\) by \\(s'\\) \\(\\quad\\) else: \\(\\quad\\) replace \\(s\\) by \\(s'\\) with probability \\(e&#94;{-\\Delta/T}\\) . If \\(T\\) is zero, this is identical to our previous local search. But if \\(T\\) is large, then moves that increase the cost are occasionally accepted. What value of \\(T\\) should be used? The trick is to start \\(T\\) large and then gradually reduce it to zero. Thus initially, the local search can wander around quite freely, with only a mild preference for low-cost solutions. As time foes on, this preference becomes stronger, and the system mostly sticks to the lower-cost region of the search space, with occasional excursions out of it to escape local optima. Eventually, when the temperature drops further, the system converges on a solution. Simulated annealing is inspired by the physics of crystallization. When a substance is to be crystallized, it starts in liquid state, with its particles in relatively unconstrained motion. Then it is slowly cooled, and as this happens, the particles gradually move into more regular configurations. This regularity becomes more and more pronounced until finally a crystal lattice is formed. The benefits of simulated annealing comes at a significant cost: because of the changing temperature and the initial freedom of movement, many more local moves are needed until convergence. Moreover, it is quite an art to choose a good timetable by which to decrease the temperature, called annealing schedule . But in many cases where the quality of solutions improves significantly. the tradeoff is worthwhile. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 6"},{"url":"posts/books/algorithms-part-5/","text":"Chapter 7: Linear Programming and reductions Linear programming describes a broad class of optimization tasks in which both the constraints and the optimization criterion are linear functions . It turns out an enormous number of problems can be expressed in this way. An introduction to linear programming Eample : Profit maximization We represent the situation be a linear program as follows, Objective function : $$max\\; x_1 + 6x_2$$ Constraints : $$x_1 \\leq 200 \\\\ x_2 \\leq 300 \\\\ x_1 + x_2 \\leq 400 \\\\ x_1, x_2 \\geq 0$$ Solving linear problems, Simplex Method : Move from vertex to vertex(generally starting at origin), optimizing the objective function. Stop when no neighbor gives better results. Here is the updated linear program, $$max\\; x_1 + 6x_2+13x_3 \\\\ x_1 \\leq 200 \\\\ x_2 \\leq 300 \\\\ x_1 + x_2 + x_3 \\leq 400 \\\\ x_2 + 3x_3 \\leq 600 \\\\ x_1, x_2, x_3 \\geq 0$$ Example : Production planning An example with large number of variables and constraints. Integer Linear Programming is hard Example : Optimum bandwidth allocation Variants of Linear Programmin A general linear programming problem has many degrees of freedom, It can be either a maximization or a minimization problem. Its constraints can be equations and/or inequalities. The variables are often restricted to be non-negative, but the can also be unrestricted in sign. All these variants can easily be reduced to one another vio simple transformations. 1. To turn a maximization problem into a minimization(or vice-versa), just multiply the coefficients of the objective function by -1. 2. To turn an inequality constraint like \\(\\sum_{i=1}&#94;na_ix_i \\leq b\\) into an equation, introduce a new variable \\(s\\) and use $$\\sum_{i=1}&#94;na_ix_i+s=b,\\quad\\quad s \\geq 0$$ This is called a slack variable for the inequality. As justification, observe that a vector \\((x_1...x_n)\\) satisfies the original inequality constraint if and only if there is some \\(s \\geq 0\\) for which it satisfies the new equality constraint. 3. To change an equality constraint into inequalities is easy : rewrite \\(ax=b\\) as the equivalent pair of constraints \\(ax \\leq b\\) and \\(ax \\geq b\\) . 4. Finally, to deal with a variable \\(x\\) that is unrestricted in sign, do the following, * Introduce two non-negative variables, \\(x&#94;+, x&#94;- \\geq 0\\) . * Replace \\(x\\) , wherever it occurs in the constraints or the objective function, by \\(x&#94;+-x&#94;-\\) . This way \\(x\\) can take on any real value by appropriately adjusting the new variables. More precisely, any feasible solution to the original LP involving \\(x\\) can be mapped to a feasible solution to the new LP involving \\(x&#94;+, x&#94;-\\) , and vice-versa. Flows in Networks Shipping Oil Maximizing flow 1. It doesn't violate edge capacities, \\(0 < f_e < c_e\\) for all \\(e \\in E\\) . 2. For all nodes \\(u\\) except \\(s\\) and \\(t\\) , the amount of flow entering \\(u\\) equals the amount leaving \\(u\\) : $$\\sum_{(w,u)\\in E}f_{wu} = \\sum_{(u,z)\\in E}f_{uz}$$ In other words, flow is conserved . A closer look at the algorithm, in each iteration, simplex looks for an \\(s-t\\) path whose edges \\((u,v)\\) can be of two types, 1. \\((u,v)\\) is in the original network, and is not yet at full capacity. 2. The reverse edge \\((u,v)\\) is in the original network, and there is some flow along it. Bipartite Matching Duality Turns out, every linear maximization problem has a dual minimization problem. Duality theorem : If a linear program has a bounded optimum, then so does its dual, and the two optimum values coincide. Zero Sum Games Various conflict situations in life can be represented by matrix games. For ex. rock-paper-scissors can be specified by the payoff matrix . Now, if they play repeatedly, they have to employ a mixed strategy , which can be specified by the vector \\(\\mathbf x = (x_1, x_2, x_3)\\) for first player and \\(\\mathbf y = (y_1, y_2, y_3)\\) for the two players. Therefore, for any given round, the expected payoff is $$\\sum_{i,j}G_{ij}\\cdot Prob[\\text{Row plays } i, \\text{Column plays } j] = \\sum_{i,j}G_{ij}x_i, y_j$$ Row wants to maximize this, while Column wants to minimize it. If both Row and Column force a \"completely random strategy\" , both of them will get an expected payoff of zero. This is in fact a consequence of linear programming duality. The simplex algorithm Let v be any vertex of the feasible region. while there is a neighbor v' of v with better objective value: set v = v' Any setting of the \\(x_i\\) 's can be represented by an \\(n\\) -tuple of real numbers and plotted in \\(n\\) -dimensional space. A linear equation involving the \\(x_i\\) 's defines a hyperplane in this same space \\(\\mathbb R&#94;n\\) and the corresponding linear equality defines a half-space , all points that are either precisely on the hyperplane or lie on one particular side of it. Finally, the feasible region of the linear program is specified by a set of inequalities and is therefore the intersection of the corresponding half-spaces, a convex polyhedron. Verices and neighbors in n-dimensional space Each vertex is the unique point at which some subset of hyperplanes meet. Alternatively, Pick a subset of the inequalities If there is a unique point that satisfies them with equality, and this point happens to be feasible, then it is a vertex . Two vertices are neighbors if they have \\(n-1\\) defining inequalities in common. The algorithm On each iteration, simplex has two tasks: 1. Check whether the current vertex is optimal(and is so, halt). 2. Determine where to move next. Loose ends The starting vertex , turns out finding a starting vertex can be reduced to an LP and solved by simplex . Degeneracy , geometrically, this means that the vertex is at the intersection of more than \\(n\\) faces of polyhedron(say \\(n+1\\) ). Algebraically, it means that if we choose any one of the \\(n+1\\) sets of \\(n\\) inequalities and solve the corresponding system of \\(n\\) linear equations in \\(n\\) unknowns, we'll get the same solution in all \\(n+1\\) cases. This is a serious problem: simplex may return a suboptimal degenerate vertex simply because all its neighbors are identical to it and thus offer no better objective. And if we modify simplex to detect degeneracy and continue to hop from vertex to vertex, despite the lack of any improvement in the cost, it may end up looping forever. This can be solved by perturbation , jolt one of the planes a little so that the vertex splits up in two. Unboundedness , in some cases the objective function can be made arbitrarily large. If this is the case, simple will discover it, in exploring the neighbor of a vertex, it will notice that taking out an inequality and adding another leads to an undetermined system of equations that has infinite number of solutions. And in fact the space of solutions contains a whole line along which the objective can become larger and larger, all the way to infinity . In this case the simplex halts and complains. The running time of simplex Consider a generic LP, max \\(c&#94;Tx\\) such that \\(Ax \\leq 0\\) and \\(x \\geq 0\\) , where there are \\(n\\) variables and \\(A\\) contains \\(m\\) inequality constraints. A naive implementation can give an unappetizing time of \\(O(mn&#94;4)\\) . How? Find out...!!! Fortunately, there is a much better way, where this can be reduced to \\(O(mn)\\) . By employing the strategy of transforming to local view of a vertex. Linear programming in polynomial time Simplex is exponential,but performs well in practice.It is considered a paradox, can be solved in practice, but not in theory. Ellipsoid Algorithm , Confine the solution into smaller and smaller ellipsoids. however, this could not compete well with simplex in practice. The paradox deepened: A problem with two algorithms, one that is efficient in theory, and one that is efficient in practice. Interior point method , dashes to the optimum corner, not be hopping from corner to corner, but by cutting a clever path in the interior of the polyhedron. And it does perform well in practice. The fierce competition between the two approaches resulted in the development of very fast code for linear programming. Postscript : circuit evaluation We are given a Boolean circuit , that is , a dag of gates of the following types, Input gates have indegree zero, with value true or false . AND gates and OR gates have indegree 2. NOT gates have indegree 1. For example, This an be reduced to an LP by the following substitutions, And, \\(0 \\geq x_g \\geq 1\\) , for all the gates. We don,t need to maximize anything, we just need to find out \\(x_g\\) corresponding to the output gate. This is the most general problem that can be solved in polynomial time. Hence, the fact that CIRCUIT VALUE reduces to LP means that all problems that can be solved in polynomial time! if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 5"},{"url":"posts/robotics/biologically-inspired-robots/","text":"Bio Robots OpenRatSLAM : an open source brain-based SLAM system Feb 2013 Source RatSLAM, OpenRatSLAM, SLAM, Navigation, Mapping, Brain-based, Appearance-based, ROS, Open-source, Hippocampus RatSLAM is a navigation system based on the neural processes underlying navigation in the rodent brain, capable of operating with low resolution monocular image data. This paper describes OpenRatSLAM, an open source version of RatSLAM with bindings to ROS SLAM(Simultaneous Localization and Mapping) , at the core based on SIFT or SURF features. This implementation is based on RatSLAM, leveraging tools like OpenCV and ROS. Modular, detailed, integrated with ROS and rviz , works online and offline. RatSLAM Pose Cells, Local View Cells and Experience Map OpenRatSLAM, code Pose Cell Network : represents pose in response to odometric and local view connections. This also makes decisions about the experience map node and link creation. Local View Cells : determines whether a scene is novel or familiar by image comparison techniques. Mostly based on template matching. Experience map : manages graph building, graph relaxation and path planning. Visual Odometry : For image only datasets, provides an odometric estimate based on changes in the visual scene. OpenRatSLAM parameters and tuning Iterative tuning by minimizing loss. Using OpenRatSLAM Examples of datasets this is used with, and some results. Future work Watch In Action Biologically Inspired App roaches to Robotics March 1997 Source Big gap between fantasy and reality in terms of Autonomous Robots. Inspirations from insects : agility, adaptability, simplicity Focuses on walking like an insect. From Biology to Robotics Studies done at various levels of integration and inspiration. Distributed Gait Control A Distributed Neural Network Controller A Stick Insect Controller Evolved Locomotion Controllers Use genetic algorithms to evolve the neural networks for controlling the locomotion. Rough Terrain Locomotion The First Takeoff of a Biologically Inspired At-Scale Robotic Insect April 2008 Source Actuators, aerial robotics, biologically inspired robotics, microrobotics Goal is to create an insect-sized, truly micro air vehicle. Harvard Microrobotic Fly Fig. (a) Conceptual drawing highlighting the four primary mechanical and aero-mechanical components. Fig. (b) First insect-scale flying robot able to takeoff. INSECT-FLIGHT Dipteran thoracic mechanics is discussed. Creation of a Robotic Insect Actuation Using peizoceramic materials. Transmission Airfoils Watch In Action Towards Dynamic Trot Gait Locomotion—Design, Control, and Experiments with Cheetah-cub, a Compliant Quadruped Robot Alexander Spröwitz , Alexandre Tuleu, Massimo Vespignani, Mostafa Ajallooeian, Emilie Badri, Auke Jan Ijspeert :July 2013 Source Cheetah Cub : novel compliant quadruped robot. Watch In Action Fastest of its kind with speeds upto \\(1.42ms&#94;{-1}\\) . The implementation of multi-segment , compliant legs presents a major biological solution. Webots model description Control Uses Central pattern generators(CPG) Results if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"robotics","title":"Biologically Inspired Robots"},{"url":"posts/machine-intelligence/neural-networks-for-computer-vision/","text":"Very minimal notes on some papers or articles that I recently read. Mainly for logging purposes. Deep Learning Image Recognition Very Deep Convolutional Networks For Large-Scale Image Recognition Karen Simonyan, Andrew Zisserman : Apr 2015 Source Implementation Introduces the VGG network that won ImageNet in 2014 . Deeper ConvNets. Takes input as (224 X 224) RGB and mean image subtracted as preprocessing. Two final FC hidden layers, followed by one FC layer with 1000 outputs. Number of total trainable parameters turn out to be 144 million for VGG-19. All the hidden layers use ReLU activations. Deeper networks with small filters result in more regularization and less parameters. Optimise multinomial logistic regression objective using mini-batch gradient descent with momentum. At the end introduces ensemble models by averaging softmax predictions from multiple models. Going Deeper with Convolutions Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich : Sep 2014 Google DeepMind Source Introduces \"Inception\" with improved utilization of computing resources. \"We need to go deeper\" : But deeper networks come with a cost of large number of parameters, which makes the model prone to overfitting, and dramatically increased use of computational resources. Fundamental idea : sparsely connected architectures, even inside the convolutions. However, the computing infrastructure is very inefficient when it comes to numerical calculations on sparse data structures. And non-uniform sparse structures require careful engineering! Architecture GoogLeNet 22 trainable Layers(100 total layers), low memory footprint. Auxillary classifiers are used to allow for efficient gradient propagation. These are used only at training time. Deep Residual Learning for Image Recognition Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun : Dec 2015 Microsoft Research Source Presents residual learning framework( ResNet ) to ease the training of networks that are substantially deeper(152 layers!) than those used previously. How to win ImageNet in 2015. Problem with deeper networks : Vanishing Gradients : Addressed by intermediate normalization. Problem with deeper networks : Degradation , not caused by overfitting.. Introduces residual learning framework by using shortcut connections that can perform identity mapping. Using Identity mapping as precondition allows the network to easily learn the identity, if it is a desired mapping. This helps in simplifying networks. Plain Network architecture, mainly based on VGG nets. Residual Network architecture, insert shortcuts to the plain network. The model shows no optimization difficulty even with > 1000 layers..!! Finally discusses improvements for detection and localization tasks. Rethinking the Inception Architecture for Computer Vision Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna : Dec 2015 Google DeepMind Source Improving upon Inception module and GoogLeNet. General guiding principles Avoid representational bottlenecks, especially early in the network. Higher dimensional representations are easier to process locally within a network. Spatial aggregation can be done over lower dimensional embeddings without much or any loss in representational power. Balance the width and depth of the network. Factorizing Convolutions with Large Filter Size Factorize into smaller convolutions. This results in reduced parameter count. Does this replacement result in any loss of expressiveness? Spatial Factorization into Asymmetric Convolutions Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi : Aug 2016 Google DeepMind Source Combining Residual networks with Inception architecture . Uniform Inception-v4 blocks are introduced for cleaner architecture. Deep Visualization Visualizing and Understanding Convolutional Networks Matthew D Zeiler, Rob Fergus L : Nov 2013 Source Understanding why CNNs perform well on Image Classification tasks. Visualizing with a Deconvnet Feature Visualization Feature Evolution during training Feature Invariance Occlusion Sensitivity Correspondence Analysis Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks Anh Nguyen, Jason Yosinski, Jeff Clune : May 2016 Source Researchers have been using activation maximization techniques until now. This assumes that each neuron detects only one type of feature. But, we know neurons can be multifaceted . Here multifaceted feature visualization (MFV) is introduced. Systematically visualize all facets of a neuron. Improve image quality of synthesized images with natural and globally consistent colors. Center biased regularization is used so that the synthesized images dont have many repeated object fragments. This is done by first producing a blurry image, then updating the center pixels more than the edge ones, producing a final image that is sharp and has a centrally-located object. This image would have far fewer duplicated fragments. Visualizing the multifaceted nature of hidden neurons Discusses various optimization techniques to produce better images in detail : center biased regularization, mean image initialization.","tags":"machine-intelligence","title":"Neural Networks for Computer Vision"},{"url":"posts/books/algorithms-part-3/","text":"Chapter 3: Decomposition of Graphs Why Graphs The range of problems that can be solved by representing your problem in Graphs. Graph representations, Adjacency Matrix $$ a_{ij} = \\begin{cases} 1 \\text{ if there is an edge from } v_i \\text{ to } v_j \\\\ 0 \\text{ otherwise} \\end{cases}$$ Or, Adjacency List , \\(|V|\\) linked lists, one per vertex. The list for u holds the names of vertices to which u , has an outgoing edge. Depth first search in undirected Graphs Exploring mazes So, we need to simulate a piece of chalk(to check whether the node has been visited), and a string(to retrace our steps back home). The analogs that we have are, a boolean flag as a chalk, and a stack as a string(in this case its the recursive system stack). Running time, \\(O(|V| + |E|)\\) Connectivity in undirected graphs Identify and assign different integers to the different connected components in a undirected Graph. Previsit and Postvisit orderings Property : For any node \\(u\\) and \\(v\\) , the two intervals \\([pre(u), post(u)]\\) and \\([pre(v), post(v)]\\) are either disjoint or one is contained within the other. Depth-First search in Directed Graphs Types of edges Directed Acyclic Graphs Property : A directed graph has a cycle if and only if its depth-first search reveals a back edge. Property : In a dag, every edge leads to a vertex with a lower \\(post\\) number. Property : Every dag has at least one source and at least one sink. Strongly Connected Components Defining connectivity for directed graphs Two nodes u and v of a directed graph are connected if there is ap path from u to v and a path from v to u . This relation partitions V into disjoint sets that we call strongly connected components .The graph above has five of them. Property : Every directed graph is a dag of its strongly connected components. An efficient algorithm Property 1 : If the \\(explore\\) subroutine is started in a node \\(u\\) , then it will terminate precisely when all nodes reachable from \\(u\\) have been visited. Therefore, if we call explore on a node that lies somewhere in a sink strongly connected component(a strongly connected component that is a sink in the meta-graph), then we will retrieve exactly that component. But, how to find a node that we know for sure lies in a sink strongly connected component. How do we continue once the first component has been discovered. Property 2: The node that receives the highest \\(post\\) number in a depth-first search must lie in a source strongly connected component. which directly follows from, Property 3: If \\(C\\) and \\(C'\\) are strongly connected components, and there is an edge from a node in \\(C\\) to a node in \\(C'\\) , then the highest \\(post\\) number in \\(C\\) is bigger than the highest \\(post\\) number in \\(C'\\) . So, now we can determine whether a particular node lies in a source component of the meta graph. The opposite of what we need. Now, consider the reverse graph. It will have exactly the same strongly connected components as G. So if we find a part of source in the reverse graph, this node will be a part of a sink component in the original graph. Once we find the first strongly connected component a d deleted it from the graph, the next node with the highest post number will be a part of another sink component in G. The resulting algorithm, 1. Run depth-first search on \\(G&#94;R\\) . 2. Run the undirected connected components algorithm on \\(G\\) and during the depth-first search, process the vertices in decreasing order of their post numbers from step 1. Chapter 4: Paths in Graphs Distances The distance between two nodes is the length of the shortest path between them. Breadth first search Dijkstra's algorithm An adaptation of breadth-first search For any edge \\(e = (u,v) \\text{ of } E\\) , replace it by \\(l_e\\) edges of length 1, by adding \\(l_e - 1\\) dummy nodes between \\(u\\) and \\(v\\) . Therefore, we can compute distances in graph by running BFS on the new graph. We can do this by setting an estimated time of arrival for each new node in the frontier. The nodes are then being processed on the basis of earliest time. The right data structure to do this is a priority queue (usually implemented by a heap ). Running time \\(O(|V| + |E|)\\log|V|\\) Which heap is best ? Priority Queue Implementations Array Simplest implementation of a priority queue is as an unordered array of key values for all potential elements. Binary Heap Here elements are stored in a complete binary tree. In addition, a special ordering constraint is enforced: the key of any node of the tree is less than or equal to that of its children , i.e. the root always contains the smallest element. d-ary heap Identical to a binary heap, except that the nodes have d children instead of just two. Shortest paths in the presence of negative edges Note : The presence of a negative cycle means we cannot answer the question of shortest paths in the given graph. Shortest paths in dags if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 3"},{"url":"posts/books/algorithms-part-4/","text":"Chapter 5: Greedy Algorithms !Thinking Ahead. Minimum spanning trees Property 1 Removing a cycle edge cannot disconnect a graph. The tree with minimum total weight is then known as minimum spanning tree . Formally, Input : An undirected graph \\(G = (V, E)\\) ; edge weights \\(w_e\\) . Output : A tree \\(T = (V, E')\\) , with \\(E' \\subseteq E\\) , that minimizes \\(weight(T) = \\sum_{e \\in E'}w_e\\) . A greedy approach Kruskal's algorithm Repeatedly add the next lightest edge that doesn't produce a cycle. The cut property Cut Property Suppose edges \\(X\\) are part of a minimum spanning tree of \\(G = (V, E)\\) . Pick any subset of nodes S for which \\(X\\) does not cross between \\(S\\) and \\(V-S\\) , and let \\(e\\) be the lightest edge across this partition. Then \\(X \\cup \\{e\\}\\) is part of some \\(MST\\) . Kruskal's algorithm We need to use a data structure for representing disjoint sets, supporting the following operations, makeset(x) : create a singelton set containing just x . find(x) : to which set does x belong. union(x,y) : merge the sets containing x and y . A data structure for disjoint sets Union by rank $$\\underline{procedure\\, makeset(x)}\\\\ \\pi(x) = x \\\\ rank(x) = 0 \\\\ \\, \\\\ \\underline{function\\, find(x)} \\\\ while\\quad x \\neq \\pi(x): x = \\pi(x) \\\\ return\\; x \\\\ \\, \\\\ \\underline{procedure\\, union(x,y)} \\\\ r_x = find(x) \\\\ r_y = find(y) \\\\ if\\quad r_x = r_y:\\, return \\\\ if\\quad rank(r_x) > rank(r_y) : \\\\ \\quad \\pi(r_y) = r_x \\\\ else: \\\\ \\quad \\pi(r_x) = r_y \\\\ \\quad if\\quad rank(r_x) = rank(r_y): rank(r_y) = rank(r_y) + 1 $$ The given structure has the following properties. Property 1 For any \\(x, rank(x) < rank(\\pi(x))\\) . Property 2 Any root node of rank \\(k\\) has at least \\(2&#94;k\\) nodes in its tree. Property 3 If there are \\(n\\) elements overall, there can be at most \\(n/2&#94;k\\) nodes of rank \\(k\\) . Path compression $$ \\\\ \\underline{function\\, find(x)} \\\\ if\\quad x \\neq \\pi(x): \\pi(x) = find(\\pi(x)) \\\\ return\\; \\pi(x) \\\\ $$ During each find , when a series of parent pointers are followed up to the root, we will change all these pointers so that they point directly to the root. This simple alteration results in doing slightly more work per find operation. However, the amortized cost of each operation turns out to be just barely more than \\(O(1)\\) . Prim's algorithm In most general terms, any algorithm working on the following general schema is guaranteed to work. $$X = \\{\\,\\}\\text{ edges picked so far} \\\\ repeat\\; until\\quad |X| = |V|-1 :\\\\ \\quad \\text{pick a set} S \\subset V \\text{ for which X has no edges between S and V - S} \\\\ \\quad let\\; e \\in E \\text{ be the minimum-weight edge between S and V - S} \\\\ X = X \\cup \\{e\\} $$ Alternative to Kruskal's algorithmfor finding Minimum Spanning Trees. This is very similar to Dijkstra, only that the priorities are decided differently. Huffman coding Variable length encoding of symbols, depending on frequency of the particular symbol. Should be prefix-free , i.e. no codeword can be a prefix of another codeword. Any prefix-free encoding can be represented by a full binary tree. The two symbols with the smallest frequencies must be the bottom of the optimal tree. $$\\underline{procedure\\; \\text{Huffman}(f)} \\\\ Input:\\quad \\text{An array $f[1...n]$ of frequencies} \\\\ Output:\\quad \\text{An encoding tree with n leaves} \\\\ \\, \\\\ \\text{let H be a priority queue of integers, ordered by } f \\\\ for\\; i = 1\\, to\\, n:\\; insert(H, i) \\\\ for\\; k=n+1\\, to\\, 2n-1: \\\\ \\quad i = deletemin(H), j = deletemin(H) \\\\ \\quad \\text{create a node numbered k with children i,j} \\\\ \\quad f[k] = f[i] + f[j] \\\\ \\quad insert(H,k) \\\\ $$ Horn formulas Horn formulas are a framework for performing logical reasoning, expressing logical facts and deriving conclusions. Knowledge about variables is represented by two kinds of clauses: 1. Implications, whose left-hand side is an AND of any number of positive literals and whose right-hand side is a single positive literal. These express statements of the form \"if the conditions on the left hold, then the one on the right must also be true.\". For instance, \\((z\\land w)\\implies u\\) might mean \"if the colonel was asleep at 8 pm and the murder took place at 8 pm then the colonel is innocent.\" A degenerate type of implication is the singleton \" \\(\\implies x\\) ,\" meaning simply that x is true : \"the murder definitely occurred in the kitchen\". 2. Pure negative clauses , consisting of an OR of any number of negative literals, as in \\((\\bar u\\lor \\bar v \\lor \\bar y)\\) Given a set of clauses, we need to assign true/false values to the variables that satisfies all the clauses. The is called a satisfying assignment . So we have this given formula for finding a satisfying assignment. $$ \\\\ Input:\\quad \\text{a Horn formula} \\\\ Output:\\quad \\text{a satisfying assignment, if one exists} \\\\ \\, \\\\ \\text{set all variables to false} \\\\ \\, \\\\ \\text{while there is an implication that is not satisfied:} \\\\ \\quad \\text{set the right-hand variable of the implication to true} \\\\ \\, \\\\ \\text{if all pure negative clauses are satisfied: return the assignment} \\\\ \\text{else: return \"formula is not satisfiable\"} \\\\ $$ Set Cover $$ \\text{SET COVER} \\\\ Input: \\text{A set of elements $B$; sets } S_1,...S_m \\subseteq B. \\\\ Output: \\text{A selection of the $S_i$ whose union is $B$} \\\\ Cost: \\text{Number of sets picked.} \\\\ $$ The greedy algorithm will not be optimal, but it will be pretty close to it. Claim , Supppose \\(B\\) contains \\(n\\) elements and that the optimal cover consists of \\(k\\) sets. Then the greedy algorithm will use at most \\(k\\ln n\\) sets. The ratio between the greedy algorithm's solution and the optimal solution varies from input to input but is always less than \\(\\ln n\\) . There are certain inputs for which the ratio is very close to \\(\\ln n\\) . We call this maximum ratio the approximation factor of the greedy algorithm. Chapter 6: Dynamic Programming The sledgehammers of the algorithms class: Dynamic Programming and Linear Programming Shortest paths in dags, revisited The following routine can be used to calculate the shortest path in DAG. $$ \\\\ \\text{initialize all $dist(.)$ values to $\\inf$} \\\\ dist(s) = 0 \\\\ \\text{for each}\\quad v \\in V\\setminus\\{s\\}, \\text{in linearized order}: \\\\ \\quad dist(v) = min{(u,v)\\in E}\\{dist(u) + l(u,v)\\} $$ Dynamic programming is a very powerful algorithmic paradigm in which a problem is solved by identifying a collection of subproblems and tackling them one by one, smallest first, using the answers to subproblems to figure out larger ones, until the whole lot of them is solved. In dynamic programming we are not given a dag, it is implicit . Its nodes are the subproblems we define, and its edges are the dependencies between the subproblems. Longest increasing subsequence The problem can be represented as a DAG, containing all possible transitions; establish a node \\(i\\) for each element \\(a_i\\) , and add directed edges \\((i,j)\\) whenever it is possible for \\(a_i\\) and \\(a_j\\) to be consecutive elements in an increasing subsequence, that is, whenever \\(i < j\\) and \\(a_i < a_j\\) . So, for finding the longest subsequence, our goal is simply to find the longest path in the dag. $$\\\\ for\\quad j = 1, 2,... n: \\\\ \\quad L(j) = 1 + max\\{L(i): (i, j) \\in E\\} \\\\ return\\; max_jL(j) \\\\ $$ , where \\(L(j)\\) is the length of the longest path(the longest increasing subsequence) ending in \\(j\\) . The actual subsequence of nodes can also be determined by some bookkeeping(ex. note down \\(prev(j)\\) ), the next-to-last node on the longest path to j.) Edit distance The minimum number of edits required to convert a string to another string. A dynamic programming solution \\(E(i,j)\\) represents the subproblems of finding match between string \\(x[1...i]\\) and \\(y[1...j]\\) . Our final objective is to compute \\(E(m,n)\\) . For that we need to express \\(E(i,j)\\) in terms of smaller subproblems. Now, \\(E(i,j) = min\\{1 + E(i-1, j), 1 + E(i, j-1), diff(i,j) + E(i-1, j-1)\\}\\) where, \\(diff(i,j)\\) is 0 if \\(x[i] = y[i]\\) , and \\(1\\) otherwise. The above relation forms a table, which can easily be computed in time \\(O(mn)\\) . Knapsack A burglar wants to find out which items to carry, considering the weight and cost where he can carry up to a fixed amount of weight, maximizing the cost of items. Knapsack with repetition \\(K(w) =\\) maximum value achievable with a knapsack of capacity \\(w\\) . \\(K(w) = max_{i:w_i \\leq w}\\{K(w - w_i)+v_i\\}\\) , Algorithm: $$\\\\ K(0) = 0 \\\\ for\\quad w = 1 to\\; W : \\\\ \\quad K(w) = max\\{K(w-w_i) + v_i : w_i < w\\} \\\\ return\\; K(W) \\\\ $$ Knapsack without repetition \\(K(w,j) =\\) maximum value achievable using knapsack of capacity \\(w\\) and items \\(1...j\\) . \\(K(w,j) = max\\{K(w-w_j,j-1) + v_j, K(w, j-1)\\}\\) $$\\\\ \\text{initialize all } K(0,j) = 0 \\text{ and all } K(w,0) = 0 \\\\ for\\quad j=1\\; to\\; n: \\\\ \\quad for\\quad w=1\\; to\\; W : \\\\ \\quad \\quad if\\; w_j > w: K(w,j) = K(w,j-1) \\\\ \\quad \\quad else: K(w,j) = max\\{K(w,j-1), K(w-w_j,j-1)+v_j\\} \\\\ return\\; K(W,n) \\\\ $$ Chain Matrix Multiplication Matrix multiplication is not commutative, but is associative. Which means, \\(A \\times (B \\times C) = (A \\times B) \\times C\\) . Thus, we can compute product of four different matrices in many different ways, Some of the ways are much better(computationally) than others. Shortest Paths Shortest reliable paths Suppose we want the shortest path from \\(s\\) to \\(t\\) that uses at most \\(k\\) edges. Is there a quick way to adapt Dijkstra's algorithm to this new task? Not quite; since the algorithm focuses on the length of each shortest path without remembering the number of hops in the path, which is now a crucial information. In dynamic programming, we can now define, for each vertex \\(v\\) and each integer \\(i < k, dist(v,i)\\) to be the length of the shortest path from \\(s\\) to \\(v\\) that uses \\(i\\) edges. \\(dist(v,i) = min_(u,v)\\in E{dist(u, i-1) + l(u,v)}\\) . All pairs shortest paths Floyd-Warshall algorithm : We want to find the shortest paths between all pairs of vertices. Is there a good subproblem for solving this problem. Yes. We can start with just two starting nodes, and gradually expand the set of possible intermediate nodes. More concretely, number the vertices in \\(V\\) as \\(\\{1...n\\}\\) and let, \\(dist(1,j,k)\\) denote the length of shortest path from \\(i\\) to \\(j\\) in which only nodes \\(\\{1,2...k\\}\\) can be used as intermediates. Initially, \\(dist(1,j,0)\\) is the length of the direct edges between \\(i\\) and \\(j\\) if one exists, and is \\(\\inf\\) otherwise. This, using \\(k\\) gives us a shorter path from \\(i\\) to \\(j\\) if and only if \\(dist(i,k,k-1) + dist(k,j,k-1) < dist(i,j,k-1)\\) , in which case \\(dist(i,j,k)\\) should be updated accordingly. Here is the Floyd-Warshall algorithm -- and it takes \\(O|V|&#94;3\\) time. $$\\\\ for \\quad i=1 to n:\\\\ \\quad for \\quad j=1 to n:\\\\ \\quad \\quad dist(i,j,0) = \\infty\\\\ for\\;all \\quad (i,j) \\in E:\\\\ \\quad dist(i,j,0) = l(i,j)\\\\ for\\quad k=1\\;to\\;n:\\\\ \\quad for\\quad i=1\\;to\\;n:\\\\ \\quad \\quad for\\quad j=1\\;to\\;n:\\\\ \\quad \\quad \\quad dist(i,j,k)=min\\{dist(i,k,k-1)+dist(k,j,k-1), dist(i,j,k-1)\\}\\;to\\;n:\\\\ $$ The travelling salesman problem What sgould be the appropriate subproblem? For a subset of cities \\(S \\subseteq {1,2,....n}\\) that includes \\(l\\) , and \\(j \\in S\\) , let \\(C(S,j)\\) be the length of the shortest path visiting each node in \\(S\\) exactly once, starting at \\(l\\) and ending at \\(j\\) . When \\(|S| > 1\\) , we define \\(C(S,1) = \\infty\\) since the path cannot both start and end at \\(1\\) . Now, let's express \\(C(S,j)\\) in terms of smaller subproblems. We need to start at \\(1\\) and end at \\(j\\) ; what should we pick as the second-to-last city? It has to be some \\(i \\in S\\) , so the overall path length is the distance from \\(1\\) to \\(i\\) , namely \\(C(S-\\{j\\}, i) + \\text{the length of the final edge,}d_{ij}\\) . We must pick the best such \\(i\\) : $$C(S,j) = min_{i\\in S:i\\neq j} C(S-\\{j\\}, i) + d_{ij}$$ The subproblems are ordered by \\(|S|\\) . here's the code. $$C(\\{1\\}, 1) = 0\\\\ for \\quad s=2\\; to \\; n: \\quad for\\; all\\; subsets\\; S \\subseteq {1,2,...n}\\text{ of size } s \\text{ and containing } 1:\\\\ \\quad \\quad C(s,j) = \\infty\\\\ \\quad \\quad for\\; all\\; j \\in S,\\; j \\neq 1:\\\\ \\quad \\quad \\quad C(S,j) = min\\{C(S-\\{j\\},i)+d_{ij}:i\\in S,\\, i \\neq j\\}\\\\ return \\quad min_jC(\\{1,...n\\},j)+d_{j1} $$ There are at most \\(2&#94;m.n\\) subproblems, and each one takes linear time to solve. The total running time is therefore $O(n&#94;22&#94;m). Independent Sets in trees We need to find the largest independent set from a tree. Here is our algorithm, Start by rooting the tree at any node \\(r\\) . Now, each node defines a subtree - the one hanging from it. This immediately suggests subproblems, \\( I(u) =\\) size of largest independent set of subtree hanging from \\(u\\) . Our final goal is \\(I(r)\\) . So, \\(I(u)\\) turns out to be, $$I(u) = max \\bigl\\{1 + \\sum_{\\text{grandchildren}\\,w\\,\\text{of}\\,u}I(w), \\sum_{\\text{children}\\,w\\,\\text{of}\\,u}I(w)\\bigr\\}$$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 4"},{"url":"posts/books/algorithms-part-1/","text":"Chapter 0: Prologue Books and algorithms Ideas that changed the world. Widespread use of decimal system. Enter Fibonacci 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...., Also, \\(F_n = F_{n-1} + F_{n-2}\\) And, \\(F_n ≈ 2&#94;{0.694n}\\) A naive implementation , with no caching of values.., fib1 Runtime --> \\(T(n) >= F_n\\) , exponential in n Can We Do Better,....? A Polynomial algorithm..., fib2 A loop based algorithm that remembers previous values in an array. Polynomial running time. More Careful Analysis What about addition of numbers Fibonacci values for large n. Adding two n-bit integers take time ~ n. So, \\(fib1 ≈ n.Fn\\) And, \\(fib2 ≈ n&#94;2\\) Big-O notation Right simplification of the analysis. Leave behind the lower order terms. General rules : Multiplicative constants can be omitted. \\(n&#94;a\\) dominates \\(n&#94;b, if a > b\\) Any exponential dominates any polynomial. \\(a&#94;n\\) dominates \\(n&#94;b\\) Likewise, any polynomial dominates any logarithm. \\(n\\) dominates \\(log(n)\\) Exercise 0.4 So now \\(F_n\\) can be computed by calculating \\(X&#94;n\\) where \\(X\\) is the square matrix. So, \\(Fn = O(log n)\\) But then, with careful analysis, Multiplication of large n-bit numbers \\(≈ O(n&#94;2)\\) Chapter 1: Algorithms with Numbers Two ancient problems: Factoring : Given a number N, express it as a product of its prime factors. Hard Primality : Given a number N, determine whether it is a prime. Easy Basic Arithmetic Addition The sum of any three single-digit numbers is at most two digits long. Given two binary numbers x and y, how does our algorithm take to add them? Depends on size of input, number of bits in x and y. Running time \\(= O(n), n =\\) number of bits in the numbers. Is there anything faster? No.. About word length and large numbers Multiplication and Division To multiply x and y , create an array of intermediate sums, each representing the product of x by a single digit if y . These values are appropriately left shifted and added up. Running time = Addition of n numbers of n-bits length = \\((n-1).O(n)\\) = \\(O(n&#94;2)\\) Another fascinating algorithm for multiplication: However, running time = \\(O(n&#94;2)\\) , n = number of bits. Modular Arithmetic $$x \\equiv y \\pmod N \\Leftrightarrow N divides (x - y)$$ Modular arithmetic is a system for dealing with restricted ranges of integers. Another interpretation is that modular arithmetic deals with all the integers, but divides into N equivalence classes, each of the form \\(\\{i+kN:k\\in \\mathbb Z\\}, i \\in [0, N-1]\\) . Modular addition and multiplication To add two numbers x and y modulo N , we start with regular addition. Since x and y are both in the range 0 to N - 1 , their sum is in the range 0 to 2(N-1) . If the sum exceeds N-1 , we merely need to subtract off N to bring it back to required range. So, running time \\(= O(n), n = log N\\) . To multiply two mod N numbers x and y, do regular multiplication, reduce the answer to modulo N. The product can be as large as \\((N-1)&#94;2\\) , at most 2n bits large. Need to compute the remainder using quadratic time division algorithm. Multiplication thus remains quadratic. Division , however is tricky, whenever legal, it can be managed in quadratic time. Modular exponentiation We want to compute \\(x&#94;y \\pmod N\\) . Let n be the size(bits) of x, y and N . As with multiplication, the algorithm will halt after at most n recursive calls, and during each call it multiplies n-bit numbers, for a total running time of \\(O(n&#94;3)\\) . Euclid's algorithm for G.C.D Eculid's rule : If x and y are positive integers with \\(x >= y\\) , then \\(gcd(x, y) = gcd(x \\pmod y, y)\\) . Also, if \\(a > b\\) , then \\(a \\pmod b < a/2\\) . This means after any two consecutive iterations, both arguments are at the very least reduced to half.If they are initially n-bit, base case will be reached in at most 2n recursive calls. And each call involves a quadratic-time division. Running time \\(= O(n&#94;3)\\) . An extension to Euclid's algorithm A small extension to Euclid's algorithm is the key to dividing in the modular world. Modular division x is the multiplicative inverse of a modulo N , if \\(ax == 1 \\pmod N\\) If \\(gcd(a,N) > 1 , \\Rightarrow ax \\neq 1 \\pmod N \\forall x\\) , and therefor a cannot have a multiplicative inverse modulo N . When \\(gcd(a, N) = 1\\) , we say a and N are relatively prime . The extended Euclid's algorithm gives us integers x and y such that \\(ax + Ny = 1\\) , which means \\(ax \\equiv 1 (mod N)\\) . Thus x is a's sought inverse . Modular Division Theorem , a has multiplicative inverse modulo N , if and only if they are relatively prime, and it can be found by running extended Euclid theorem in time \\(O(n&#94;3)\\) . Primality Testing Here the theorem does not say anything about what happens if number is not prime. In fact, for some composite numbers, Pr(Algorithm returns yes when N is not prime) <= 1/2 We can thus choose k different random integers to test for primality testing, reducing Pr to \\(1/2&#94;k\\) . Generating random primes Due to such abundance of prime numbers, prime number generation is easy. Generate a random n-bit number. Check for primality. If not prime, repeat the process. Cryptography Rivest-Shamir-Adelman(RSA) : Blabber about private key and public key systems. Private-key schemes: one time pad and AES RSA Public key cryptography Based heavily upon number theory. Universal Hashing Hash Tables Give a key to any value . Hash function : How to define the mapping between key and value . Families of Hash Functions A family of hash functions with this property is called universal . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 1"},{"url":"posts/books/algorithms-part-2/","text":"Chapter 2: Divide-and-Conquer Algorithms The divide and conquer strategy solves a problem by 1. Breaking it into sub-problems that are themselves smaller instances of the same type of problem. 2. Recursively solving these problems. 3. Appropriately combining their results. Multiplication For multiplying two n-bit integers x and y. \\(x = \\bbox[5px, border:2px solid black]{ x_L } \\quad \\bbox[5px, border:2px solid black]{ x_R } = 2&#94;{n/2}x_L + x_R\\) \\(y = \\bbox[5px, border:2px solid black]{ y_L } \\quad \\bbox[5px, border:2px solid black]{ y_R } = 2&#94;{n/2}y_L + y_R\\) then, \\(xy = (2&#94;{n/2}x_L + x_R)(2&#94;{n/2}y_L + y_R) = 2&#94;nx_Ly_L + 2&#94;{n/2}(x_Ly_R + x_Ry_L) + x_Ry_R\\) Now, we can compute xy by evaluating the RHS. Addition and multiplication by \\(2&#94;n\\) are linear time. Rest of the 4 multiplications can be done by recursively applying this algorithm. So, \\(T(n) = 4T(n/2) + O(n)\\) . Which results in \\(O(n&#94;2)\\) . By expanding the middle term, we can do with just three calculations, \\(x_Ly_L , x_Ry_R, (x_L+x_R)(y_L+y_R)\\) . since, \\(x_Ly_R + x_Ry_L = (x_L + x_R ) (y_L + y_R ) - x_Ly_L – x_Ry_R\\) . Resulting algorithm would then be \\(T(n) = 3T(n/2) + O(n)\\) , which is \\(O(n&#94;{1.59})\\) Height of the tree \\(= \\log_2 n\\) , since the length of the sub-problem gets halved at every level. Branching factor = 3. So, at any level k we will have \\(3&#94;k\\) to solve each of size \\(n/2&#94;k\\) . Therefore, time spent at level k is, \\(3&#94;k \\times O(\\frac n {2&#94;k}) = (\\frac 3 2)&#94;k \\times O(n)\\) Which is a geometric series. So, the sum then approximates to the last term of the series. That is \\(O(3&#94;{\\log_2 n})\\) , which can be written as \\(O(n&#94;{\\log_2 3})\\) , which is about \\(O(n&#94;{1.59})\\) . Can we do better ??? using Fast Fourier Transforms discussed later. Recurrence relations Consider this recurrence tree. Master's Theorem : If \\(T(n) = aT(\\lceil n/b \\rceil) + O(n&#94;d)\\) for some constants \\(a > 0, b > 1\\) , and \\(d \\ge 0\\) , then $$ T(n) = \\begin{cases} O(n&#94;d), \\text{ if } d > \\log_b a \\\\ O(n&#94;d\\log n), \\text{ if } d = \\log_b a \\\\ O(n&#94;{\\log_b a}), \\text{ if } d < \\log_b a \\end{cases}$$ Mergesort Sort an array by recursively sorting each half and merging the results. Since merge does constant amount of work per recursive call, overall time is $$ T(n) = 2T(n/2) + O(n), \\text{ or } O(n\\log n)$$ Here is an iterative version using a Queue. Medians Median = 50th percentile of a list of numbers. A randomized divide-and-conquer algorithm for selection For any number v , Split S into three categories: elements smaller than v \\((S_L)\\) , equal to v \\((S_v)\\) , greater than v \\((S_R)\\) , then $$ selection(S, k) = \\begin{cases} selection(S_L, k), \\quad\\quad\\quad\\quad\\quad\\quad \\text{if } k \\le |S_L| \\\\ v , \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad \\text{ if } |S_L| < k \\le |S_L| + |S_v| \\\\ selection(S_R, k - |S_L| - |S_v|), \\text{ if } k > |S_L| + |S_v| \\end{cases}$$ The three sub-lists can be computed in linear time, even in place. How to pick v ? Randomly from S . Matrix multiplication Symbolically, $$ Z_{ij} = \\sum_{k=1}&#94;n X_{ik}Y_{kj}$$ This implies the algorithm to be \\(O(n&#94;3)\\) Enter divide-and-conquer. Divide the matrices X and Y into 4 blocks. $$ X = \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix}, Y = \\begin{bmatrix}E & F \\\\ G & H\\end{bmatrix} $$ , Then, their product can be expressed as, $$ XY = \\begin{bmatrix}A & B \\\\ C & D\\end{bmatrix} = \\begin{bmatrix}AE+BG & AF+BH \\\\ CE+DG & CF+DH \\end{bmatrix} $$ Total running time can be described as, \\(T(n) = 8T(n/2) + O(n&#94;2), \\text{ which is again } O(n&#94;3)\\) . Turns out you can do this, $$ XY = \\begin{bmatrix}P_5+P_4-P_2+P_6 & P_1+P_2 \\\\ P_3+P_4 & P_1+P_5-P_3-P_7\\end{bmatrix} $$ where, \\(P_1 = A(F-H) \\quad\\quad P_5 = (A+D)(E+H)\\) \\(P_2 = (A+B)H \\quad\\quad P_6 = (B-D)(G+H)\\) \\(P_3 = (C+D)E \\quad\\quad P_7 = (A-C)(E+F)\\) \\(P_4 = D(G-E)\\) The new running time is, \\(T(n) = 7T(n/2) + O(n&#94;2), \\text{which is } O(n&#94;{\\log_2 7}) \\approx O(n&#94;{2.81})\\) Fast Fourier transform Next target, Polynomials . The general solution for polynomial multiplication works in \\(\\theta(d&#94;2)\\) time, where \\(d\\) is the degree of polynomials. An alternative representation of polynomials. Fact : A degree-d polynomial is uniquely characterized by its values at any \\(d+1\\) distinct points . So, we can specify a degree-d polynomial $$A(x) = a_0+a_1x+...+a_dx&#94;d$$ by any one of the following, 1. Its coefficients, \\(a_0, a_1,..., a_d\\) 2. The values \\(A(x_0), A(x_1), ..., A(x_d)\\) Now, taking in consideration the second form, the product has a degree \\(2d\\) , and is completely determined by its values at \\(2d+1\\) points. Since, those values are just products of the two polynomials at the given point. Thus, polynomial multiplication takes linear time in the value representation. Evaluation by divide-and-conquer The Trick : Choose the n points to be selected as positive-negative pairs, then the computations needed to be done overlap a lot. Specifically, if we could then recurse, we would have, $$T(n) = 2T(n/2) + O(n), \\text{which is } O(n\\log n)$$ But, recursing it at the second level and beyond seems impossible. Unless, of-course we use complex numbers. To get positive-negative pairs at subsequent levels, we can use the roots of \\(z&#94;n = 1\\) Which are, \\(1, \\omega, \\omega&#94;2, ... \\omega&#94;{n-1}, \\text{ where, } \\omega = e&#94;{2\\pi i/n}\\) So, if we choose these numbers, at every successive level of recursion we have pairs of positive-negative numbers Interpolation $$\\langle \\text{values} \\rangle = FFT(\\langle \\text{coefficients} \\rangle, \\omega)$$ , and $$\\langle \\text{coefficients} \\rangle = \\frac 1 n FFT(\\langle \\text{values} \\rangle, \\omega&#94;{-1}) $$ Details left,, See Fourier basis A closer look at the fast Fourier Transform The FFT takes as input a vector \\(a = (a_0, ... a_{n-1})\\) and a complex number \\(\\omega\\) whose powers are the complex root of unity. It multiplies this vector with the Matrix \\(M_n(\\omega)\\) , which has \\((j, k)_{th}\\) entry (starting row and column count at zero) \\(\\omega&#94;{jk}\\) . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Algorithms, Part 2"},{"url":"posts/books/elements-of-statistical-learning-part-1/","text":"Chapter 1: Introduction Motivation towards statistical learning and belief in data. What's next. Chapter 2: Overview of Supervised Learning Variable types and terminology Quantitative vs Qualitative output. Regression and Classification Simple approaches : Least Squares and Nearest Neighbors Linear Models and Least Squares \\(\\hat Y = \\hat \\beta_0 + \\sum_{j=1}&#94;pX_j\\hat\\beta_j\\) Least squares by solving normal equations. Nearest Neighbor Methods Voronoi tessellation From Least Squares to Nearest Neighbors Statistical Decision Theory Local Methods in High Dimensions The curse of Dimensionality, Bellman Statistical Models, Supervised Learning and Function Approximation A Statistical Model for the Joint Distribution Pr(X, Y ) Supervised Learning Function Approximation Structured Regression Models Difficulty of the Problem Classes of Restricted Estimators Roughness Penalty and Bayesian Methods regularization Kernel Methods and Local Regression Basis Functions and Dictionary Methods Model Selection and the Bias–Variance Tradeoff Chapter 3: Linear Methods Of Regression Introduction Linear Regression Models and Least Squares Solution from normal form F statistic Example : prostrate cancer The Gauss-Markov Theorem Proof that the Least Squares estimate for the parameters, \\(\\beta\\) has the least variance. Multiple Regression from Simple Univariate Regression Multiple Outputs Subset Selection Best-Subset Selection Forward and Backward-Stepwise Selection Forward-Stagewise Selection Example : Prostrate Cancer (Continued) Shrinkage Methods Ridge Regression : L2 regularization The Lasso : L1 regularization Discussion : Subset Selection, Ridge Regression and the Lasso Least Angle Regression Methods Using Derived Input Directions Principal Components Regression Partial Least Squares Discussion : A Comparison of Selection and Shrinkage Methods Multiple Outcomes Shrinkage and Selection ☠ More on Lasso and Related Path Algorithms ☠ Incremental Forward Stagewise Regression Piecewise-Linear Path Algorithms The Dantzig selector The Grouped Lasso Further Properties of Lasso Pathwise Coordinate Optimization Computational Considerations Fitting is usually done using Cholesky decomposition of matrix \\(X&#94;TX\\) . Chapter 4: Linear Methods of Classification Introduction Linear Regression of an Indicator Matrix Linear Discriminant Analysis Regularized Discriminant Analysis Computations for LDA Reduced-Rank Linear Discriminant Analysis Logistic Regression Fitting Logistic Regression Models Example : South African Heart Disease Quadratic Approximations and Inference \\(L_1\\) Regularized Logistic Regression Logistic Regression or LDA ? Separating Hyperplanes Rosenblatt's Perceptron Learning Algorithm Optimal Separating Hyperplanes ☠ Chapter 5: Basis Expansions and Regularization Introduction Piecewise Polynomials and Splines Natural Cubic Splines Example: South African Heart Disease (Continued) Example: Phoneme Recognition Filtering and Feature Extraction Smoothing Splines Degrees of Freedom and Smoother Matrices Automatic Selection of the Smoothing Parameters Fixing the Degrees of Freedom The Bias–Variance Tradeoff Nonparametric Logistic Regression Multidimensional Splines Regularization and Reproducing Kernel Hilbert Spaces ☠ Spaces of Functions Generated by Kernels Examples of RKHS Penalized Polynomial Regression Gaussian Radial Basis Functions Support Vector Classifiers Wavelet Smoothing ☠ Wavelet Smoothing and the Wavelet Transform Adaptive Wavelet Filtering Chapter 6: Kernel Smoothing Methods One-Dimensional Kernel Smoothers Local Linear Regression Local Polynomial Regression Selecting the Width of the Kernel Local Regression in \\({\\mathbb R}&#94;p\\) Structured Local Regression Models in \\({\\mathbb R}&#94;p\\) Structured Kernels Structured Regression Functions Kernel Density Estimation and Classification Kernel Density Estimation Kernel Density Classification The Naive Bayes Classifier Radial Basis Functions and Kernels Mixture Models for Density Estimation and Classification Computational Considerations if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Elements Of Statistical Learning, Part 1"},{"url":"posts/books/introduction-to-philosophy/","text":"These are just some bullet notes from the Coursera course Introduction to philosophy What Is Philosophy Working out the best way to thinking about things. The philosophical question. Philosophy: Difficult, Important and Everywhere Is it 'Fundamental'? No,.. Yes,..? Is it 'Important'? No,.. Yes,.? How Do We Do It? Arguments to your questions Do we have free will? Is there a right way to think about things? How do we know we can get to the right way just by thinking,.? What Is Knowledge? And Do We Have Any? Basic Constituents of Knowledge Propositional vs Ability knowledge Conditions for propositional knowledge Truth Belief Knowledge : Something more than just getting it right. Intuitions About Knowledge The Anti-Luck Intuition The Ability Intuition The Classical Account of Knowledge and the Gettier Problem Classical definition od knowledge Justified, True, Belief Gettier CounterExamples Knowledge cannot be merely justified true belief It might just be a matter of luck that your belief is true, irreverent of your justification. Examples The Stopped Clock!! A Sheep Behind a Sheep Shaped Object. Formula For Creating Gettier Cases - is easy!! Additional Conditions !! @@ NO FALSE LEMMAS : Farley complicated and boring Do We have any knowledge? Radical Skepticism, we don't know nearly as much as we think we do. We have as much knowledge as we take ourselves to have. Brain-in-a-vat Hypothesis : The Matrix How do we know that its not true.? Quite far fetched. Lots of arguments. And similar problems... Still not answerable to a simple solution. Minds, Brains and Computers What is it to have a mind? Theories of Mind Cartesian (or Substance) Dualism, by Descartes Mind is made of fundamentally different substance to the body. The mind is made of immaterial stuff and the body is made of material stuff. Princess Elizabeth of Bohemia & other problems of causation Physical things can only be affected/changed by interaction with other physical things Physicalism , all that exists is physical stuff. Identity Theory of physicalism having a mental state consists in being a particular physical state, mental and physical states are identical. Type identity and Token Identity Type identity offers a strong research prograam, it says that type of physical states are identical to type of mental states. A problem of type identity theory Hilary Putnam, claimed that type-identity would find the identical physical state with mental state of being in pain, for humans It might be something entirely different physical state for octopus for example, but the same mental state of being in pain. Mental states are multiply realizable. Functionalism Chairs can be made of many different things, shapes, sizes, look completely different But what makes them identifiable as chairs is the job that they do. Mind as a Computer With Functionalism, it has become very popular to think about the mind as analogous to a computer. It tries to argue that, like computers, minds are information processing units that take information of some kind and turn it into information of other kind. Turing Machines Identify the between machine and man. When the machine is able to fool the interrogator, then the computer has reached the level of functional complexity required to have a mind. Objections , A machine with a huge database with answers to all the questions. Would we call it a 'thinking' machine.? There can be beings that cannot persuade the questioner that they are human, but who we nevertheless want to count as minded. The Turing test relies on language, and a very narrow criteria for minds. John Searle's Chinese Room You get a symbol that you dont understand, you have a code book that tells what other symbol to respond with when you see a symbol. On the other hand, there is a person who is conversing with you in Chinese. But you don't even know that you are in a communicative act. Computers work by processing symbols. Symbols have syntactic and semantic properties. Computers are manipulating machines, more importantly, they are only aware of the syntactic properties of the symbol. We program the computer to operate on the syntactic structure of the symbol. The problem is that the computer does not 'know' the semantic content about the symbols that it is manipulating. If our mind is indeed a machine, where is the 'programmer' who deciphers meanings of symbols that our mind process? Representation is a three way relation. X represents Y to Z; the beer-mug represents my position on field to my friends. However, in case of the mind this neural activity represents a dog to ??? Morality: Objective, Relative or Emotive The status of morality Here we ask the question, what are we doing when we make moral judgments. The Questions Are they sorts of judgments that can be true or false - or are they mere opinions? If they are true /false, what makes them true /false? If they are true, are they objectively true? Objectivism Our moral judgments are the sorts of things that can be true or false, and what makes them true or false are facts that are generally independent of what are or what cultural groups we belong to - they are objective moral facts. Objection : How do you account for moral disputes between two people then? Relativism Our moral judgments are indeed true or false, but they're only true or false relative to something that can vary between people. Objections : How do you explain or keep track of moral progress then? Subjectivism , a form of relativism Out moral judgments are indeed true or false, but they're only true or false relative to the subjective feelings of the person who makes them. \"X is bad\" = \"I dislike X\" Cultural Relativism , a form of relativism Our moral judgments are indeed true or false, but they are only true or false relative to the culture of the person who makes them. \"X is bad\" = \"X is disapproved of in my culture\" Emotivism Moral judgments are neither objectively true/false or relatively true/false. They're direct expressions of our emotive reactions. Objections : How do you account for the moral decisions that we make and conclusions we arrive at based on our cognitive abilities. Should you believe what you hear Testimony and Miracles The Enlightenment : intellectual autonomy Hume : naturalistic philosophy Never believe that a miracle has occurred, on the basis of a testimony What is testimony? Any situation in which you believe something on the basis of what someone else asserts, either verbally or in writing. A lot of what we believe about the world is based on the testimony of other people. Hume assumes that you should only trust testimony when you have evidence that the testifier is likely to be right. Evidentialism : A wise man,... proportions his belief to the evidence. On Miracle, A miracle is a violation of the laws of nature. Thomas Ried argued, that trusting testimony is analogous to trusting your senses. we don't only trust our senses when we have evidence that they're likely to be right. Kant, Enlightenment is man's emergence from his self-incurred immaturity. Immaturity is the inability to use one's own understanding without the guidance of another. The motto of enlightenment is therefore : Have courage to use your own understanding. Intellectual autonomy : Think for yourself. Is your beliefs are based merely on testimony, they will not amount to knowledge. Are Scientific Theories true Time Travel and Philosophy Reading","tags":"books","title":"Introduction To Philosophy"},{"url":"posts/books/notes-on-opengl/","text":"Transformations Translation : (x, y, z) $$ \\begin{bmatrix} 1 & 0 & 0 & x \\\\ 0 & 1 & 0 & y \\\\ 0 & 0 & 1 & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Scale : (x, y, z) $$ \\begin{bmatrix} x & 0 & 0 & 0 \\\\ 0 & y & 0 & 0 \\\\ 0 & 0 & z & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Rotation x : $$ \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & cos(\\theta) & -sin(\\theta) & 0 \\\\ 0 & sin(theta) & cos(theta) & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Rotation y : $$ \\begin{bmatrix} cos(\\theta) & 0 & sin(\\theta) & 0 \\\\ 0 & 1 & 0 & 0 \\\\ -sin(\\theta) & 0 & cos(theta) & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Rotation z : $$ \\begin{bmatrix} cos(\\theta) & -sin(\\theta) & 0 & 0 \\\\ sin(theta) & cos(theta) & 0 & 0 \\\\ 0 & 0 & 1 & z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix} $$ Vertex Specifications Specify vertex data. Create buffer Data: const float vertexPositions[] = {...} Initialize vertex Buffer: glGenBuffers(1, &posiionBufferObject) glbindbuffer(GL_ARRAY_BUFFER, positionbufferObject) glbufferData(GL_ARRAY_BUFFER, sizeof(vertexpositions), vertexpositions, BufferobjectUsageHint) BufferobjectUsagehint: GL__STATIC_DRAW : Static data, only intend to set it once GL_STREAM_DRAW : Dynamic data, intend to update it constantly, generally once per frame glbindbuffer(0) Specify vertex data: glbindbuffer(GL_ARRAY_BUFFER, positionbufferobject) glenablevertexattribarray(0) glvertexattribarray(0, 4, GL_FLOAT, GL_FALSE, 0, 0) Display: gldrawarrays(GL_TRIANGLES, 0, 3) glbufferSubData() : Change buffer data value Vertex Array Objects: OpenGL Objects that store all of the state needed to make one or more draw calls. This includes attribute array setup information from glVertexAttribArray , buffer objects used for attribute arrays, and GL_ELEMENT_ARRAY_BUFFER binding, which is a buffer object that stores the index arrays, if needed Pipeline Vertex Specification Vertex Proocessing and Vertex Shader Culling Rasterization Fragment Processing if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"left\", indent = \"0em\", linebreak = \"true\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"books","title":"Notes On Opengl"},{"url":"posts/robotics/kuka-kinematics/","text":"https://github.com/NitishPuri/RoboND-Kinematics-Project/blob/master/writeup.md","tags":"robotics","title":"Kuka Kinematics"},{"url":"posts/gallery/sketch_2/","text":"Some recent sketches, Part 2","tags":"gallery","title":"sketch_2"},{"url":"posts/meta/blogging-like-a-hacker/","text":"Edit: After the blog post I have moved to Pelican , mostly because of my affinity for python. ❤️ So, finally I was able to settle up for a blog after months of procrastination with multiple frameworks and platforms. I had earlier tried to use Tumblr . But, I wanted to be able to explore different areas, like sharing my views on technology that I am currently interested in, music that I am currently digging in, some random art that I create and so on. Tumblr turned out to be a great platform for sharing my art, but for the same reasons did not look like a place where I could write about deep neural networks, natural language and computer vision. Though there are some blogs there that do just that . Then I tried Wordpress, but was never able to settle down on something satisfying and never actually pushed anything. It just had too much to fiddle with, so many options, so many plugins. :confused: This was very difficult for someone like me who opens 20 new browser tabs reading a single post and then bookmarks them all for reading later.:innocent: Then I spend two weeks doing Django tutorials . It was an interesting experience as this was my first time dealing with Python and web frameworks as well. but, in the end, I realized that these are just as many knobs, even if I keep the features minimal, it was too much work for me as I did not wanted to spend so much time building web technology(i would rather complete Skyrim). :grin: Then, after abandoning my quest for several months, I came across this awesome article about writing programming blogs, and how it is important for being a part of the technical community today. And, naturally, I had another 25 tabs open looking for advice on starting a tech blog and most feasible platforms to do so today. There I found this post. It talks about using jekyll with github pages as a blogging platform. Though I already \"knew\" about it, but I only thought of as a cleaner way of viewing your README files written in markdown. As I read through that article, it was clear to me that I would be able to settle in with this. It was simple to setup, free and simple to host, works with markdown which everybody uses, no necessary knobs to fiddle with databases and hosting providers. It was a great resource as it also listed out other links that I could follow to customize as much as I wanted. So, I opened up another browser window and started searching for some good themes, which brought me back to the themes originally suggested here . So, this website was created using the theme lanyon , which derives from poole . Jekyll, Poole and Lanyon are all characters from The Strange Case of Dr. Jekyll and Mr. Hyde . I started with forking the theme to my repo, following this article. However, before actually posting anything I had to setup up a local environment for jekyll also discussed in the article. Customizations Added support for Disqus comments. Added Google Analytics support. Changed some icons. Added sections for Timeline and resume Added sections for Art gallery.","tags":"meta","title":"Blogging like a hacker"},{"url":"posts/gallery/fractals_1/","text":"Some fun with fractals","tags":"gallery","title":"fractals_1"},{"url":"posts/gallery/sketch_1/","text":"Some recent sketches, Part 1","tags":"gallery","title":"sketch_1"},{"url":"posts/gallery/misc/","text":"Some misc. cutouts and experiments.","tags":"gallery","title":"misc"},{"url":"posts/gallery/monochrome/","text":"Some black and white stuff, with colors","tags":"gallery","title":"monochrome"},{"url":"posts/gallery/in_making_3/","text":"Some early creations, Part 3","tags":"gallery","title":"in_making_3"},{"url":"posts/gallery/in_making_2/","text":"Some early creations, Part 2","tags":"gallery","title":"in_making_2"},{"url":"posts/gallery/in_making_1/","text":"Some early creations, Part 1","tags":"gallery","title":"in_making_1"}]}