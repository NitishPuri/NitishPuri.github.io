<!DOCTYPE html>
<html lang="english" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Research Notes - Machine Learning - nitishpuri.github.io</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="/posts/summary/research-notes-machine-learning/">

        <meta name="author" content="Nitish" />
        <meta name="keywords" content="notes,deep-learning" />
        <meta name="description" content="Minimal notes on some papers or articles that I recently read. Mainly for logging." />

        <meta property="og:site_name" content="nitishpuri.github.io" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Research Notes - Machine Learning"/>
        <meta property="og:url" content="/posts/summary/research-notes-machine-learning/"/>
        <meta property="og:description" content="Minimal notes on some papers or articles that I recently read. Mainly for logging."/>
        <meta property="article:published_time" content="2017-09-05" />
            <meta property="article:section" content="Summary" />
            <meta property="article:tag" content="notes" />
            <meta property="article:tag" content="deep-learning" />
            <meta property="article:author" content="Nitish" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="/theme/css/bootstrap.cosmo.min.css" type="text/css"/>
    <link href="/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="/theme/css/pygments/native.css" rel="stylesheet">
    <link href="/theme/tipuesearch/tipuesearch.css" rel="stylesheet">
    <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>





</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="/" class="navbar-brand">
nitishpuri.github.io            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                    <li><a href="/pages/bio/">Bio</a></li>
                    <li><a href="/pages/gallery/">Gallery</a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              <li><span>
                <form class="navbar-search" action="/search.html">
                  <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input" required>
                </form></span>
              </li>
              <li><a href="/archives/"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="/posts/summary/research-notes-machine-learning/"
                       rel="bookmark"
                       title="Permalink to Research Notes - Machine Learning">
                        Research Notes - Machine Learning
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2017-09-05T00:00:00+05:30"> Tue 05 September 2017</time>
    </span>


            <span class="label label-default">By</span>
            <a href="/author/nitish.html"><i class="fa fa-user"></i> Nitish</a>

        <span class="label label-default">Category</span>
        <a href="/category/summary/">Summary</a>


<span class="label label-default">Tags</span>
	<a href="/tag/notes/">notes</a>
        /
	<a href="/tag/deep-learning/">deep-learning</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>

                <p>Contents:</p>
                <nav class="toc">
                  <div id="toc"><ul><li><a class="toc-href" href="#deep-learning" title="Deep Learning">Deep Learning</a><ul><li><a class="toc-href" href="#image-recognition" title="Image Recognition">Image Recognition</a><ul><li><a class="toc-href" href="#very-deep-convolutional-networks-for-large-scale-image-recognition-apr-2015" title="Very Deep Convolutional Networks For Large-Scale Image Recognition : Apr 2015">Very Deep Convolutional Networks For Large-Scale Image Recognition : Apr 2015</a></li><li><a class="toc-href" href="#deep-residual-learning-for-image-recognition-dec-2015" title="Deep Residual Learning for Image Recognition : Dec 2015">Deep Residual Learning for Image Recognition : Dec 2015</a></li></ul></li><li><a class="toc-href" href="#deep-visualization_1" title="Deep Visualization">Deep Visualization</a><ul><li><a class="toc-href" href="#visualizing-and-understanding-convolutional-networks-nov-2013" title="Visualizing and Understanding Convolutional Networks : Nov 2013">Visualizing and Understanding Convolutional Networks : Nov 2013</a></li><li><a class="toc-href" href="#multifaceted-feature-visualization-uncovering-the-different-types-of-features-learned-by-each-neuron-in-deep-neural-networks-may-2016" title="Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks : May 2016">Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks : May 2016</a></li></ul></li><li><a class="toc-href" href="#image-segmentation_1" title="Image Segmentation">Image Segmentation</a><ul><li><a class="toc-href" href="#image-segmentation-review" title="Image segmentation review">Image segmentation review</a></li><li><a class="toc-href" href="#a-review-of-deep-learning-techniques-applied-to-semantic-segmentation-apr-2017" title="A Review of Deep Learning Techniques Applied to Semantic Segmentation : Apr 2017">A Review of Deep Learning Techniques Applied to Semantic Segmentation : Apr 2017</a></li><li><a class="toc-href" href="#deeplab-semantic-image-segmentation-with-deep-convolution-nets-atrous-convolution-and-fully-connected-crfs-may-2017" title="DeepLab : Semantic Image Segmentation with Deep Convolution Nets, Atrous Convolution, and Fully Connected CRFs : May 2017">DeepLab : Semantic Image Segmentation with Deep Convolution Nets, Atrous Convolution, and Fully Connected CRFs : May 2017</a></li><li><a class="toc-href" href="#u-net-convolution-networks-for-biomedical-image-segmentation-may-2015" title="U-Net: Convolution Networks for Biomedical Image Segmentation : May 2015">U-Net: Convolution Networks for Biomedical Image Segmentation : May 2015</a></li><li><a class="toc-href" href="#fully-convolutional-networks-for-semantic-segmentation-mar-2015" title="Fully Convolutional Networks for Semantic Segmentation : Mar 2015">Fully Convolutional Networks for Semantic Segmentation : Mar 2015</a></li><li><a class="toc-href" href="#from-image-level-to-pixel-level-labeling-with-convolutional-networks-apr-2015" title="From Image-level to Pixel-level Labeling with Convolutional Networks : Apr 2015">From Image-level to Pixel-level Labeling with Convolutional Networks : Apr 2015</a></li></ul></li><li><a class="toc-href" href="#neural-style_1" title="Neural Style">Neural Style</a><ul><li><a class="toc-href" href="#a-neural-style-algorithm-of-artistic-style-sep-2015" title="A Neural Style Algorithm of Artistic Style : Sep 2015">A Neural Style Algorithm of Artistic Style : Sep 2015</a></li></ul></li><li><a class="toc-href" href="#to-read_1" title="To Read">To Read</a></li></ul></li></ul></div>
                </nav>
                <hr>
                
                <p>Very minimal notes on some papers or articles that I recently read. Mainly for logging purposes.</p>
<h2 id="deep-learning">Deep Learning</h2>
<h3 id="image-recognition">Image Recognition</h3>
<h4 id="very-deep-convolutional-networks-for-large-scale-image-recognition-apr-2015">Very Deep Convolutional Networks For Large-Scale Image Recognition : <em>Apr 2015</em></h4>
<p><a href="https://arxiv.org/pdf/1409.1556.pdf"><em>Source</em></a></p>
<ul>
<li>Introduces the <em>VGG network that won ImageNet in 2014</em>.</li>
<li>Deeper ConvNets. Takes input as (224 X 224) RGB and mean image subtracted as preprocessing. Two final FC hidden layers, followed by one FC layer with 1000 outputs. Number of total trainable parameters turn out to be 144 million for VGG-19. </li>
<li>All the hidden layers use <em>ReLU</em> activations.</li>
<li>Deeper networks with small filters result in more regularization and less parameters.</li>
<li>Optimise multinomial logistic regression objective using mini-batch gradient descent with momentum.</li>
<li>At the end introduces ensemble models by averaging softmax predictions from multiple models.</li>
</ul>
<h4 id="deep-residual-learning-for-image-recognition-dec-2015">Deep Residual Learning for Image Recognition : <em>Dec 2015</em></h4>
<p><a href="https://arxiv.org/pdf/1512.03385v1.pdf"><em>Source</em></a></p>
<ul>
<li>Presents residual learning framework to ease the training of networks that are substantially deeper(152 layers!) than those used previously. <em>How to win ImageNet in 2015.</em></li>
<li>Problem with deeper networks : <em>Vanishing Gradients</em> : Addressed by intermediate normalization.</li>
<li>Problem with deeper networks : <em>Degradation</em>, not caused by overfitting..
<img alt="alt" src="/images/papers/resNet1.jpg"/></li>
<li>Introduces residual learning framework by using shortcut connections that can perform identity mapping.</li>
<li>Using Identity mapping as precondition allows the network to easily learn the identity, if it is a desired mapping. This helps in <em>simplifying</em> networks.</li>
<li><em>Plain Network</em> architecture, mainly based on VGG nets.</li>
<li><em>Residual Network</em> architecture, insert shortcuts to the plain network.</li>
<li>The model shows <em>no optimization difficulty</em> even with &gt; 1000 layers..!!</li>
<li>Finally discusses improvements for detection and localization tasks.</li>
</ul>
<h3 id="deep-visualization_1">Deep Visualization</h3>
<h4 id="visualizing-and-understanding-convolutional-networks-nov-2013">Visualizing and Understanding Convolutional Networks : <em>Nov 2013</em></h4>
<p><a href="https://arxiv.org/abs/1311.2901"><em>Source</em></a></p>
<ul>
<li>Understanding why CNNs perform well on Image Classification tasks.</li>
<li>Visualizing with a Deconvnet
<img alt="alt" src="/images/papers/visnet1.jpg"/></li>
<li>Feature Visualization
<img alt="alt" src="/images/papers/visnet2.jpg"/>
<img alt="alt" src="/images/papers/visnet3.jpg"/>
<img alt="alt" src="/images/papers/visnet4.jpg"/>
<img alt="alt" src="/images/papers/visnet5.jpg"/></li>
<li>Feature Evolution during training
<img alt="alt" src="/images/papers/visnet6.jpg"/></li>
<li>Feature Invariance</li>
<li>Occlusion Sensitivity
<img alt="alt" src="/images/papers/visnet7.jpg"/>
<img alt="alt" src="/images/papers/visnet8.jpg"/></li>
<li>Correspondence Analysis  </li>
</ul>
<h4 id="multifaceted-feature-visualization-uncovering-the-different-types-of-features-learned-by-each-neuron-in-deep-neural-networks-may-2016">Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks : <em>May 2016</em></h4>
<p><a href="https://arxiv.org/pdf/1602.03616.pdf"><em>Source</em></a> </p>
<ul>
<li>Researchers have been using <em>activation maximization</em> techniques until now. This assumes that each neuron detects only one type of feature.</li>
<li>But, we know neurons can be <em>multifaceted</em>. Here <em>multifaceted feature visualization</em> (MFV) is introduced.<ul>
<li>Systematically visualize all facets of a neuron.</li>
<li>Improve image quality of synthesized images with natural and globally consistent colors.
<img alt="alt" src="/images/papers/multiVis1.jpg"/></li>
</ul>
</li>
<li><em>Center biased regularization</em> is used so that the synthesized images dont have many repeated object fragments.<ul>
<li>This is done by first producing a blurry image, then updating the center pixels more than the edge ones, producing a final image that is sharp and has a centrally-located object.</li>
<li>This image would have far fewer duplicated fragments.
<img alt="alt" src="/images/papers/multiVis2.jpg"/></li>
</ul>
</li>
<li>Visualizing the multifaceted nature of hidden neurons
<img alt="alt" src="/images/papers/multiVis3.jpg"/>
<img alt="alt" src="/images/papers/multiVis4.jpg"/></li>
<li>Discusses various optimization techniques to produce better images in detail : center biased regularization, mean image initialization.</li>
</ul>
<h3 id="image-segmentation_1">Image Segmentation</h3>
<h4 id="image-segmentation-review">Image segmentation review</h4>
<p><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review"><em>Source</em></a> </p>
<ul>
<li>A review of segmentation at qure.ai  </li>
</ul>
<h4 id="a-review-of-deep-learning-techniques-applied-to-semantic-segmentation-apr-2017">A Review of Deep Learning Techniques Applied to Semantic Segmentation : <em>Apr 2017</em></h4>
<p><a href="https://arxiv.org/pdf/1704.06857"><em>Source</em></a> </p>
<ul>
<li><em>Semantic Segmentation, Deep Learning, Scene Labeling, Object Segmentation</em> </li>
<li>This paper provides a review on deep learning methods for semantic segmentation applied to various  application areas. This also describes the terminology used as well as some background concepts, then some existing models are reviewed(2017). At last a set of promising future works are discussed.</li>
<li>These techniques are not very mature as of yet, mainly because of a lack of unifying picture.
<img alt="Evolution of object recognition" src="/images/papers/deepSegment1.jpg"/></li>
<li>CNN Architectures : AlexNet, VGG, GoogleNet, ResNet, etc..</li>
<li>2D and 3D Datasets : <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/">PascalVOC</a>,  <a href="6. http://mscoco.org/">Microsoft COCO</a>, and more,...   </li>
<li>Decoder Variants, Integrating Context Knowledge</li>
<li>Instance Segmentation</li>
<li>RGB-D Data and 3D Data</li>
<li>Video Sequences   </li>
</ul>
<h4 id="deeplab-semantic-image-segmentation-with-deep-convolution-nets-atrous-convolution-and-fully-connected-crfs-may-2017">DeepLab : Semantic Image Segmentation with Deep Convolution Nets, Atrous Convolution, and Fully Connected CRFs : <em>May 2017</em></h4>
<p><a href="https://arxiv.org/abs/1606.00915"><em>Source</em></a> </p>
<ul>
<li><em>Semantic Segmentation, Atrous Convolution, Conditional Random Fields</em></li>
<li>Introduces upsampled filters(Altrous Convolution) as a tool in dense prediction tasks. Allows us to control the resolution at which feature responses are computed and also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation.</li>
<li>???? // <em>Read this again..</em></li>
</ul>
<h4 id="u-net-convolution-networks-for-biomedical-image-segmentation-may-2015">U-Net: Convolution Networks for Biomedical Image Segmentation : <em>May 2015</em></h4>
<p><a href="https://arxiv.org/abs/1505.04597"><em>Source</em></a> </p>
<ul>
<li>Focuses on end-to-end training for segmentation tasks, relying heavily on data augmentation.</li>
</ul>
<h4 id="fully-convolutional-networks-for-semantic-segmentation-mar-2015">Fully Convolutional Networks for Semantic Segmentation : <em>Mar 2015</em></h4>
<p><a href="https://arxiv.org/abs/1411.4038"><em>Source</em></a> </p>
<ul>
<li>One of the first works to use Fully Connected layers to create pixel heatmap as output.</li>
<li>Introducing Upsampling or Convolution Transpose.</li>
</ul>
<h4 id="from-image-level-to-pixel-level-labeling-with-convolutional-networks-apr-2015">From Image-level to Pixel-level Labeling with Convolutional Networks : <em>Apr 2015</em></h4>
<p><a href="https://arxiv.org/abs/1411.6228"><em>Source</em></a> </p>
<ul>
<li>Weakly supervised segmentation.</li>
<li>Put more weights to pixels with known class labels.</li>
<li>Uses part of model trained on ImageNet and trains for segmentation on PascalVOC.</li>
</ul>
<h3 id="neural-style_1">Neural Style</h3>
<h4 id="a-neural-style-algorithm-of-artistic-style-sep-2015">A Neural Style Algorithm of Artistic Style : <em>Sep 2015</em></h4>
<p><a href="https://arxiv.org/abs/1508.06576"><em>Source</em></a> </p>
<ul>
<li>In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities.</li>
<li>Then we came across Deep Neural Networks.
<img alt="alt" src="/images/papers/styleTransfer1.jpg"/></li>
<li><em>Higher</em> layers in the network capture the high-level <em>content</em> in terms of objects and their arrangement in the input image. We represent these feature responses as <em>content representation</em>.
<div class="math">$$\mathcal L_{content}(\vec p,\vec x,l) = \frac12\sum_{i,j}{(F^l_{ij} - P^l_{ij})^2}$$</div>
</li>
<li>For <em>style</em> we need to capture correlations(given by <em>Gram matrix</em> <span class="math">\(G^l \in \mathcal R^{N_l \times N_l}\)</span> where <span class="math">\(G^l_{ij} = \sum_kF^l_{ik}F^l_{jk}\)</span>) between different filter responses. This representation captures the texture information of the input, but not the global arrangement. This multi-scale representation is called <em>style representation</em>.
<div class="math">$$E_l = \frac1{4N^2_lM^2_l}\sum_{ij}(G^l_{ij}-A^l_{ij})^2$$</div>
<div class="math">$$\mathcal L_{style}(\vec a,\vec x) = \sum_{l=0}^Lw_lE_l$$</div>
</li>
<li>So, we can manipulate both <em>content</em> and <em>style</em> separately.</li>
<li>The images are synthesised by finding an image that simultaneously matches the content representation of the photograph and the style representation of the respective piece of art.
<div class="math">$$\mathcal L_{total}(\vec p,\vec a,\vec x) = \alpha\mathcal L_{content}(\vec p,\vec x) + \beta\mathcal L_{style}(\vec a,\vec x)$$</div>
<img alt="alt" src="/images/papers/styleTransfer2.jpg"/>
<img alt="alt" src="/images/papers/styleTransfer3.jpg"/>
<img alt="alt" src="/images/papers/styleTransfer4.jpg"/></li>
<li><em>Gallleries</em><ul>
<li><a href="http://kylemcdonald.net/stylestudies/">Style Transfer Studies</a></li>
</ul>
</li>
<li><em>Implementations</em> <ul>
<li><a href="https://github.com/jcjohnson/neural-style">Neural Style, JC Johnson, Lua</a></li>
<li>[]</li>
</ul>
</li>
</ul>
<h3 id="to-read_1">To Read</h3>
<ul>
<li>https://arxiv.org/pdf/1602.03616.pdf</li>
<li>https://arxiv.org/abs/1605.04603</li>
<li>https://arxiv.org/abs/1606.05897</li>
<li>https://arxiv.org/abs/1604.08610</li>
<li>https://arxiv.org/abs/1708.08288</li>
<li>http://cs.stanford.edu/people/jcjohns/eccv16/</li>
<li>https://arxiv.org/abs/1607.08022</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "left",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}</script>

            
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Part 1 of the Research Notes series</h4>
       <h5>Next articles</h5>
       <ul>
           <li><a href="/posts/summary/research-notes-robotics/">Research Notes - Robotics</a></li>
       </ul>
</section>
    <hr />
    <!-- AddThis Button BEGIN -->
    <div class="addthis_toolbox addthis_default_style">
            <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
            <a class="addthis_button_tweet"></a>
            <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    </div>
    <!-- AddThis Button END -->
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'nitishpuri'; // required: replace example with your forum shortname

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://www.facebook.com/npuri1903"><i class="fa fa-facebook-square fa-lg"></i> Facebook</a></li>
    <li class="list-group-item"><a href="https://github.com/nitishpuri"><i class="fa fa-github-square fa-lg"></i> Github</a></li>
    <li class="list-group-item"><a href="https://www.linkedin.com/in/nitishpuri/"><i class="fa fa-linkedin-square fa-lg"></i> Linkedin</a></li>
    <li class="list-group-item"><a href="https://www.instagram.com/purinitish/"><i class="fa fa-instagram fa-lg"></i> Instagram</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-2">
      <a href="/tag/algorithms/">algorithms</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/blogging/">blogging</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/data-science/">data-science</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/deep-learning/">deep-learning</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/gallery/">gallery</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/generative/">generative</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/graphics/">graphics</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/jekyll/">jekyll</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="/tag/notes/">notes</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/opengl/">opengl</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/philosophy/">philosophy</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="/tag/robotics/">robotics</a>
    </li>
    <li class="list-group-item tag-3">
      <a href="/tag/sketch/">sketch</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Series -->
<li class="list-group-item">
  <h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Series</span></h4>
  <ul class="list-group">
    <li class="list-group-item">
      <h5>Next article</h5>
      <a href="/posts/summary/research-notes-robotics/">Research Notes - Robotics</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Series -->


<!-- Sidebar/Github -->
<li class="list-group-item">
  <h4><i class="fa fa-github fa-lg"></i><span class="icon-label">GitHub Repos</span></h4>
  <div id="gh_repos">
    <p class="list-group-item">Status updating...</p>
  </div>
</li>
<!-- End Sidebar/Github -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 Nitish Puri
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>                <p><small>  <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.english"><img alt="Creative Commons License" style="border-width:0" src="//i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a>
    Content
  licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.english">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="/theme/js/respond.min.js"></script>


<!-- GitHub JS Code -->
<script type="text/javascript">
$(document).ready(function () {
  if (!window.jXHR) {
    var jxhr = document.createElement('script');
    jxhr.type = 'text/javascript';
    jxhr.src = '/theme/js/jXHR.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(jxhr, s);
  }

  github.showRepos({
    user: 'nitishpuri',
    count: 5,
    skip_forks: true,
    target: '#gh_repos'
  });
});
</script>
<script src="/theme/js/github.js" type="text/javascript"></script>
<!-- End GitHub JS Code -->
    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'nitishpuri'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->
    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-103032011-1']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->


    <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-59bc69ad3aa13e47"></script>
</body>
</html>